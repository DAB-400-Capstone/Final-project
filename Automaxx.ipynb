{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset \n",
    "\n",
    "data = pd.read_csv('Auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Inv</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>Chrysler</td>\n",
       "      <td>Concorde LXi FWD</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>I</td>\n",
       "      <td>2C3HD36M32H196490</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Liberty Limited 4WD</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>black</td>\n",
       "      <td>205000</td>\n",
       "      <td>I</td>\n",
       "      <td>1J4GL58K74W203537</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Malibu LS FWD</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>I</td>\n",
       "      <td>1G1ZT52875F158217</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 XLT 4x4</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>I</td>\n",
       "      <td>1FTRW14W16KB59343</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Altima 2.5 S FWD</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Blue</td>\n",
       "      <td>206598</td>\n",
       "      <td>I</td>\n",
       "      <td>1N4AL11D96C124803</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year       Make                Model           Car Name Wheel Drive  \\\n",
       "0  2002   Chrysler     Concorde LXi FWD  Chrysler Concorde         FWD   \n",
       "1  2004       Jeep  Liberty Limited 4WD       Jeep Liberty         4WD   \n",
       "2  2005  Chevrolet        Malibu LS FWD   Chevrolet Malibu         FWD   \n",
       "3  2006       Ford        F-150 XLT 4x4         Ford F-150         4WD   \n",
       "4  2006     Nissan     Altima 2.5 S FWD      Nissan Altima         FWD   \n",
       "\n",
       "            Colour  Odometer Inv                VIN Retail  Price  \n",
       "0           SILVER    245305   I  2C3HD36M32H196490   AUTO   1200  \n",
       "1            black    205000   I  1J4GL58K74W203537   AUTO   1200  \n",
       "2            WHITE    199885   I  1G1ZT52875F158217   AUTO   1200  \n",
       "3  Black Clearcoat    176880   I  1FTRW14W16KB59343   AUTO      0  \n",
       "4             Blue    206598   I  1N4AL11D96C124803   AUTO   1200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 5 rows\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Inv</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>2019</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Spark LT FWD</td>\n",
       "      <td>Chevrolet Spark</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Blue</td>\n",
       "      <td>32700</td>\n",
       "      <td>I</td>\n",
       "      <td>KL8CD6SA1KC776013</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2019</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Veloster 2.0 GL - RENTAL FWD</td>\n",
       "      <td>Hyundai Veloster</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47314</td>\n",
       "      <td>I</td>\n",
       "      <td>KMHTG6AF8KU008174</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>16995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>2019</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Soul EX - RENTAL FWD</td>\n",
       "      <td>Kia Soul</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>38790</td>\n",
       "      <td>I</td>\n",
       "      <td>KNDJP3A50K7909751</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>17900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>2019</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Micra S Rental FWD</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Black</td>\n",
       "      <td>17836</td>\n",
       "      <td>I</td>\n",
       "      <td>3N1CK3CP6KL214890</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>2019</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Micra S - rental FWD</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>20225</td>\n",
       "      <td>I</td>\n",
       "      <td>3N1CK3CP3KL217164</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       Make                         Model          Car Name  \\\n",
       "215  2019  Chevrolet                  Spark LT FWD   Chevrolet Spark   \n",
       "216  2019    Hyundai  Veloster 2.0 GL - RENTAL FWD  Hyundai Veloster   \n",
       "217  2019        Kia          Soul EX - RENTAL FWD          Kia Soul   \n",
       "218  2019     Nissan            Micra S Rental FWD      Nissan Micra   \n",
       "219  2019     Nissan          Micra S - rental FWD      Nissan Micra   \n",
       "\n",
       "    Wheel Drive Colour  Odometer Inv                VIN Retail  Price  \n",
       "215         FWD   Blue     32700   I  KL8CD6SA1KC776013   AUTO  14300  \n",
       "216         FWD  WHITE     47314   I  KMHTG6AF8KU008174   AUTO  16995  \n",
       "217         FWD  WHITE     38790   I  KNDJP3A50K7909751   AUTO  17900  \n",
       "218         FWD  Black     17836   I  3N1CK3CP6KL214890   AUTO  14700  \n",
       "219         FWD  WHITE     20225   I  3N1CK3CP3KL217164   AUTO  14300  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the last 5 rows\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the number of rows and columns.\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 11 columns):\n",
      "Year           220 non-null int64\n",
      "Make           220 non-null object\n",
      "Model          220 non-null object\n",
      "Car Name       220 non-null object\n",
      "Wheel Drive    220 non-null object\n",
      "Colour         218 non-null object\n",
      "Odometer       220 non-null int64\n",
      "Inv            220 non-null object\n",
      "VIN            220 non-null object\n",
      "Retail         220 non-null object\n",
      "Price          220 non-null int64\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 19.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Look at the information of all the features\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2015.386364</td>\n",
       "      <td>70621.022727</td>\n",
       "      <td>16436.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.356531</td>\n",
       "      <td>46718.323024</td>\n",
       "      <td>5045.752147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>47590.000000</td>\n",
       "      <td>13700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>63728.000000</td>\n",
       "      <td>15995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>81488.750000</td>\n",
       "      <td>19625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>494156.000000</td>\n",
       "      <td>30900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year       Odometer         Price\n",
       "count   220.000000     220.000000    220.000000\n",
       "mean   2015.386364   70621.022727  16436.545455\n",
       "std       2.356531   46718.323024   5045.752147\n",
       "min    2002.000000       0.000000      0.000000\n",
       "25%    2015.000000   47590.000000  13700.000000\n",
       "50%    2016.000000   63728.000000  15995.000000\n",
       "75%    2017.000000   81488.750000  19625.000000\n",
       "max    2019.000000  494156.000000  30900.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the Dataset\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Make           0\n",
       "Model          0\n",
       "Car Name       0\n",
       "Wheel Drive    0\n",
       "Colour         2\n",
       "Odometer       0\n",
       "Inv            0\n",
       "VIN            0\n",
       "Retail         0\n",
       "Price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null Values\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing null values by taking the mean values.\n",
    "\n",
    "data['Colour'].fillna( method ='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Make           0\n",
       "Model          0\n",
       "Car Name       0\n",
       "Wheel Drive    0\n",
       "Colour         0\n",
       "Odometer       0\n",
       "Inv            0\n",
       "VIN            0\n",
       "Retail         0\n",
       "Price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again Check for null Values\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of unique Model\n",
    "\n",
    "\n",
    "data['Model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of unique Car Name.\n",
    "\n",
    "data['Car Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of unique Makers or Company.\n",
    "\n",
    "data['Make'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21]), <a list of 22 Text xticklabel objects>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for showing different Make. \n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Make'], data = data,palette=\"rocket\",order = data['Make'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), <a list of 4 Text xticklabel objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for showing different Wheel Drive.\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Wheel Drive'], data = data,order = data['Wheel Drive'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for showing different Retail.\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Retail'], data = data,palette=\"PRGn\",order = data['Retail'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Names:  ['SILVER' 'black' 'WHITE' 'Black Clearcoat' 'Blue' 'Copper' 'silver'\n",
      " 'Green' 'Black' 'BLACK' 'Red' 'White' 'Grey' 'Silver' 'Maroon'\n",
      " 'Summit White' 'Yellow' 'GRAY' 'BROWN' 'P8163' 'Billet Metallic' 'GREY'\n",
      " 'Brown' 'BLUE' 'Beige' 'RED' 'Cream' 'Gold' 'Black Cherry']\n"
     ]
    }
   ],
   "source": [
    "# Unique color names.\n",
    "\n",
    "print(\"Color Names: \" , data['Colour'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing all the similar colors.\n",
    "\n",
    "data['Colour'].replace(to_replace =[\"silver\"],  \n",
    "                            value =\"SILVER\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Silver\"],  \n",
    "                            value =\"SILVER\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"black\"],  \n",
    "                            value =\"BLACK\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Black\"],  \n",
    "                            value =\"BLACK\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"White\"],  \n",
    "                            value =\"WHITE\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Blue\"],  \n",
    "                            value =\"BLUE\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Red\"],  \n",
    "                            value =\"RED\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Grey\"],  \n",
    "                            value =\"GREY\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"GRAY\"],  \n",
    "                            value =\"GREY\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Brown\"],  \n",
    "                            value =\"BROWN\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"P8163\"],  \n",
    "                            value =\"GREY\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Names:  ['SILVER' 'BLACK' 'WHITE' 'Black Clearcoat' 'BLUE' 'Copper' 'Green' 'RED'\n",
      " 'GREY' 'Maroon' 'Summit White' 'Yellow' 'BROWN' 'Billet Metallic' 'Beige'\n",
      " 'Cream' 'Gold' 'Black Cherry']\n"
     ]
    }
   ],
   "source": [
    "# Unique color names.\n",
    "\n",
    "print(\"Color Names: \" , data['Colour'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17]), <a list of 18 Text xticklabel objects>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histogram for showing different Color. \n",
    "\n",
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Colour'], data = data,palette=\"rocket\",order = data['Colour'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which are of least importance.\n",
    "\n",
    "cars = data.drop(['Make','Model','Inv','VIN',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>205000</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>206598</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Car Name Wheel Drive           Colour  Odometer Retail  \\\n",
       "0  2002  Chrysler Concorde         FWD           SILVER    245305   AUTO   \n",
       "1  2004       Jeep Liberty         4WD            BLACK    205000   AUTO   \n",
       "2  2005   Chevrolet Malibu         FWD            WHITE    199885   AUTO   \n",
       "3  2006         Ford F-150         4WD  Black Clearcoat    176880   AUTO   \n",
       "4  2006      Nissan Altima         FWD             BLUE    206598   AUTO   \n",
       "\n",
       "   Price  \n",
       "0   1200  \n",
       "1   1200  \n",
       "2   1200  \n",
       "3      0  \n",
       "4   1200  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "      <th>No_of_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>205000</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>206598</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>Chevrolet Spark</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>32700</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>Hyundai Veloster</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47314</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>16995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>Kia Soul</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>38790</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>17900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>17836</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>20225</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Car Name Wheel Drive           Colour  Odometer Retail  Price  \\\n",
       "0    Chrysler Concorde         FWD           SILVER    245305   AUTO   1200   \n",
       "1         Jeep Liberty         4WD            BLACK    205000   AUTO   1200   \n",
       "2     Chevrolet Malibu         FWD            WHITE    199885   AUTO   1200   \n",
       "3           Ford F-150         4WD  Black Clearcoat    176880   AUTO      0   \n",
       "4        Nissan Altima         FWD             BLUE    206598   AUTO   1200   \n",
       "..                 ...         ...              ...       ...    ...    ...   \n",
       "215    Chevrolet Spark         FWD             BLUE     32700   AUTO  14300   \n",
       "216   Hyundai Veloster         FWD            WHITE     47314   AUTO  16995   \n",
       "217           Kia Soul         FWD            WHITE     38790   AUTO  17900   \n",
       "218       Nissan Micra         FWD            BLACK     17836   AUTO  14700   \n",
       "219       Nissan Micra         FWD            WHITE     20225   AUTO  14300   \n",
       "\n",
       "     No_of_Years  \n",
       "0             18  \n",
       "1             16  \n",
       "2             15  \n",
       "3             14  \n",
       "4             14  \n",
       "..           ...  \n",
       "215            1  \n",
       "216            1  \n",
       "217            1  \n",
       "218            1  \n",
       "219            1  \n",
       "\n",
       "[220 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column showing the number of years. \n",
    "\n",
    "year = 2020\n",
    "cars['No_of_Years'] = cars['Year'].apply(lambda x :year - x)\n",
    "cars.drop('Year',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical values into dummies using the get_dummies function  \n",
    "\n",
    "\n",
    "df=pd.get_dummies(cars['Car Name'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Car Name'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Wheel Drive'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Wheel Drive'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Colour'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Colour'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Retail'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Retail'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Price</th>\n",
       "      <th>No_of_Years</th>\n",
       "      <th>BMW 3</th>\n",
       "      <th>BMW X3</th>\n",
       "      <th>Buick Encore</th>\n",
       "      <th>Buick Regal</th>\n",
       "      <th>Buick Verano</th>\n",
       "      <th>Cadillac ATS</th>\n",
       "      <th>Cadillac SRX</th>\n",
       "      <th>...</th>\n",
       "      <th>Cream</th>\n",
       "      <th>GREY</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Green</th>\n",
       "      <th>Maroon</th>\n",
       "      <th>RED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>Summit White</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>AUTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>245305</td>\n",
       "      <td>1200</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>205000</td>\n",
       "      <td>1200</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199885</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>176880</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>206598</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Odometer  Price  No_of_Years  BMW 3  BMW X3  Buick Encore  Buick Regal  \\\n",
       "0    245305   1200           18      0       0             0            0   \n",
       "1    205000   1200           16      0       0             0            0   \n",
       "2    199885   1200           15      0       0             0            0   \n",
       "3    176880      0           14      0       0             0            0   \n",
       "4    206598   1200           14      0       0             0            0   \n",
       "\n",
       "   Buick Verano  Cadillac ATS  Cadillac SRX  ...  Cream  GREY  Gold  Green  \\\n",
       "0             0             0             0  ...      0     0     0      0   \n",
       "1             0             0             0  ...      0     0     0      0   \n",
       "2             0             0             0  ...      0     0     0      0   \n",
       "3             0             0             0  ...      0     0     0      0   \n",
       "4             0             0             0  ...      0     0     0      0   \n",
       "\n",
       "   Maroon  RED  SILVER  Summit White  WHITE  AUTO  \n",
       "0       0    0       1             0      0     1  \n",
       "1       0    0       0             0      0     1  \n",
       "2       0    0       0             0      1     1  \n",
       "3       0    0       0             0      0     1  \n",
       "4       0    0       0             0      0     1  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the Year Column \n",
    "\n",
    "cars.drop(['Year'],axis=1,inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be making Y as the target variable by only passing the Price column from the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars.drop('Price',axis=1)\n",
    "Y = cars['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odometer</th>\n",
       "      <th>No_of_Years</th>\n",
       "      <th>BMW 3</th>\n",
       "      <th>BMW X3</th>\n",
       "      <th>Buick Encore</th>\n",
       "      <th>Buick Regal</th>\n",
       "      <th>Buick Verano</th>\n",
       "      <th>Cadillac ATS</th>\n",
       "      <th>Cadillac SRX</th>\n",
       "      <th>Cadillac XTS</th>\n",
       "      <th>...</th>\n",
       "      <th>Cream</th>\n",
       "      <th>GREY</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Green</th>\n",
       "      <th>Maroon</th>\n",
       "      <th>RED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>Summit White</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>AUTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>245305</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>205000</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199885</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>176880</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>206598</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Odometer  No_of_Years  BMW 3  BMW X3  Buick Encore  Buick Regal  \\\n",
       "0    245305           18      0       0             0            0   \n",
       "1    205000           16      0       0             0            0   \n",
       "2    199885           15      0       0             0            0   \n",
       "3    176880           14      0       0             0            0   \n",
       "4    206598           14      0       0             0            0   \n",
       "\n",
       "   Buick Verano  Cadillac ATS  Cadillac SRX  Cadillac XTS  ...  Cream  GREY  \\\n",
       "0             0             0             0             0  ...      0     0   \n",
       "1             0             0             0             0  ...      0     0   \n",
       "2             0             0             0             0  ...      0     0   \n",
       "3             0             0             0             0  ...      0     0   \n",
       "4             0             0             0             0  ...      0     0   \n",
       "\n",
       "   Gold  Green  Maroon  RED  SILVER  Summit White  WHITE  AUTO  \n",
       "0     0      0       0    0       1             0      0     1  \n",
       "1     0      0       0    0       0             0      0     1  \n",
       "2     0      0       0    0       0             0      1     1  \n",
       "3     0      0       0    0       0             0      0     1  \n",
       "4     0      0       0    0       0             0      0     1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "1    1200\n",
       "2    1200\n",
       "3       0\n",
       "4    1200\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Train and Test data using Minmax Scaler\n",
    "\n",
    "minma = MinMaxScaler()\n",
    "minma.fit(X_train)\n",
    "X_train = minma.transform(X_train)\n",
    "X_test = minma.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.73\n",
      "Accuracy for Training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=200)\n",
    "rf_reg.fit(X_train,y_train)\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "test_pred=rf_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(rf_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(rf_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 4.7\n",
      "Tree on test set MAE%: 12.2\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2745.988723510147"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.54\n",
      "Accuracy for Training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "dec_reg = DecisionTreeRegressor()\n",
    "dec_reg.fit(X_train,y_train)\n",
    "train_pred = dec_reg.predict(X_train)\n",
    "test_pred=dec_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(dec_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(dec_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 0.0\n",
      "Tree on test set MAE%: 16.0\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3567.741359612676"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: -790058709270002982191104.00\n",
      "Accuracy for Training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg = reg.fit(X_train,y_train)\n",
    "train_pred = reg.predict(X_train)\n",
    "test_pred = reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 5.2\n",
      "Tree on test set MAE%: 6782234639112.4\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695386783326496.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbor Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.54\n",
      "Accuracy for Training set: 0.58\n"
     ]
    }
   ],
   "source": [
    "k_reg=KNeighborsRegressor()\n",
    "k_reg = k_reg.fit(X_train,y_train)\n",
    "train_pred = k_reg.predict(X_train)\n",
    "test_pred=k_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(k_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(k_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 14.2\n",
      "Tree on test set MAE%: 16.3\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595.8954757789156"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.44\n",
      "Accuracy for Training set: 0.57\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor(max_features=4,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=300,\n",
    "                                random_state=10)\n",
    "gb_reg.fit(X_train,y_train)\n",
    "train_pred = gb_reg.predict(X_train)\n",
    "test_pred=gb_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(gb_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(gb_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 15.2\n",
      "Tree on test set MAE%: 18.2\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3935.6608373117283"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "model = Sequential()\n",
    "model.add(Dense(200,activation='relu',input_dim=104))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 290603706.1818\n",
      "Epoch 2/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 290548891.6364\n",
      "Epoch 3/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 290454304.0000\n",
      "Epoch 4/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 290275240.7273\n",
      "Epoch 5/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 289972011.6364\n",
      "Epoch 6/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 289456043.6364\n",
      "Epoch 7/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 288665592.7273\n",
      "Epoch 8/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 287507179.6364\n",
      "Epoch 9/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 285899261.0909\n",
      "Epoch 10/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 283802808.7273\n",
      "Epoch 11/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 280983810.9091\n",
      "Epoch 12/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 277514462.5455\n",
      "Epoch 13/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 273258545.4545\n",
      "Epoch 14/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 268389293.0909\n",
      "Epoch 15/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 262028264.7273\n",
      "Epoch 16/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 255811344.0000\n",
      "Epoch 17/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 247397636.3636\n",
      "Epoch 18/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 238898084.3636\n",
      "Epoch 19/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 229521064.7273\n",
      "Epoch 20/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 219145790.5455\n",
      "Epoch 21/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 208152501.8182\n",
      "Epoch 22/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 196641201.4545\n",
      "Epoch 23/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 183104978.9091\n",
      "Epoch 24/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 171363547.6364\n",
      "Epoch 25/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 159678285.8182\n",
      "Epoch 26/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 146824279.2727\n",
      "Epoch 27/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 132906866.9091\n",
      "Epoch 28/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 120410078.5455\n",
      "Epoch 29/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 108622721.4545\n",
      "Epoch 30/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 97402194.9091\n",
      "Epoch 31/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 87412485.8182\n",
      "Epoch 32/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 78050718.1818\n",
      "Epoch 33/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 68428662.9091\n",
      "Epoch 34/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 62341809.6364\n",
      "Epoch 35/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 55185082.7273\n",
      "Epoch 36/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 49661236.1818\n",
      "Epoch 37/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 46665547.8182\n",
      "Epoch 38/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 40747768.0000\n",
      "Epoch 39/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 39186750.7273\n",
      "Epoch 40/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 35432316.9091\n",
      "Epoch 41/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 35942901.0909\n",
      "Epoch 42/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 34801466.7273\n",
      "Epoch 43/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 34961272.8182\n",
      "Epoch 44/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 31709161.2727\n",
      "Epoch 45/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 32173628.0000\n",
      "Epoch 46/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 31650234.9091\n",
      "Epoch 47/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 31715720.8182\n",
      "Epoch 48/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 32202181.2273\n",
      "Epoch 49/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 31366239.8182\n",
      "Epoch 50/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 30601162.5455\n",
      "Epoch 51/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 28829059.8182\n",
      "Epoch 52/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 28123904.7273\n",
      "Epoch 53/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 30579578.0909\n",
      "Epoch 54/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 31162334.3636\n",
      "Epoch 55/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 29383803.2273\n",
      "Epoch 56/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 32416338.5909\n",
      "Epoch 57/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 30077162.0227\n",
      "Epoch 58/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 27821539.0909\n",
      "Epoch 59/2000\n",
      "176/176 [==============================] - 0s 343us/step - loss: 27020072.6136\n",
      "Epoch 60/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 27955864.6364\n",
      "Epoch 61/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 27979440.0000\n",
      "Epoch 62/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 27043496.1818\n",
      "Epoch 63/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 28934165.0000\n",
      "Epoch 64/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 25078217.2727\n",
      "Epoch 65/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 28011112.9545\n",
      "Epoch 66/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 26904060.3636\n",
      "Epoch 67/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 26744261.3636\n",
      "Epoch 68/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 26029115.3182\n",
      "Epoch 69/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 25296850.6818\n",
      "Epoch 70/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 25961417.5909\n",
      "Epoch 71/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 29297631.5909\n",
      "Epoch 72/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 24000650.1818\n",
      "Epoch 73/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 24137710.6364\n",
      "Epoch 74/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 22505577.5909\n",
      "Epoch 75/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 24473199.9773\n",
      "Epoch 76/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 25630044.3636\n",
      "Epoch 77/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 25145057.6818\n",
      "Epoch 78/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 24530070.0909\n",
      "Epoch 79/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 24894046.3182\n",
      "Epoch 80/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 23057303.7727\n",
      "Epoch 81/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 23839150.0000\n",
      "Epoch 82/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 23331700.4545\n",
      "Epoch 83/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 21062351.3636\n",
      "Epoch 84/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 23728877.5455\n",
      "Epoch 85/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 22662778.6364\n",
      "Epoch 86/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 22453262.5455\n",
      "Epoch 87/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 22723225.8182\n",
      "Epoch 88/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 22282480.4545\n",
      "Epoch 89/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 23114000.0455\n",
      "Epoch 90/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 22447284.6364\n",
      "Epoch 91/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 21569685.6364\n",
      "Epoch 92/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 21090289.5455\n",
      "Epoch 93/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 23005404.0455\n",
      "Epoch 94/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 21429889.6364\n",
      "Epoch 95/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 21294404.5455\n",
      "Epoch 96/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 21416603.5455\n",
      "Epoch 97/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 22000896.9091\n",
      "Epoch 98/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 19881101.7273\n",
      "Epoch 99/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 19564904.5000\n",
      "Epoch 100/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 22378140.8182\n",
      "Epoch 101/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 18900262.1364\n",
      "Epoch 102/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 19549310.4545\n",
      "Epoch 103/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 19920165.8636\n",
      "Epoch 104/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 19466456.7273\n",
      "Epoch 105/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 18813935.3182\n",
      "Epoch 106/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 18957412.1591\n",
      "Epoch 107/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 18781885.5455\n",
      "Epoch 108/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 18788422.3636\n",
      "Epoch 109/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 19865256.9091\n",
      "Epoch 110/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 19197142.5000\n",
      "Epoch 111/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 18366309.3636\n",
      "Epoch 112/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 20056758.2727\n",
      "Epoch 113/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 16920077.7727\n",
      "Epoch 114/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 17319758.8636\n",
      "Epoch 115/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 18646852.2727\n",
      "Epoch 116/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 16883927.1364\n",
      "Epoch 117/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 17018579.5909\n",
      "Epoch 118/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 17968441.0000\n",
      "Epoch 119/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 17398849.7727\n",
      "Epoch 120/2000\n",
      "176/176 [==============================] - 0s 132us/step - loss: 16451007.1818\n",
      "Epoch 121/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 17844813.1818\n",
      "Epoch 122/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 15785557.5909\n",
      "Epoch 123/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 16811984.2727\n",
      "Epoch 124/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 16339031.6364\n",
      "Epoch 125/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 16883720.5455\n",
      "Epoch 126/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 17603575.2045\n",
      "Epoch 127/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 16016043.3636\n",
      "Epoch 128/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 17212460.2727\n",
      "Epoch 129/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 16201121.6364\n",
      "Epoch 130/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 17473897.2727\n",
      "Epoch 131/2000\n",
      "176/176 [==============================] - 0s 152us/step - loss: 15846012.2500\n",
      "Epoch 132/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 15931202.4091\n",
      "Epoch 133/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 16461188.1818\n",
      "Epoch 134/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 15110036.3636\n",
      "Epoch 135/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 14819015.2273\n",
      "Epoch 136/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 15189036.4545\n",
      "Epoch 137/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 14896572.3636\n",
      "Epoch 138/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 15343940.6591\n",
      "Epoch 139/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 13621207.7273\n",
      "Epoch 140/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 14572271.9773\n",
      "Epoch 141/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 14923202.9545\n",
      "Epoch 142/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 15246245.6364\n",
      "Epoch 143/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 14026209.8864\n",
      "Epoch 144/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 13567813.6818\n",
      "Epoch 145/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 13781312.9545\n",
      "Epoch 146/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 13542660.5000\n",
      "Epoch 147/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 14880384.5000\n",
      "Epoch 148/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 14319200.0000\n",
      "Epoch 149/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 13735731.6364\n",
      "Epoch 150/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 13754556.6818\n",
      "Epoch 151/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 14158697.2273\n",
      "Epoch 152/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 14444449.5455\n",
      "Epoch 153/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 12450735.2273\n",
      "Epoch 154/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 13685593.1364\n",
      "Epoch 155/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 13854175.5000\n",
      "Epoch 156/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 11955726.3864\n",
      "Epoch 157/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 13355569.8182\n",
      "Epoch 158/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 13262028.6818\n",
      "Epoch 159/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 13200211.3182\n",
      "Epoch 160/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 12699973.9545\n",
      "Epoch 161/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 12117401.5909\n",
      "Epoch 162/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 11279792.9545\n",
      "Epoch 163/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 12047483.0909\n",
      "Epoch 164/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 13303506.8182\n",
      "Epoch 165/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 11884706.1818\n",
      "Epoch 166/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 12117592.5000\n",
      "Epoch 167/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 12400368.5909\n",
      "Epoch 168/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 10926417.9545\n",
      "Epoch 169/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 11509622.5682\n",
      "Epoch 170/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 11620094.9545\n",
      "Epoch 171/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 11012860.0682\n",
      "Epoch 172/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 10827561.3636\n",
      "Epoch 173/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 10633954.8636\n",
      "Epoch 174/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 11578838.5000\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 168us/step - loss: 12588650.7273\n",
      "Epoch 176/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 10694585.5682\n",
      "Epoch 177/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 10320939.3182\n",
      "Epoch 178/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 10870677.3182\n",
      "Epoch 179/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 10839220.9773\n",
      "Epoch 180/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 11045789.3636\n",
      "Epoch 181/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 10337755.5909\n",
      "Epoch 182/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 10768299.1364\n",
      "Epoch 183/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 12118056.7273\n",
      "Epoch 184/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 10257292.9545\n",
      "Epoch 185/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 10707682.4091\n",
      "Epoch 186/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 9984138.0455\n",
      "Epoch 187/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 9852525.3636\n",
      "Epoch 188/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 10473707.5909\n",
      "Epoch 189/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 9832798.0000\n",
      "Epoch 190/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 9851363.5455\n",
      "Epoch 191/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 10434788.2727\n",
      "Epoch 192/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 9926584.5909\n",
      "Epoch 193/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 10078146.3182\n",
      "Epoch 194/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 10856158.7273\n",
      "Epoch 195/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 10107985.6364\n",
      "Epoch 196/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 8646299.0455\n",
      "Epoch 197/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 8806420.1818\n",
      "Epoch 198/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 9985815.0455\n",
      "Epoch 199/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 9299088.5682\n",
      "Epoch 200/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 8227579.8864\n",
      "Epoch 201/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 8201712.3864\n",
      "Epoch 202/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 7873893.7727\n",
      "Epoch 203/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 8688661.4091\n",
      "Epoch 204/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 9433611.3182\n",
      "Epoch 205/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 9040662.7955\n",
      "Epoch 206/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 9019903.9545\n",
      "Epoch 207/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 8714832.7727\n",
      "Epoch 208/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 9278661.1591\n",
      "Epoch 209/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 9315081.6364\n",
      "Epoch 210/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 7929452.7273\n",
      "Epoch 211/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 7203251.3182\n",
      "Epoch 212/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 8636548.9545\n",
      "Epoch 213/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 8352581.2273\n",
      "Epoch 214/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 7764998.8636\n",
      "Epoch 215/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 7826995.7273\n",
      "Epoch 216/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 7300889.3409\n",
      "Epoch 217/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 8639986.2273\n",
      "Epoch 218/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 7969465.8409\n",
      "Epoch 219/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 7401403.0000\n",
      "Epoch 220/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 7677032.5909\n",
      "Epoch 221/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 7304023.1364\n",
      "Epoch 222/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 7917335.7273\n",
      "Epoch 223/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 8795460.2727\n",
      "Epoch 224/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 7477204.2045\n",
      "Epoch 225/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 8916299.9091\n",
      "Epoch 226/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 8178126.0227\n",
      "Epoch 227/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 8404475.5682\n",
      "Epoch 228/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 6939608.7273\n",
      "Epoch 229/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 6432651.6818\n",
      "Epoch 230/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 7571103.9545\n",
      "Epoch 231/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 7353579.3182\n",
      "Epoch 232/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 8348222.6364\n",
      "Epoch 233/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 7192119.2273\n",
      "Epoch 234/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 7447421.0909\n",
      "Epoch 235/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 6060978.8636\n",
      "Epoch 236/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 8651037.8636\n",
      "Epoch 237/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 6759300.8636\n",
      "Epoch 238/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 8029309.1364\n",
      "Epoch 239/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 7686350.6364\n",
      "Epoch 240/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 7140948.7500\n",
      "Epoch 241/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 7677955.7045\n",
      "Epoch 242/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 6812727.5909\n",
      "Epoch 243/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 6430053.6591\n",
      "Epoch 244/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 6764139.9773\n",
      "Epoch 245/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 7362413.1818\n",
      "Epoch 246/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 7482646.2273\n",
      "Epoch 247/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 6991979.0682\n",
      "Epoch 248/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 7099630.1364\n",
      "Epoch 249/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 6650208.7727\n",
      "Epoch 250/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 6174811.4545\n",
      "Epoch 251/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 6321357.9773\n",
      "Epoch 252/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 6147375.6932\n",
      "Epoch 253/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 6524689.7841\n",
      "Epoch 254/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 5890703.2727\n",
      "Epoch 255/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 5736980.7727\n",
      "Epoch 256/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 6141831.4091\n",
      "Epoch 257/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 6227926.1591\n",
      "Epoch 258/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 6769110.3409\n",
      "Epoch 259/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 7032075.1136\n",
      "Epoch 260/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 6235175.5000\n",
      "Epoch 261/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 6719666.5455\n",
      "Epoch 262/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 6978488.7273\n",
      "Epoch 263/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 167us/step - loss: 6630091.3636\n",
      "Epoch 264/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 5576549.7273\n",
      "Epoch 265/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 6148811.9545\n",
      "Epoch 266/2000\n",
      "176/176 [==============================] - 0s 342us/step - loss: 6210342.6818\n",
      "Epoch 267/2000\n",
      "176/176 [==============================] - 0s 322us/step - loss: 6178910.7727\n",
      "Epoch 268/2000\n",
      "176/176 [==============================] - 0s 344us/step - loss: 5534490.8864\n",
      "Epoch 269/2000\n",
      "176/176 [==============================] - 0s 317us/step - loss: 6430750.1818\n",
      "Epoch 270/2000\n",
      "176/176 [==============================] - 0s 324us/step - loss: 6277442.5455\n",
      "Epoch 271/2000\n",
      "176/176 [==============================] - 0s 307us/step - loss: 6512688.1818\n",
      "Epoch 272/2000\n",
      "176/176 [==============================] - 0s 315us/step - loss: 5972747.0909\n",
      "Epoch 273/2000\n",
      "176/176 [==============================] - 0s 356us/step - loss: 6199635.3409\n",
      "Epoch 274/2000\n",
      "176/176 [==============================] - 0s 354us/step - loss: 6060396.2500\n",
      "Epoch 275/2000\n",
      "176/176 [==============================] - 0s 314us/step - loss: 5635616.5000\n",
      "Epoch 276/2000\n",
      "176/176 [==============================] - 0s 293us/step - loss: 5596720.9773\n",
      "Epoch 277/2000\n",
      "176/176 [==============================] - 0s 315us/step - loss: 5217383.4773\n",
      "Epoch 278/2000\n",
      "176/176 [==============================] - 0s 321us/step - loss: 6013456.4091\n",
      "Epoch 279/2000\n",
      "176/176 [==============================] - 0s 345us/step - loss: 4979837.8409\n",
      "Epoch 280/2000\n",
      "176/176 [==============================] - 0s 356us/step - loss: 5717909.8750\n",
      "Epoch 281/2000\n",
      "176/176 [==============================] - 0s 326us/step - loss: 5819828.0909\n",
      "Epoch 282/2000\n",
      "176/176 [==============================] - 0s 305us/step - loss: 5595071.5455\n",
      "Epoch 283/2000\n",
      "176/176 [==============================] - 0s 338us/step - loss: 5516358.6136\n",
      "Epoch 284/2000\n",
      "176/176 [==============================] - 0s 328us/step - loss: 6408134.1818\n",
      "Epoch 285/2000\n",
      "176/176 [==============================] - 0s 319us/step - loss: 5300591.7955\n",
      "Epoch 286/2000\n",
      "176/176 [==============================] - 0s 361us/step - loss: 5124687.6818\n",
      "Epoch 287/2000\n",
      "176/176 [==============================] - 0s 312us/step - loss: 6089385.5682\n",
      "Epoch 288/2000\n",
      "176/176 [==============================] - 0s 299us/step - loss: 5864064.0455\n",
      "Epoch 289/2000\n",
      "176/176 [==============================] - 0s 318us/step - loss: 5056886.4545\n",
      "Epoch 290/2000\n",
      "176/176 [==============================] - 0s 311us/step - loss: 5614145.9091\n",
      "Epoch 291/2000\n",
      "176/176 [==============================] - 0s 327us/step - loss: 5899486.7045\n",
      "Epoch 292/2000\n",
      "176/176 [==============================] - 0s 374us/step - loss: 5624988.0455\n",
      "Epoch 293/2000\n",
      "176/176 [==============================] - 0s 320us/step - loss: 5945746.3636\n",
      "Epoch 294/2000\n",
      "176/176 [==============================] - 0s 325us/step - loss: 5259404.8409\n",
      "Epoch 295/2000\n",
      "176/176 [==============================] - 0s 331us/step - loss: 5770790.5909\n",
      "Epoch 296/2000\n",
      "176/176 [==============================] - 0s 331us/step - loss: 5584835.6136\n",
      "Epoch 297/2000\n",
      "176/176 [==============================] - 0s 303us/step - loss: 4918002.7614\n",
      "Epoch 298/2000\n",
      "176/176 [==============================] - 0s 322us/step - loss: 4649301.4773\n",
      "Epoch 299/2000\n",
      "176/176 [==============================] - 0s 343us/step - loss: 5713343.2955\n",
      "Epoch 300/2000\n",
      "176/176 [==============================] - 0s 341us/step - loss: 5018964.9318\n",
      "Epoch 301/2000\n",
      "176/176 [==============================] - 0s 321us/step - loss: 5049420.2500\n",
      "Epoch 302/2000\n",
      "176/176 [==============================] - 0s 290us/step - loss: 5600397.7500\n",
      "Epoch 303/2000\n",
      "176/176 [==============================] - 0s 306us/step - loss: 5456135.8864\n",
      "Epoch 304/2000\n",
      "176/176 [==============================] - 0s 311us/step - loss: 4875271.9545\n",
      "Epoch 305/2000\n",
      "176/176 [==============================] - 0s 361us/step - loss: 5314084.2500\n",
      "Epoch 306/2000\n",
      "176/176 [==============================] - 0s 316us/step - loss: 5319305.7727\n",
      "Epoch 307/2000\n",
      "176/176 [==============================] - 0s 312us/step - loss: 5000434.7045\n",
      "Epoch 308/2000\n",
      "176/176 [==============================] - 0s 310us/step - loss: 5905742.7273\n",
      "Epoch 309/2000\n",
      "176/176 [==============================] - 0s 314us/step - loss: 5023469.2955\n",
      "Epoch 310/2000\n",
      "176/176 [==============================] - 0s 328us/step - loss: 4603680.4091\n",
      "Epoch 311/2000\n",
      "176/176 [==============================] - 0s 377us/step - loss: 5759742.5000\n",
      "Epoch 312/2000\n",
      "176/176 [==============================] - 0s 333us/step - loss: 5070152.3409\n",
      "Epoch 313/2000\n",
      "176/176 [==============================] - 0s 324us/step - loss: 4862464.2500\n",
      "Epoch 314/2000\n",
      "176/176 [==============================] - 0s 306us/step - loss: 4566735.0568\n",
      "Epoch 315/2000\n",
      "176/176 [==============================] - 0s 321us/step - loss: 5447083.0682\n",
      "Epoch 316/2000\n",
      "176/176 [==============================] - 0s 302us/step - loss: 5725516.5227\n",
      "Epoch 317/2000\n",
      "176/176 [==============================] - 0s 375us/step - loss: 4789175.1136\n",
      "Epoch 318/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 5307832.4091\n",
      "Epoch 319/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 4942335.6818\n",
      "Epoch 320/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 5141378.0455\n",
      "Epoch 321/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 4029718.0000\n",
      "Epoch 322/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4050383.5227\n",
      "Epoch 323/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 5298726.7955\n",
      "Epoch 324/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4714051.4091\n",
      "Epoch 325/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4955425.8636\n",
      "Epoch 326/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 4529524.6136\n",
      "Epoch 327/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 5834423.3636\n",
      "Epoch 328/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 5582759.2273\n",
      "Epoch 329/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 4960485.1591\n",
      "Epoch 330/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 4829008.7955\n",
      "Epoch 331/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 5162242.0227\n",
      "Epoch 332/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 5508137.5341\n",
      "Epoch 333/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 5606019.8182\n",
      "Epoch 334/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4487251.0000\n",
      "Epoch 335/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 5467096.3864\n",
      "Epoch 336/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4759868.3636\n",
      "Epoch 337/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 4521166.7045\n",
      "Epoch 338/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 5197287.7955\n",
      "Epoch 339/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 5797376.7159\n",
      "Epoch 340/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4401468.6818\n",
      "Epoch 341/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 5060500.8864\n",
      "Epoch 342/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4818973.6364\n",
      "Epoch 343/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 4863971.0227\n",
      "Epoch 344/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4813005.1705\n",
      "Epoch 345/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 5011257.8864\n",
      "Epoch 346/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 4921129.9318\n",
      "Epoch 347/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4366594.5682\n",
      "Epoch 348/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4265434.4318\n",
      "Epoch 349/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4383474.2159\n",
      "Epoch 350/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4498385.0227\n",
      "Epoch 351/2000\n",
      "176/176 [==============================] - 0s 152us/step - loss: 4267334.3636\n",
      "Epoch 352/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 4897547.2273\n",
      "Epoch 353/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 4032376.4545\n",
      "Epoch 354/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4953651.8864\n",
      "Epoch 355/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 4914019.0000\n",
      "Epoch 356/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4669696.5227\n",
      "Epoch 357/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 5169043.5227\n",
      "Epoch 358/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 4542124.1591\n",
      "Epoch 359/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 5316448.2955\n",
      "Epoch 360/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 5099055.3409\n",
      "Epoch 361/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4038960.0568\n",
      "Epoch 362/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 5915268.3636\n",
      "Epoch 363/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4658573.3409\n",
      "Epoch 364/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4649017.5455\n",
      "Epoch 365/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3860442.4091\n",
      "Epoch 366/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4573783.4545\n",
      "Epoch 367/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4810834.0227\n",
      "Epoch 368/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 4480747.9091\n",
      "Epoch 369/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 5465199.5682\n",
      "Epoch 370/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 4627534.2841\n",
      "Epoch 371/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 4050519.1136\n",
      "Epoch 372/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4797320.6136\n",
      "Epoch 373/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4637106.9773\n",
      "Epoch 374/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3847068.6364\n",
      "Epoch 375/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 5077346.5682\n",
      "Epoch 376/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4609051.5455\n",
      "Epoch 377/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4405035.6364\n",
      "Epoch 378/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4486197.6705\n",
      "Epoch 379/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 4609561.9318\n",
      "Epoch 380/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4443463.0682\n",
      "Epoch 381/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4644163.2273\n",
      "Epoch 382/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4956839.2273\n",
      "Epoch 383/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 4501302.7045\n",
      "Epoch 384/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 5177425.5455\n",
      "Epoch 385/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 4194790.4545\n",
      "Epoch 386/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 4576320.3864\n",
      "Epoch 387/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 5139833.0455\n",
      "Epoch 388/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4797225.3182\n",
      "Epoch 389/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4367654.7727\n",
      "Epoch 390/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4794667.0682\n",
      "Epoch 391/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 5278065.5682\n",
      "Epoch 392/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 4456462.7727\n",
      "Epoch 393/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 4101258.5682\n",
      "Epoch 394/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4252814.5000\n",
      "Epoch 395/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4140723.1818\n",
      "Epoch 396/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4025736.3977\n",
      "Epoch 397/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 4431342.2955\n",
      "Epoch 398/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3956789.1818\n",
      "Epoch 399/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4916264.6023\n",
      "Epoch 400/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3895297.2500\n",
      "Epoch 401/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 4038421.6023\n",
      "Epoch 402/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 4265811.2159\n",
      "Epoch 403/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4732267.5455\n",
      "Epoch 404/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3443499.2500\n",
      "Epoch 405/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 4290769.9318\n",
      "Epoch 406/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4296033.3523\n",
      "Epoch 407/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3791940.5909\n",
      "Epoch 408/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4059944.4545\n",
      "Epoch 409/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3391354.6136\n",
      "Epoch 410/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4392054.2500\n",
      "Epoch 411/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4116925.3636\n",
      "Epoch 412/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4342595.4318\n",
      "Epoch 413/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 4860567.5682\n",
      "Epoch 414/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3915484.3636\n",
      "Epoch 415/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 5104916.2727\n",
      "Epoch 416/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 4684557.1364\n",
      "Epoch 417/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 4453904.1591\n",
      "Epoch 418/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3887441.1818\n",
      "Epoch 419/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4401231.3409\n",
      "Epoch 420/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 5300993.9091\n",
      "Epoch 421/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4750322.3523\n",
      "Epoch 422/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3874120.3523\n",
      "Epoch 423/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3911475.8864\n",
      "Epoch 424/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3729883.6818\n",
      "Epoch 425/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4027496.8864\n",
      "Epoch 426/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 4380497.3636\n",
      "Epoch 427/2000\n",
      "176/176 [==============================] - 0s 127us/step - loss: 3640948.9545\n",
      "Epoch 428/2000\n",
      "176/176 [==============================] - 0s 129us/step - loss: 3917615.0000\n",
      "Epoch 429/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 4159546.8182\n",
      "Epoch 430/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 4469580.0909\n",
      "Epoch 431/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 4990603.2727\n",
      "Epoch 432/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 4564225.4091\n",
      "Epoch 433/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3864748.2955\n",
      "Epoch 434/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4408872.0227\n",
      "Epoch 435/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 4440618.4318\n",
      "Epoch 436/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 4342310.9773\n",
      "Epoch 437/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3892552.4545\n",
      "Epoch 438/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 4600420.5682\n",
      "Epoch 439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 148us/step - loss: 4183829.2500\n",
      "Epoch 440/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4473884.3409\n",
      "Epoch 441/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4147596.0000\n",
      "Epoch 442/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4078261.2500\n",
      "Epoch 443/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4859910.0227\n",
      "Epoch 444/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3687508.0000\n",
      "Epoch 445/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4461012.6761\n",
      "Epoch 446/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 4543501.6591\n",
      "Epoch 447/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4411093.4091\n",
      "Epoch 448/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3734774.7500\n",
      "Epoch 449/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4510498.5795\n",
      "Epoch 450/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3701521.7500\n",
      "Epoch 451/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3659187.1705\n",
      "Epoch 452/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4714586.3864\n",
      "Epoch 453/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 4381747.7273\n",
      "Epoch 454/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3863541.9432\n",
      "Epoch 455/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4003261.4886\n",
      "Epoch 456/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3240346.6023\n",
      "Epoch 457/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4320411.5568\n",
      "Epoch 458/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4251784.9318\n",
      "Epoch 459/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 4075329.4318\n",
      "Epoch 460/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3816833.8864\n",
      "Epoch 461/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 4643863.4205\n",
      "Epoch 462/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4470361.4545\n",
      "Epoch 463/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4621078.2500\n",
      "Epoch 464/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3599148.3864\n",
      "Epoch 465/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4176986.8409\n",
      "Epoch 466/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4127045.4318\n",
      "Epoch 467/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 4245507.8864\n",
      "Epoch 468/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 4350582.0227\n",
      "Epoch 469/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4126564.7273\n",
      "Epoch 470/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 4052245.4545\n",
      "Epoch 471/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4126573.4318\n",
      "Epoch 472/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3843453.1364\n",
      "Epoch 473/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 4046457.0000\n",
      "Epoch 474/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3752652.2955\n",
      "Epoch 475/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4036655.5000\n",
      "Epoch 476/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3637552.0909\n",
      "Epoch 477/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3763308.2727\n",
      "Epoch 478/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3805481.0455\n",
      "Epoch 479/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3894250.7841\n",
      "Epoch 480/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4496391.6136\n",
      "Epoch 481/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4750778.5455\n",
      "Epoch 482/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4144237.2841\n",
      "Epoch 483/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4334990.5909\n",
      "Epoch 484/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 4134525.7273\n",
      "Epoch 485/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3551104.2614\n",
      "Epoch 486/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4522989.8409\n",
      "Epoch 487/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3924723.2273\n",
      "Epoch 488/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 4001461.8864\n",
      "Epoch 489/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4235485.1818\n",
      "Epoch 490/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 4058661.5227\n",
      "Epoch 491/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3540540.7727\n",
      "Epoch 492/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3950593.6023\n",
      "Epoch 493/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 4125755.2045\n",
      "Epoch 494/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4371954.9432\n",
      "Epoch 495/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3610793.7500\n",
      "Epoch 496/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4655320.2500\n",
      "Epoch 497/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3746272.0455\n",
      "Epoch 498/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 4788012.0000\n",
      "Epoch 499/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3360861.7841\n",
      "Epoch 500/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3426538.1193\n",
      "Epoch 501/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3920315.0682\n",
      "Epoch 502/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3830606.1136\n",
      "Epoch 503/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3897665.5114\n",
      "Epoch 504/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3986970.0227\n",
      "Epoch 505/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4152386.7273\n",
      "Epoch 506/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4263653.7273\n",
      "Epoch 507/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3899206.3409\n",
      "Epoch 508/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3790550.9886\n",
      "Epoch 509/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3526065.3636\n",
      "Epoch 510/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4175654.9318\n",
      "Epoch 511/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4120531.2727\n",
      "Epoch 512/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3367474.7727\n",
      "Epoch 513/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3959655.3409\n",
      "Epoch 514/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4275055.4091\n",
      "Epoch 515/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3636313.0000\n",
      "Epoch 516/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3782419.5682\n",
      "Epoch 517/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3590155.3636\n",
      "Epoch 518/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4055128.0909\n",
      "Epoch 519/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3910630.7500\n",
      "Epoch 520/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3497645.8977\n",
      "Epoch 521/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4247617.5227\n",
      "Epoch 522/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 4084286.3068\n",
      "Epoch 523/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4019466.2273\n",
      "Epoch 524/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3317802.5455\n",
      "Epoch 525/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4317667.1364\n",
      "Epoch 526/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3367312.6705\n",
      "Epoch 527/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3968857.9091\n",
      "Epoch 528/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3575766.0000\n",
      "Epoch 529/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3506162.0795\n",
      "Epoch 530/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3408686.1364\n",
      "Epoch 531/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3673131.7273\n",
      "Epoch 532/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 4004780.7273\n",
      "Epoch 533/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3867490.0682\n",
      "Epoch 534/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4650508.6136\n",
      "Epoch 535/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4471711.6591\n",
      "Epoch 536/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4017473.7955\n",
      "Epoch 537/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3512323.5455\n",
      "Epoch 538/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4139848.5909\n",
      "Epoch 539/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 4186393.6136\n",
      "Epoch 540/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3504221.1364\n",
      "Epoch 541/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 4064015.1364\n",
      "Epoch 542/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3718625.2727\n",
      "Epoch 543/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3451046.0795\n",
      "Epoch 544/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4508486.6818\n",
      "Epoch 545/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3695496.8864\n",
      "Epoch 546/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3769967.3977\n",
      "Epoch 547/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3714526.2727\n",
      "Epoch 548/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 4248399.6705\n",
      "Epoch 549/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3640878.9318\n",
      "Epoch 550/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3778171.1932\n",
      "Epoch 551/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3696891.1591\n",
      "Epoch 552/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4206111.1818\n",
      "Epoch 553/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3793634.7500\n",
      "Epoch 554/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3512262.0455\n",
      "Epoch 555/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3476515.4545\n",
      "Epoch 556/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4689184.1591\n",
      "Epoch 557/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3916909.6023\n",
      "Epoch 558/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3958261.8409\n",
      "Epoch 559/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3800142.0682\n",
      "Epoch 560/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3936207.5682\n",
      "Epoch 561/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3778865.6307\n",
      "Epoch 562/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3617591.1818\n",
      "Epoch 563/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4531608.2727\n",
      "Epoch 564/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4194963.7045\n",
      "Epoch 565/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4386815.6818\n",
      "Epoch 566/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3771503.5682\n",
      "Epoch 567/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3920409.8864\n",
      "Epoch 568/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3353478.4318\n",
      "Epoch 569/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3698675.5000\n",
      "Epoch 570/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3856157.7955\n",
      "Epoch 571/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3771719.1591\n",
      "Epoch 572/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3693025.1250\n",
      "Epoch 573/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3716511.5000\n",
      "Epoch 574/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4012548.5000\n",
      "Epoch 575/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3784086.9773\n",
      "Epoch 576/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3077503.1250\n",
      "Epoch 577/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3434221.6364\n",
      "Epoch 578/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3233743.6477\n",
      "Epoch 579/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4412166.9773\n",
      "Epoch 580/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4054500.9773\n",
      "Epoch 581/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3831163.5909\n",
      "Epoch 582/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3322241.5000\n",
      "Epoch 583/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3900006.7955\n",
      "Epoch 584/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3878507.4091\n",
      "Epoch 585/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3948319.0909\n",
      "Epoch 586/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3672952.2045\n",
      "Epoch 587/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3294946.7273\n",
      "Epoch 588/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3912041.6364\n",
      "Epoch 589/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 4170853.0682\n",
      "Epoch 590/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3719714.4148\n",
      "Epoch 591/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3923886.2614\n",
      "Epoch 592/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3360274.2045\n",
      "Epoch 593/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3395817.4432\n",
      "Epoch 594/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 4488409.8864\n",
      "Epoch 595/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4356889.3977\n",
      "Epoch 596/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3363558.0682\n",
      "Epoch 597/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3474608.5227\n",
      "Epoch 598/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 4404657.0000\n",
      "Epoch 599/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4217029.2386\n",
      "Epoch 600/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 4289266.2273\n",
      "Epoch 601/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3763877.2727\n",
      "Epoch 602/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3897936.4432\n",
      "Epoch 603/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3877649.5000\n",
      "Epoch 604/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4458847.9886\n",
      "Epoch 605/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3657030.3636\n",
      "Epoch 606/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3637702.2727\n",
      "Epoch 607/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 4062387.7273\n",
      "Epoch 608/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4327429.5000\n",
      "Epoch 609/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4803614.6591\n",
      "Epoch 610/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4019774.5000\n",
      "Epoch 611/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3908733.7500\n",
      "Epoch 612/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3320944.9545\n",
      "Epoch 613/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3903405.7727\n",
      "Epoch 614/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3118055.4432\n",
      "Epoch 615/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 218us/step - loss: 4311439.2841\n",
      "Epoch 616/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 4190878.3409\n",
      "Epoch 617/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3895304.2727\n",
      "Epoch 618/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3999765.4659\n",
      "Epoch 619/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3457472.4318\n",
      "Epoch 620/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4093663.6364\n",
      "Epoch 621/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4007417.9773\n",
      "Epoch 622/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3952162.1136\n",
      "Epoch 623/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3641482.2727\n",
      "Epoch 624/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3750130.0455\n",
      "Epoch 625/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3418093.8182\n",
      "Epoch 626/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3418020.9205\n",
      "Epoch 627/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3908600.5000\n",
      "Epoch 628/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4142395.2273\n",
      "Epoch 629/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3286869.6818\n",
      "Epoch 630/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3409918.7500\n",
      "Epoch 631/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3627884.4091\n",
      "Epoch 632/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3463428.1364\n",
      "Epoch 633/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4242784.7727\n",
      "Epoch 634/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3237404.1364\n",
      "Epoch 635/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4146221.0682\n",
      "Epoch 636/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3620513.7500\n",
      "Epoch 637/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3199689.5568\n",
      "Epoch 638/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3401677.4318\n",
      "Epoch 639/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3262955.0568\n",
      "Epoch 640/2000\n",
      "176/176 [==============================] - 0s 379us/step - loss: 4311234.7955\n",
      "Epoch 641/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3811349.6818\n",
      "Epoch 642/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3302013.4545\n",
      "Epoch 643/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3445049.8068\n",
      "Epoch 644/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3323886.7727\n",
      "Epoch 645/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4312650.8409\n",
      "Epoch 646/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4792638.3864\n",
      "Epoch 647/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3321978.8409\n",
      "Epoch 648/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3554687.6477\n",
      "Epoch 649/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3826944.2045\n",
      "Epoch 650/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3948533.2273\n",
      "Epoch 651/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3621365.8409\n",
      "Epoch 652/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 2871772.9773\n",
      "Epoch 653/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4001485.3864\n",
      "Epoch 654/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3244847.8295\n",
      "Epoch 655/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3246209.1023\n",
      "Epoch 656/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3731305.9091\n",
      "Epoch 657/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3760653.3864\n",
      "Epoch 658/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 4207949.1136\n",
      "Epoch 659/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4263658.0682\n",
      "Epoch 660/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4483750.2273\n",
      "Epoch 661/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3524500.8750\n",
      "Epoch 662/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4396705.6364\n",
      "Epoch 663/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3921238.3864\n",
      "Epoch 664/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3967247.5909\n",
      "Epoch 665/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3540234.0455\n",
      "Epoch 666/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4116819.4205\n",
      "Epoch 667/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3927953.2614\n",
      "Epoch 668/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3846674.4545\n",
      "Epoch 669/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3681761.5227\n",
      "Epoch 670/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3619149.0000\n",
      "Epoch 671/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 4019575.9545\n",
      "Epoch 672/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3510446.6023\n",
      "Epoch 673/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3385039.4773\n",
      "Epoch 674/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3398289.2500\n",
      "Epoch 675/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2732837.5682\n",
      "Epoch 676/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3281699.5114\n",
      "Epoch 677/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4096977.3295\n",
      "Epoch 678/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3641297.6705\n",
      "Epoch 679/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3426262.1591\n",
      "Epoch 680/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3813345.8864\n",
      "Epoch 681/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3846775.2727\n",
      "Epoch 682/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3963551.2727\n",
      "Epoch 683/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3644756.3864\n",
      "Epoch 684/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3829235.6364\n",
      "Epoch 685/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3541211.6818\n",
      "Epoch 686/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3906499.2273\n",
      "Epoch 687/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 1649013.500 - 0s 203us/step - loss: 3724688.7386\n",
      "Epoch 688/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3253232.9432\n",
      "Epoch 689/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3480142.3409\n",
      "Epoch 690/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3687445.9545\n",
      "Epoch 691/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3825158.0341\n",
      "Epoch 692/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3839984.8864\n",
      "Epoch 693/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3367546.9318\n",
      "Epoch 694/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 4335472.1136\n",
      "Epoch 695/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3835567.7614\n",
      "Epoch 696/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3020608.7159\n",
      "Epoch 697/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3966299.7727\n",
      "Epoch 698/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3317703.6364\n",
      "Epoch 699/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3356779.0227\n",
      "Epoch 700/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 3909259.5682\n",
      "Epoch 701/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 3627156.9091\n",
      "Epoch 702/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3317076.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3829112.8409\n",
      "Epoch 704/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4099029.5227\n",
      "Epoch 705/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3899646.6364\n",
      "Epoch 706/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3681059.6705\n",
      "Epoch 707/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3114540.3750\n",
      "Epoch 708/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4045572.0682\n",
      "Epoch 709/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 4376511.6818\n",
      "Epoch 710/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3316642.3295\n",
      "Epoch 711/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3657267.5682\n",
      "Epoch 712/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3611100.0000\n",
      "Epoch 713/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4013925.4091\n",
      "Epoch 714/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 4004256.0227\n",
      "Epoch 715/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3183858.3409\n",
      "Epoch 716/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3761585.5227\n",
      "Epoch 717/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3762278.0455\n",
      "Epoch 718/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3949586.9205\n",
      "Epoch 719/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3271904.1932\n",
      "Epoch 720/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3331886.4545\n",
      "Epoch 721/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3417699.6136\n",
      "Epoch 722/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 4450676.1818\n",
      "Epoch 723/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4023414.7955\n",
      "Epoch 724/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3791082.0000\n",
      "Epoch 725/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3199417.5000\n",
      "Epoch 726/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3900727.2045\n",
      "Epoch 727/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3647031.5455\n",
      "Epoch 728/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3312236.0455\n",
      "Epoch 729/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4077390.2045\n",
      "Epoch 730/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3930058.1420\n",
      "Epoch 731/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4474987.7045\n",
      "Epoch 732/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3737754.0341\n",
      "Epoch 733/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4162390.5455\n",
      "Epoch 734/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3839387.5227\n",
      "Epoch 735/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3290819.7614\n",
      "Epoch 736/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4122233.5000\n",
      "Epoch 737/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3681244.5909\n",
      "Epoch 738/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3431709.3409\n",
      "Epoch 739/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4417957.6136\n",
      "Epoch 740/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3435041.6136\n",
      "Epoch 741/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3703655.8409\n",
      "Epoch 742/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3197529.4659\n",
      "Epoch 743/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3091266.3636\n",
      "Epoch 744/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3707187.8523\n",
      "Epoch 745/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3592133.0000\n",
      "Epoch 746/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3987362.0909\n",
      "Epoch 747/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4108407.1250\n",
      "Epoch 748/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3794254.4091\n",
      "Epoch 749/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4616502.0568\n",
      "Epoch 750/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3812915.9205\n",
      "Epoch 751/2000\n",
      "176/176 [==============================] - 0s 134us/step - loss: 3653160.2273\n",
      "Epoch 752/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3355131.7159\n",
      "Epoch 753/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3705004.9886\n",
      "Epoch 754/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3596548.2159\n",
      "Epoch 755/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3799978.6818\n",
      "Epoch 756/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3935655.0000\n",
      "Epoch 757/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3869786.2500\n",
      "Epoch 758/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 4782687.5227\n",
      "Epoch 759/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 4185077.1136\n",
      "Epoch 760/2000\n",
      "176/176 [==============================] - 0s 401us/step - loss: 3694767.2045\n",
      "Epoch 761/2000\n",
      "176/176 [==============================] - 0s 252us/step - loss: 3334588.1818\n",
      "Epoch 762/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3446319.9886\n",
      "Epoch 763/2000\n",
      "176/176 [==============================] - 0s 285us/step - loss: 3325202.6818\n",
      "Epoch 764/2000\n",
      "176/176 [==============================] - 0s 327us/step - loss: 4361028.2955\n",
      "Epoch 765/2000\n",
      "176/176 [==============================] - 0s 379us/step - loss: 4023617.8182\n",
      "Epoch 766/2000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 3577824.5341\n",
      "Epoch 767/2000\n",
      "176/176 [==============================] - 0s 373us/step - loss: 2871120.0909\n",
      "Epoch 768/2000\n",
      "176/176 [==============================] - 0s 372us/step - loss: 4136747.3636\n",
      "Epoch 769/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 3761284.0114\n",
      "Epoch 770/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 4100060.1477\n",
      "Epoch 771/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 3542633.2159\n",
      "Epoch 772/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3635748.8409\n",
      "Epoch 773/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3426850.1364\n",
      "Epoch 774/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3154225.3977\n",
      "Epoch 775/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3982371.0227\n",
      "Epoch 776/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 4285702.4659\n",
      "Epoch 777/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3881096.0000\n",
      "Epoch 778/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4007593.2727\n",
      "Epoch 779/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3677940.0795\n",
      "Epoch 780/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3279047.2273\n",
      "Epoch 781/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3957793.6705\n",
      "Epoch 782/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3869738.8409\n",
      "Epoch 783/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3599064.0114\n",
      "Epoch 784/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3876512.2727\n",
      "Epoch 785/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3498200.0682\n",
      "Epoch 786/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4328060.2955\n",
      "Epoch 787/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3618181.6364\n",
      "Epoch 788/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4333625.2273\n",
      "Epoch 789/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4294479.5455\n",
      "Epoch 790/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3669863.4545\n",
      "Epoch 791/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 188us/step - loss: 3620071.8864\n",
      "Epoch 792/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3619617.6932\n",
      "Epoch 793/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3746313.2273\n",
      "Epoch 794/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3544527.1023\n",
      "Epoch 795/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3553135.2841\n",
      "Epoch 796/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3370137.3977\n",
      "Epoch 797/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3377567.0000\n",
      "Epoch 798/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4411685.1477\n",
      "Epoch 799/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3822873.2955\n",
      "Epoch 800/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3971879.2955\n",
      "Epoch 801/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3355781.2727\n",
      "Epoch 802/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 4016164.0227\n",
      "Epoch 803/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3920986.0682\n",
      "Epoch 804/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 4270972.0455\n",
      "Epoch 805/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3654222.1591\n",
      "Epoch 806/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3600241.8409\n",
      "Epoch 807/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3605325.9886\n",
      "Epoch 808/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4271128.5455\n",
      "Epoch 809/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3717490.6818\n",
      "Epoch 810/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3241497.9773\n",
      "Epoch 811/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4140131.4545\n",
      "Epoch 812/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3601659.5341\n",
      "Epoch 813/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3761694.0909\n",
      "Epoch 814/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3734694.4773\n",
      "Epoch 815/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3465583.7955\n",
      "Epoch 816/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3900440.2727\n",
      "Epoch 817/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3856393.9659\n",
      "Epoch 818/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3643479.3523\n",
      "Epoch 819/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4187060.2727\n",
      "Epoch 820/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3799662.7955\n",
      "Epoch 821/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3857243.1818\n",
      "Epoch 822/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4207839.4091\n",
      "Epoch 823/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3417553.3977\n",
      "Epoch 824/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3451747.4773\n",
      "Epoch 825/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3409115.7955\n",
      "Epoch 826/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4219521.7500\n",
      "Epoch 827/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 4168328.5000\n",
      "Epoch 828/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3402924.2386\n",
      "Epoch 829/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3897557.7500\n",
      "Epoch 830/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3614598.3864\n",
      "Epoch 831/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3461685.3295\n",
      "Epoch 832/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4001962.9318\n",
      "Epoch 833/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3627717.4318\n",
      "Epoch 834/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 4110794.2273\n",
      "Epoch 835/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3828832.7841\n",
      "Epoch 836/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3668018.4318\n",
      "Epoch 837/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3595496.6705\n",
      "Epoch 838/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3302874.8409\n",
      "Epoch 839/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3395733.3409\n",
      "Epoch 840/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4057140.4318\n",
      "Epoch 841/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3624380.2727\n",
      "Epoch 842/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3927932.9545\n",
      "Epoch 843/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3571873.6705\n",
      "Epoch 844/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 4366968.9432\n",
      "Epoch 845/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 2990861.3977\n",
      "Epoch 846/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3498679.3864\n",
      "Epoch 847/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3495987.5000\n",
      "Epoch 848/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3573268.5909\n",
      "Epoch 849/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3213149.6136\n",
      "Epoch 850/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3057734.1023\n",
      "Epoch 851/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3588174.0455\n",
      "Epoch 852/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3676252.3295\n",
      "Epoch 853/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3771312.7386\n",
      "Epoch 854/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3530774.6705\n",
      "Epoch 855/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3941010.7727\n",
      "Epoch 856/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3212683.1477\n",
      "Epoch 857/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3581800.4545\n",
      "Epoch 858/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3437657.8864\n",
      "Epoch 859/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3303779.2727\n",
      "Epoch 860/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4448473.1136\n",
      "Epoch 861/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3812532.7727\n",
      "Epoch 862/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3673142.7045\n",
      "Epoch 863/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 4297384.3068\n",
      "Epoch 864/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4274414.3409\n",
      "Epoch 865/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3205677.9205\n",
      "Epoch 866/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3563831.4318\n",
      "Epoch 867/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2973626.2159\n",
      "Epoch 868/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3144005.2614\n",
      "Epoch 869/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3741835.7045\n",
      "Epoch 870/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3695968.1364\n",
      "Epoch 871/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3399981.6136\n",
      "Epoch 872/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3019189.7386\n",
      "Epoch 873/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3293140.8750\n",
      "Epoch 874/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3023501.6591\n",
      "Epoch 875/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4083474.8636\n",
      "Epoch 876/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3693737.5455\n",
      "Epoch 877/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3616354.0227\n",
      "Epoch 878/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3198005.7273\n",
      "Epoch 879/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3481102.3864\n",
      "Epoch 880/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3162900.0227\n",
      "Epoch 881/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3310648.2386\n",
      "Epoch 882/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3946377.4545\n",
      "Epoch 883/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3658037.3068\n",
      "Epoch 884/2000\n",
      "176/176 [==============================] - 0s 139us/step - loss: 3709927.7727\n",
      "Epoch 885/2000\n",
      "176/176 [==============================] - 0s 133us/step - loss: 3418565.2727\n",
      "Epoch 886/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 4455003.7500\n",
      "Epoch 887/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3860309.1932\n",
      "Epoch 888/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3520076.0341\n",
      "Epoch 889/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3310432.2273\n",
      "Epoch 890/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3288664.0000\n",
      "Epoch 891/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3541954.3864\n",
      "Epoch 892/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3637515.9545\n",
      "Epoch 893/2000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 3292115.4545\n",
      "Epoch 894/2000\n",
      "176/176 [==============================] - 0s 407us/step - loss: 3228063.3068\n",
      "Epoch 895/2000\n",
      "176/176 [==============================] - 0s 402us/step - loss: 4160427.4205\n",
      "Epoch 896/2000\n",
      "176/176 [==============================] - 0s 381us/step - loss: 3364898.8182\n",
      "Epoch 897/2000\n",
      "176/176 [==============================] - 0s 380us/step - loss: 4236847.3523\n",
      "Epoch 898/2000\n",
      "176/176 [==============================] - 0s 361us/step - loss: 3111314.6591\n",
      "Epoch 899/2000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 3839227.9659\n",
      "Epoch 900/2000\n",
      "176/176 [==============================] - 0s 412us/step - loss: 3627995.8182\n",
      "Epoch 901/2000\n",
      "176/176 [==============================] - 0s 409us/step - loss: 3311565.4545\n",
      "Epoch 902/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3350695.2727\n",
      "Epoch 903/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3476672.4545\n",
      "Epoch 904/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3645864.7955\n",
      "Epoch 905/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3378348.6250\n",
      "Epoch 906/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4205226.8409\n",
      "Epoch 907/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3601272.8295\n",
      "Epoch 908/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3805206.3864\n",
      "Epoch 909/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3581009.3636\n",
      "Epoch 910/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3875193.1705\n",
      "Epoch 911/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3452752.5000\n",
      "Epoch 912/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3733977.8409\n",
      "Epoch 913/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4260809.0455\n",
      "Epoch 914/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3728492.4545\n",
      "Epoch 915/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3279974.1023\n",
      "Epoch 916/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3484462.0000\n",
      "Epoch 917/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3316802.5000\n",
      "Epoch 918/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3550654.5000\n",
      "Epoch 919/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3619910.2727\n",
      "Epoch 920/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3348243.5227\n",
      "Epoch 921/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 4117094.5227\n",
      "Epoch 922/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4053354.1364\n",
      "Epoch 923/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3178947.2500\n",
      "Epoch 924/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3983709.1136\n",
      "Epoch 925/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3715390.9318\n",
      "Epoch 926/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3311122.5455\n",
      "Epoch 927/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3232582.1591\n",
      "Epoch 928/2000\n",
      "176/176 [==============================] - 0s 142us/step - loss: 3763981.9545\n",
      "Epoch 929/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3483949.7955\n",
      "Epoch 930/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 4294758.4318\n",
      "Epoch 931/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3640217.5227\n",
      "Epoch 932/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3432209.3864\n",
      "Epoch 933/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4375697.6591\n",
      "Epoch 934/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3314314.4545\n",
      "Epoch 935/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3866940.0114\n",
      "Epoch 936/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3956450.6364\n",
      "Epoch 937/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3598891.6136\n",
      "Epoch 938/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 2984536.6023\n",
      "Epoch 939/2000\n",
      "176/176 [==============================] - 0s 137us/step - loss: 3367406.4773\n",
      "Epoch 940/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3247171.4318\n",
      "Epoch 941/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 4285004.7045\n",
      "Epoch 942/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3007955.0682\n",
      "Epoch 943/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3297968.1705\n",
      "Epoch 944/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3467328.6932\n",
      "Epoch 945/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4128068.3409\n",
      "Epoch 946/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3474145.1591\n",
      "Epoch 947/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3921723.7273\n",
      "Epoch 948/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3296621.6023\n",
      "Epoch 949/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3606244.0000\n",
      "Epoch 950/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3443423.4545\n",
      "Epoch 951/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3825097.8580\n",
      "Epoch 952/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3705327.6591\n",
      "Epoch 953/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3646623.5227\n",
      "Epoch 954/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3037002.4659\n",
      "Epoch 955/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3641548.1818\n",
      "Epoch 956/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3371940.6364\n",
      "Epoch 957/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3788011.8864\n",
      "Epoch 958/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3553716.9205\n",
      "Epoch 959/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3382251.5227\n",
      "Epoch 960/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3966276.1364\n",
      "Epoch 961/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3756240.0227\n",
      "Epoch 962/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3334586.7614\n",
      "Epoch 963/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3264247.8636\n",
      "Epoch 964/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3969588.4659\n",
      "Epoch 965/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4137763.1591\n",
      "Epoch 966/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3877052.5455\n",
      "Epoch 967/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 190us/step - loss: 3507204.6818\n",
      "Epoch 968/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3266695.0341\n",
      "Epoch 969/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3775120.1250\n",
      "Epoch 970/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4502502.3182\n",
      "Epoch 971/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3864383.3977\n",
      "Epoch 972/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4171961.7273\n",
      "Epoch 973/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3484144.0455\n",
      "Epoch 974/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4915450.3977\n",
      "Epoch 975/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3407721.2045\n",
      "Epoch 976/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3893013.3409\n",
      "Epoch 977/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3325411.8295\n",
      "Epoch 978/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 4556952.5455\n",
      "Epoch 979/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4032868.9432\n",
      "Epoch 980/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3220531.0682\n",
      "Epoch 981/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3275627.5000\n",
      "Epoch 982/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3947959.0682\n",
      "Epoch 983/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3964451.6477\n",
      "Epoch 984/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3433469.1136\n",
      "Epoch 985/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 4052201.1364\n",
      "Epoch 986/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3671583.7500\n",
      "Epoch 987/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3674813.8409\n",
      "Epoch 988/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3504319.0795\n",
      "Epoch 989/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3373128.9773\n",
      "Epoch 990/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3585478.6591\n",
      "Epoch 991/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3570382.4318\n",
      "Epoch 992/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3150432.7727\n",
      "Epoch 993/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3261737.9886\n",
      "Epoch 994/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3708326.9318\n",
      "Epoch 995/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3699773.3409\n",
      "Epoch 996/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 3539239.5227\n",
      "Epoch 997/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4099904.2614\n",
      "Epoch 998/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3886604.1477\n",
      "Epoch 999/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 3029654.2216\n",
      "Epoch 1000/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3947983.4205\n",
      "Epoch 1001/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3913955.8636\n",
      "Epoch 1002/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3185657.7045\n",
      "Epoch 1003/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3145174.9545\n",
      "Epoch 1004/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3901879.8409\n",
      "Epoch 1005/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3776489.0341\n",
      "Epoch 1006/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3765264.4318\n",
      "Epoch 1007/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3319705.4091\n",
      "Epoch 1008/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3964949.7273\n",
      "Epoch 1009/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3375546.7727\n",
      "Epoch 1010/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3382634.1932\n",
      "Epoch 1011/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4182284.2273\n",
      "Epoch 1012/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3630413.5341\n",
      "Epoch 1013/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4136157.2273\n",
      "Epoch 1014/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4139054.3409\n",
      "Epoch 1015/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3685452.4091\n",
      "Epoch 1016/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3239229.3977\n",
      "Epoch 1017/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4177325.5455\n",
      "Epoch 1018/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3956070.5682\n",
      "Epoch 1019/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 3177805.6023\n",
      "Epoch 1020/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3936502.4773\n",
      "Epoch 1021/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 2908911.8068\n",
      "Epoch 1022/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3085336.3409\n",
      "Epoch 1023/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3298386.6023\n",
      "Epoch 1024/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3711416.2955\n",
      "Epoch 1025/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3496224.0455\n",
      "Epoch 1026/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4198474.9545\n",
      "Epoch 1027/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3623731.9886\n",
      "Epoch 1028/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3988503.1364\n",
      "Epoch 1029/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3815716.6591\n",
      "Epoch 1030/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3584446.7045\n",
      "Epoch 1031/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3443707.1818\n",
      "Epoch 1032/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3830062.0682\n",
      "Epoch 1033/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 3508544.1932\n",
      "Epoch 1034/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 3184197.1932\n",
      "Epoch 1035/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3909143.9545\n",
      "Epoch 1036/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4002109.1023\n",
      "Epoch 1037/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3701500.3864\n",
      "Epoch 1038/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3919993.2273\n",
      "Epoch 1039/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3197610.3750\n",
      "Epoch 1040/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3416822.7500\n",
      "Epoch 1041/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3261874.4773\n",
      "Epoch 1042/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 2933795.8182\n",
      "Epoch 1043/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3620809.7159\n",
      "Epoch 1044/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3805022.9773\n",
      "Epoch 1045/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3236951.2273\n",
      "Epoch 1046/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3338512.6023\n",
      "Epoch 1047/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3676713.2500\n",
      "Epoch 1048/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3347855.6250\n",
      "Epoch 1049/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4080065.4545\n",
      "Epoch 1050/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3913193.7045\n",
      "Epoch 1051/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3514633.9318\n",
      "Epoch 1052/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3671064.3523\n",
      "Epoch 1053/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 4404513.0909\n",
      "Epoch 1054/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3158141.6023\n",
      "Epoch 1055/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3990795.0455\n",
      "Epoch 1056/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4558396.5455\n",
      "Epoch 1057/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3947091.2727\n",
      "Epoch 1058/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3645474.5227\n",
      "Epoch 1059/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3327750.2841\n",
      "Epoch 1060/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3756192.0455\n",
      "Epoch 1061/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3613221.0341\n",
      "Epoch 1062/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4028244.5000\n",
      "Epoch 1063/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3620797.5227\n",
      "Epoch 1064/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3059058.6364\n",
      "Epoch 1065/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4144056.0000\n",
      "Epoch 1066/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3344142.1364\n",
      "Epoch 1067/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3424125.5455\n",
      "Epoch 1068/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3728839.4318\n",
      "Epoch 1069/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3779286.1591\n",
      "Epoch 1070/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4230967.4318\n",
      "Epoch 1071/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3308915.3864\n",
      "Epoch 1072/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3054958.2955\n",
      "Epoch 1073/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3781673.8977\n",
      "Epoch 1074/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3931212.4545\n",
      "Epoch 1075/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4075239.5682\n",
      "Epoch 1076/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4112989.8068\n",
      "Epoch 1077/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3560655.5909\n",
      "Epoch 1078/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3442712.5455\n",
      "Epoch 1079/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3043354.3352\n",
      "Epoch 1080/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3745026.1136\n",
      "Epoch 1081/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3689170.8182\n",
      "Epoch 1082/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 4040195.2727\n",
      "Epoch 1083/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3428131.3977\n",
      "Epoch 1084/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3364077.6477\n",
      "Epoch 1085/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3453932.7500\n",
      "Epoch 1086/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3415359.0227\n",
      "Epoch 1087/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2821799.5568\n",
      "Epoch 1088/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3679939.5341\n",
      "Epoch 1089/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3499856.1136\n",
      "Epoch 1090/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3789859.1591\n",
      "Epoch 1091/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 4603552.8864\n",
      "Epoch 1092/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3662262.9091\n",
      "Epoch 1093/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3108203.5739\n",
      "Epoch 1094/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 4059468.5909\n",
      "Epoch 1095/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3351505.7955\n",
      "Epoch 1096/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3637973.3750\n",
      "Epoch 1097/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3709037.0227\n",
      "Epoch 1098/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3555237.3864\n",
      "Epoch 1099/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3455385.8409\n",
      "Epoch 1100/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3773292.0455\n",
      "Epoch 1101/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3717818.2045\n",
      "Epoch 1102/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 3420253.7045\n",
      "Epoch 1103/2000\n",
      "176/176 [==============================] - 0s 123us/step - loss: 3806945.6705\n",
      "Epoch 1104/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3986444.6818\n",
      "Epoch 1105/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3993419.2273\n",
      "Epoch 1106/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3558103.8409\n",
      "Epoch 1107/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2890024.6023\n",
      "Epoch 1108/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3853270.9545\n",
      "Epoch 1109/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3216635.9545\n",
      "Epoch 1110/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3645358.2955\n",
      "Epoch 1111/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3734941.8864\n",
      "Epoch 1112/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3554290.9545\n",
      "Epoch 1113/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 3188582.7045\n",
      "Epoch 1114/2000\n",
      "176/176 [==============================] - 0s 137us/step - loss: 3201149.6477\n",
      "Epoch 1115/2000\n",
      "176/176 [==============================] - 0s 152us/step - loss: 3557838.0000\n",
      "Epoch 1116/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3386500.1250\n",
      "Epoch 1117/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3946953.1250\n",
      "Epoch 1118/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3379794.0341\n",
      "Epoch 1119/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3836658.3182\n",
      "Epoch 1120/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3505501.8977\n",
      "Epoch 1121/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3659829.6932\n",
      "Epoch 1122/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3227762.3750\n",
      "Epoch 1123/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 4058663.3636\n",
      "Epoch 1124/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3688949.9318\n",
      "Epoch 1125/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4048253.0682\n",
      "Epoch 1126/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3662347.6080\n",
      "Epoch 1127/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3941918.1818\n",
      "Epoch 1128/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 4320394.1364\n",
      "Epoch 1129/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3361304.8750\n",
      "Epoch 1130/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3378281.0227\n",
      "Epoch 1131/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3769542.6477\n",
      "Epoch 1132/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3820722.5909\n",
      "Epoch 1133/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3800243.8182\n",
      "Epoch 1134/2000\n",
      "176/176 [==============================] - 0s 127us/step - loss: 2899188.2159\n",
      "Epoch 1135/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3960211.9773\n",
      "Epoch 1136/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 4039462.8409\n",
      "Epoch 1137/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3349978.1364\n",
      "Epoch 1138/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3674456.5909\n",
      "Epoch 1139/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3039207.1818\n",
      "Epoch 1140/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3595571.2500\n",
      "Epoch 1141/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 203us/step - loss: 3666180.4091\n",
      "Epoch 1142/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3858840.0455\n",
      "Epoch 1143/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 4074820.8750\n",
      "Epoch 1144/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3603555.8636\n",
      "Epoch 1145/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3823799.5000\n",
      "Epoch 1146/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3726243.6364\n",
      "Epoch 1147/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3925928.5909\n",
      "Epoch 1148/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4656351.4773\n",
      "Epoch 1149/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3563686.9773\n",
      "Epoch 1150/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3283261.6591\n",
      "Epoch 1151/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3422248.2727\n",
      "Epoch 1152/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3439968.6136\n",
      "Epoch 1153/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3428409.6136\n",
      "Epoch 1154/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3941459.0455\n",
      "Epoch 1155/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3569137.1364\n",
      "Epoch 1156/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4154458.9318\n",
      "Epoch 1157/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3849001.1818\n",
      "Epoch 1158/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3673003.7955\n",
      "Epoch 1159/2000\n",
      "176/176 [==============================] - 0s 255us/step - loss: 3449632.8182\n",
      "Epoch 1160/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3554292.0909\n",
      "Epoch 1161/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3701701.8523\n",
      "Epoch 1162/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3490337.4205\n",
      "Epoch 1163/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3742656.7898\n",
      "Epoch 1164/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3683367.1932\n",
      "Epoch 1165/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3392810.3068\n",
      "Epoch 1166/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3570200.7727\n",
      "Epoch 1167/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4666455.3864\n",
      "Epoch 1168/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3538988.1591\n",
      "Epoch 1169/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3361064.4091\n",
      "Epoch 1170/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3639349.9545\n",
      "Epoch 1171/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3541935.6705\n",
      "Epoch 1172/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3156250.8977\n",
      "Epoch 1173/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3046853.3182\n",
      "Epoch 1174/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3899088.4773\n",
      "Epoch 1175/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3770777.9773\n",
      "Epoch 1176/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4579292.2045\n",
      "Epoch 1177/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3336730.8182\n",
      "Epoch 1178/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3287538.2386\n",
      "Epoch 1179/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3848459.6591\n",
      "Epoch 1180/2000\n",
      "176/176 [==============================] - 0s 142us/step - loss: 3914775.4545\n",
      "Epoch 1181/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3658463.0568\n",
      "Epoch 1182/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3846169.9091\n",
      "Epoch 1183/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3163633.9716\n",
      "Epoch 1184/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3787792.4318\n",
      "Epoch 1185/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3144635.7386\n",
      "Epoch 1186/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3522821.0455\n",
      "Epoch 1187/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3629450.8182\n",
      "Epoch 1188/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3863154.5455\n",
      "Epoch 1189/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 2792049.5568\n",
      "Epoch 1190/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3362881.1477\n",
      "Epoch 1191/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 2964739.1136\n",
      "Epoch 1192/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3270689.5341\n",
      "Epoch 1193/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3055389.3182\n",
      "Epoch 1194/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4585564.5909\n",
      "Epoch 1195/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3506166.2159\n",
      "Epoch 1196/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3220334.7955\n",
      "Epoch 1197/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3465435.2386\n",
      "Epoch 1198/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3289116.2045\n",
      "Epoch 1199/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 2996064.3295\n",
      "Epoch 1200/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3177342.4318\n",
      "Epoch 1201/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 4526464.5000\n",
      "Epoch 1202/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3675807.1818\n",
      "Epoch 1203/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4461251.1818\n",
      "Epoch 1204/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3816297.6705\n",
      "Epoch 1205/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3632247.5511\n",
      "Epoch 1206/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3244839.1818\n",
      "Epoch 1207/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3234072.1250\n",
      "Epoch 1208/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3084946.7500\n",
      "Epoch 1209/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 2919188.6705\n",
      "Epoch 1210/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4204454.1705\n",
      "Epoch 1211/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 2973963.5455\n",
      "Epoch 1212/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3395141.6818\n",
      "Epoch 1213/2000\n",
      "176/176 [==============================] - 0s 368us/step - loss: 3785534.6818\n",
      "Epoch 1214/2000\n",
      "176/176 [==============================] - 0s 286us/step - loss: 3783120.3977\n",
      "Epoch 1215/2000\n",
      "176/176 [==============================] - 0s 340us/step - loss: 4136989.0000\n",
      "Epoch 1216/2000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 3311660.0114\n",
      "Epoch 1217/2000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 3723370.3295\n",
      "Epoch 1218/2000\n",
      "176/176 [==============================] - 0s 379us/step - loss: 3361387.3182\n",
      "Epoch 1219/2000\n",
      "176/176 [==============================] - 0s 376us/step - loss: 4351737.7955\n",
      "Epoch 1220/2000\n",
      "176/176 [==============================] - 0s 375us/step - loss: 3410883.0455\n",
      "Epoch 1221/2000\n",
      "176/176 [==============================] - 0s 324us/step - loss: 3786626.5909\n",
      "Epoch 1222/2000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 3467156.8864\n",
      "Epoch 1223/2000\n",
      "176/176 [==============================] - 0s 390us/step - loss: 3542480.8977\n",
      "Epoch 1224/2000\n",
      "176/176 [==============================] - 0s 422us/step - loss: 3746604.9432\n",
      "Epoch 1225/2000\n",
      "176/176 [==============================] - 0s 320us/step - loss: 3131112.5455\n",
      "Epoch 1226/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3722768.4886\n",
      "Epoch 1227/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3533090.1818\n",
      "Epoch 1228/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 3323579.1705\n",
      "Epoch 1229/2000\n",
      "176/176 [==============================] - 0s 267us/step - loss: 4150841.3977\n",
      "Epoch 1230/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3601348.4545\n",
      "Epoch 1231/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3891523.7955\n",
      "Epoch 1232/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3544913.2500\n",
      "Epoch 1233/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3582262.6477\n",
      "Epoch 1234/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 4116277.0682\n",
      "Epoch 1235/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3874383.3409\n",
      "Epoch 1236/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3434029.8977\n",
      "Epoch 1237/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 4269798.8977\n",
      "Epoch 1238/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 3504202.2500\n",
      "Epoch 1239/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 4311216.3864\n",
      "Epoch 1240/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3637578.8295\n",
      "Epoch 1241/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4523042.4091\n",
      "Epoch 1242/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3403626.7500\n",
      "Epoch 1243/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3377854.9773\n",
      "Epoch 1244/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3478897.0455\n",
      "Epoch 1245/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3675012.5568\n",
      "Epoch 1246/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3527619.2500\n",
      "Epoch 1247/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3569192.7045\n",
      "Epoch 1248/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3970294.1591\n",
      "Epoch 1249/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3930071.5909\n",
      "Epoch 1250/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3583077.0682\n",
      "Epoch 1251/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3515093.2273\n",
      "Epoch 1252/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3315090.5455\n",
      "Epoch 1253/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 4397323.4205\n",
      "Epoch 1254/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2894191.8409\n",
      "Epoch 1255/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3209933.7159\n",
      "Epoch 1256/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 4608046.3409\n",
      "Epoch 1257/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3370238.0455\n",
      "Epoch 1258/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3994775.4886\n",
      "Epoch 1259/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3604687.9318\n",
      "Epoch 1260/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 4023441.6818\n",
      "Epoch 1261/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3777112.5795\n",
      "Epoch 1262/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3660071.8182\n",
      "Epoch 1263/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2976519.4545\n",
      "Epoch 1264/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3245033.7614\n",
      "Epoch 1265/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3430926.0568\n",
      "Epoch 1266/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3389221.0682\n",
      "Epoch 1267/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3374760.6136\n",
      "Epoch 1268/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3759653.2159\n",
      "Epoch 1269/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3903703.3182\n",
      "Epoch 1270/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3598740.9318\n",
      "Epoch 1271/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3247333.8523\n",
      "Epoch 1272/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3671829.7273\n",
      "Epoch 1273/2000\n",
      "176/176 [==============================] - 0s 290us/step - loss: 4341260.6364\n",
      "Epoch 1274/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3508770.8182\n",
      "Epoch 1275/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3755258.6136\n",
      "Epoch 1276/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3854076.6591\n",
      "Epoch 1277/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 4330604.3409\n",
      "Epoch 1278/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 4206865.7273\n",
      "Epoch 1279/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3429975.8636\n",
      "Epoch 1280/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3335003.9773\n",
      "Epoch 1281/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 3627215.1591\n",
      "Epoch 1282/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 3869328.5114\n",
      "Epoch 1283/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3381090.4773\n",
      "Epoch 1284/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3731213.9318\n",
      "Epoch 1285/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 2825577.1591\n",
      "Epoch 1286/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 4391507.1136\n",
      "Epoch 1287/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 4191446.1591\n",
      "Epoch 1288/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3453817.1591\n",
      "Epoch 1289/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 4489988.6136\n",
      "Epoch 1290/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3302163.2159\n",
      "Epoch 1291/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3399599.8295\n",
      "Epoch 1292/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3259384.2841\n",
      "Epoch 1293/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3296203.1364\n",
      "Epoch 1294/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3293237.8295\n",
      "Epoch 1295/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3166601.9886\n",
      "Epoch 1296/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3424237.4205\n",
      "Epoch 1297/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3520981.2500\n",
      "Epoch 1298/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3449614.2614\n",
      "Epoch 1299/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3556996.5227\n",
      "Epoch 1300/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3891035.0455\n",
      "Epoch 1301/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3858396.7273\n",
      "Epoch 1302/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3184742.7614\n",
      "Epoch 1303/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3520857.1136\n",
      "Epoch 1304/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3844750.1818\n",
      "Epoch 1305/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3128896.9205\n",
      "Epoch 1306/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3013465.9773\n",
      "Epoch 1307/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3738094.9773\n",
      "Epoch 1308/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3666073.4432\n",
      "Epoch 1309/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3710134.4091\n",
      "Epoch 1310/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3328738.4318\n",
      "Epoch 1311/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4353954.0455\n",
      "Epoch 1312/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3973169.4091\n",
      "Epoch 1313/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2812131.8636\n",
      "Epoch 1314/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3678872.8182\n",
      "Epoch 1315/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 200us/step - loss: 3754893.3636\n",
      "Epoch 1316/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3510114.5455\n",
      "Epoch 1317/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3337530.5000\n",
      "Epoch 1318/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3816290.2500\n",
      "Epoch 1319/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3248673.4545\n",
      "Epoch 1320/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3489947.2045\n",
      "Epoch 1321/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3366085.3864\n",
      "Epoch 1322/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3551620.0682\n",
      "Epoch 1323/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3554289.0795\n",
      "Epoch 1324/2000\n",
      "176/176 [==============================] - 0s 262us/step - loss: 3693433.5341\n",
      "Epoch 1325/2000\n",
      "176/176 [==============================] - 0s 363us/step - loss: 4289805.2955\n",
      "Epoch 1326/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3259522.3864\n",
      "Epoch 1327/2000\n",
      "176/176 [==============================] - 0s 305us/step - loss: 3098624.8977\n",
      "Epoch 1328/2000\n",
      "176/176 [==============================] - 0s 278us/step - loss: 3608333.6591\n",
      "Epoch 1329/2000\n",
      "176/176 [==============================] - 0s 365us/step - loss: 3765439.5455\n",
      "Epoch 1330/2000\n",
      "176/176 [==============================] - 0s 389us/step - loss: 3779906.0795\n",
      "Epoch 1331/2000\n",
      "176/176 [==============================] - 0s 329us/step - loss: 2741740.0909\n",
      "Epoch 1332/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 3468153.5682\n",
      "Epoch 1333/2000\n",
      "176/176 [==============================] - 0s 296us/step - loss: 4073262.7273\n",
      "Epoch 1334/2000\n",
      "176/176 [==============================] - 0s 292us/step - loss: 3193140.8636\n",
      "Epoch 1335/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 1700875.500 - 0s 227us/step - loss: 3482101.8182\n",
      "Epoch 1336/2000\n",
      "176/176 [==============================] - 0s 285us/step - loss: 3452854.1023\n",
      "Epoch 1337/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 3015260.6250\n",
      "Epoch 1338/2000\n",
      "176/176 [==============================] - 0s 411us/step - loss: 3848257.7273\n",
      "Epoch 1339/2000\n",
      "176/176 [==============================] - 0s 396us/step - loss: 3010495.8636\n",
      "Epoch 1340/2000\n",
      "176/176 [==============================] - 0s 321us/step - loss: 3852209.1477\n",
      "Epoch 1341/2000\n",
      "176/176 [==============================] - 0s 302us/step - loss: 3894161.6364\n",
      "Epoch 1342/2000\n",
      "176/176 [==============================] - 0s 315us/step - loss: 3556742.1591\n",
      "Epoch 1343/2000\n",
      "176/176 [==============================] - 0s 314us/step - loss: 3600582.7727\n",
      "Epoch 1344/2000\n",
      "176/176 [==============================] - 0s 357us/step - loss: 3475864.6023\n",
      "Epoch 1345/2000\n",
      "176/176 [==============================] - 0s 360us/step - loss: 3584425.6818\n",
      "Epoch 1346/2000\n",
      "176/176 [==============================] - 0s 311us/step - loss: 4108460.3864\n",
      "Epoch 1347/2000\n",
      "176/176 [==============================] - 0s 289us/step - loss: 3354549.1250\n",
      "Epoch 1348/2000\n",
      "176/176 [==============================] - 0s 355us/step - loss: 3121079.5000\n",
      "Epoch 1349/2000\n",
      "176/176 [==============================] - 0s 346us/step - loss: 3417286.6364\n",
      "Epoch 1350/2000\n",
      "176/176 [==============================] - 0s 365us/step - loss: 3386974.1023\n",
      "Epoch 1351/2000\n",
      "176/176 [==============================] - 0s 330us/step - loss: 3009511.8409\n",
      "Epoch 1352/2000\n",
      "176/176 [==============================] - 0s 329us/step - loss: 4119073.0455\n",
      "Epoch 1353/2000\n",
      "176/176 [==============================] - 0s 298us/step - loss: 4238390.7955\n",
      "Epoch 1354/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 3212511.5795\n",
      "Epoch 1355/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4000469.1932\n",
      "Epoch 1356/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 3845200.7045\n",
      "Epoch 1357/2000\n",
      "176/176 [==============================] - 0s 288us/step - loss: 3443050.9773\n",
      "Epoch 1358/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3653783.6932\n",
      "Epoch 1359/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 3709023.0568\n",
      "Epoch 1360/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3378534.8864\n",
      "Epoch 1361/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3404002.3182\n",
      "Epoch 1362/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3396961.3182\n",
      "Epoch 1363/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 4127081.0227\n",
      "Epoch 1364/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3100703.0795\n",
      "Epoch 1365/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3611482.6136\n",
      "Epoch 1366/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3380729.8977\n",
      "Epoch 1367/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3082430.6818\n",
      "Epoch 1368/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 4306645.6591\n",
      "Epoch 1369/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3557517.0341\n",
      "Epoch 1370/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3308284.1818\n",
      "Epoch 1371/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3172006.3636\n",
      "Epoch 1372/2000\n",
      "176/176 [==============================] - 0s 275us/step - loss: 3863156.8182\n",
      "Epoch 1373/2000\n",
      "176/176 [==============================] - 0s 369us/step - loss: 4168034.7500\n",
      "Epoch 1374/2000\n",
      "176/176 [==============================] - 0s 311us/step - loss: 3721357.7955\n",
      "Epoch 1375/2000\n",
      "176/176 [==============================] - 0s 300us/step - loss: 3685118.7955\n",
      "Epoch 1376/2000\n",
      "176/176 [==============================] - 0s 336us/step - loss: 3013696.3409\n",
      "Epoch 1377/2000\n",
      "176/176 [==============================] - 0s 326us/step - loss: 3336169.9773\n",
      "Epoch 1378/2000\n",
      "176/176 [==============================] - 0s 292us/step - loss: 3136055.2614\n",
      "Epoch 1379/2000\n",
      "176/176 [==============================] - 0s 317us/step - loss: 3825651.1364\n",
      "Epoch 1380/2000\n",
      "176/176 [==============================] - 0s 288us/step - loss: 3257226.7500\n",
      "Epoch 1381/2000\n",
      "176/176 [==============================] - 0s 287us/step - loss: 2692628.7045\n",
      "Epoch 1382/2000\n",
      "176/176 [==============================] - 0s 327us/step - loss: 3591389.7955\n",
      "Epoch 1383/2000\n",
      "176/176 [==============================] - 0s 304us/step - loss: 3669408.5000\n",
      "Epoch 1384/2000\n",
      "176/176 [==============================] - 0s 295us/step - loss: 3082682.4318\n",
      "Epoch 1385/2000\n",
      "176/176 [==============================] - 0s 318us/step - loss: 4210843.2614\n",
      "Epoch 1386/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 3987783.7727\n",
      "Epoch 1387/2000\n",
      "176/176 [==============================] - 0s 377us/step - loss: 3571971.3750\n",
      "Epoch 1388/2000\n",
      "176/176 [==============================] - 0s 371us/step - loss: 3563819.3864\n",
      "Epoch 1389/2000\n",
      "176/176 [==============================] - 0s 372us/step - loss: 3011416.8750\n",
      "Epoch 1390/2000\n",
      "176/176 [==============================] - 0s 317us/step - loss: 3637886.2955\n",
      "Epoch 1391/2000\n",
      "176/176 [==============================] - 0s 368us/step - loss: 3291510.9091\n",
      "Epoch 1392/2000\n",
      "176/176 [==============================] - 0s 261us/step - loss: 3615290.0227\n",
      "Epoch 1393/2000\n",
      "176/176 [==============================] - 0s 279us/step - loss: 3644625.1364\n",
      "Epoch 1394/2000\n",
      "176/176 [==============================] - 0s 371us/step - loss: 3468797.8182\n",
      "Epoch 1395/2000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 4505507.4091\n",
      "Epoch 1396/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4174666.2955\n",
      "Epoch 1397/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3874098.1705\n",
      "Epoch 1398/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4002329.8409\n",
      "Epoch 1399/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 3687459.9659\n",
      "Epoch 1400/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3157121.2500\n",
      "Epoch 1401/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3669831.1136\n",
      "Epoch 1402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 174us/step - loss: 3801934.4091\n",
      "Epoch 1403/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3767948.5682\n",
      "Epoch 1404/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4102782.6818\n",
      "Epoch 1405/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3911474.0455\n",
      "Epoch 1406/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3785649.0227\n",
      "Epoch 1407/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3138371.0455\n",
      "Epoch 1408/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3420051.9773\n",
      "Epoch 1409/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3579089.0795\n",
      "Epoch 1410/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4076675.5227\n",
      "Epoch 1411/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3425686.3182\n",
      "Epoch 1412/2000\n",
      "176/176 [==============================] - 0s 124us/step - loss: 3343077.6818\n",
      "Epoch 1413/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3544590.2727\n",
      "Epoch 1414/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3852425.2727\n",
      "Epoch 1415/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3861826.5000\n",
      "Epoch 1416/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3743835.3409\n",
      "Epoch 1417/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3537382.1023\n",
      "Epoch 1418/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3855588.0909\n",
      "Epoch 1419/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3374563.0000\n",
      "Epoch 1420/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 2739064.5114\n",
      "Epoch 1421/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3427657.1364\n",
      "Epoch 1422/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3228608.4091\n",
      "Epoch 1423/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 2967220.7841\n",
      "Epoch 1424/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3845494.9659\n",
      "Epoch 1425/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3352472.1136\n",
      "Epoch 1426/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 2950993.0795\n",
      "Epoch 1427/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3261874.0341\n",
      "Epoch 1428/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3668340.9545\n",
      "Epoch 1429/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3352025.1250\n",
      "Epoch 1430/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3317421.5057\n",
      "Epoch 1431/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3436916.1136\n",
      "Epoch 1432/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 2614529.0625\n",
      "Epoch 1433/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3047469.8182\n",
      "Epoch 1434/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3897201.9091\n",
      "Epoch 1435/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 3607571.6136\n",
      "Epoch 1436/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3876157.5682\n",
      "Epoch 1437/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3728744.7614\n",
      "Epoch 1438/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3385061.1136\n",
      "Epoch 1439/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2684773.8409\n",
      "Epoch 1440/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3649128.6364\n",
      "Epoch 1441/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 4097210.3636\n",
      "Epoch 1442/2000\n",
      "176/176 [==============================] - 0s 305us/step - loss: 3469805.4205\n",
      "Epoch 1443/2000\n",
      "176/176 [==============================] - 0s 316us/step - loss: 3754293.0114\n",
      "Epoch 1444/2000\n",
      "176/176 [==============================] - 0s 281us/step - loss: 3331135.1761\n",
      "Epoch 1445/2000\n",
      "176/176 [==============================] - 0s 316us/step - loss: 3654068.5455\n",
      "Epoch 1446/2000\n",
      "176/176 [==============================] - 0s 294us/step - loss: 3279453.9659\n",
      "Epoch 1447/2000\n",
      "176/176 [==============================] - 0s 299us/step - loss: 4031896.1818\n",
      "Epoch 1448/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 4172804.7273\n",
      "Epoch 1449/2000\n",
      "176/176 [==============================] - 0s 343us/step - loss: 3422372.9318\n",
      "Epoch 1450/2000\n",
      "176/176 [==============================] - 0s 271us/step - loss: 3359060.6023\n",
      "Epoch 1451/2000\n",
      "176/176 [==============================] - 0s 372us/step - loss: 3420641.9091\n",
      "Epoch 1452/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3563842.1250\n",
      "Epoch 1453/2000\n",
      "176/176 [==============================] - 0s 295us/step - loss: 3547674.4773\n",
      "Epoch 1454/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3774526.6364\n",
      "Epoch 1455/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3550179.9432\n",
      "Epoch 1456/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3969337.3182\n",
      "Epoch 1457/2000\n",
      "176/176 [==============================] - 0s 332us/step - loss: 3415273.4432\n",
      "Epoch 1458/2000\n",
      "176/176 [==============================] - 0s 275us/step - loss: 4091120.1818\n",
      "Epoch 1459/2000\n",
      "176/176 [==============================] - 0s 351us/step - loss: 2997414.9545\n",
      "Epoch 1460/2000\n",
      "176/176 [==============================] - 0s 317us/step - loss: 3989453.5227\n",
      "Epoch 1461/2000\n",
      "176/176 [==============================] - 0s 305us/step - loss: 4062056.3636\n",
      "Epoch 1462/2000\n",
      "176/176 [==============================] - 0s 359us/step - loss: 3628837.3295\n",
      "Epoch 1463/2000\n",
      "176/176 [==============================] - 0s 366us/step - loss: 3908073.6591\n",
      "Epoch 1464/2000\n",
      "176/176 [==============================] - 0s 367us/step - loss: 4121671.2955\n",
      "Epoch 1465/2000\n",
      "176/176 [==============================] - 0s 306us/step - loss: 4691236.3864\n",
      "Epoch 1466/2000\n",
      "176/176 [==============================] - 0s 642us/step - loss: 3227334.8864\n",
      "Epoch 1467/2000\n",
      "176/176 [==============================] - 0s 329us/step - loss: 3782575.8636\n",
      "Epoch 1468/2000\n",
      "176/176 [==============================] - 0s 485us/step - loss: 3696045.4318\n",
      "Epoch 1469/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3265349.8977\n",
      "Epoch 1470/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3748148.3750\n",
      "Epoch 1471/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3468773.1705\n",
      "Epoch 1472/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3826393.3409\n",
      "Epoch 1473/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3855291.8750\n",
      "Epoch 1474/2000\n",
      "176/176 [==============================] - 0s 95us/step - loss: 3430262.9205\n",
      "Epoch 1475/2000\n",
      "176/176 [==============================] - 0s 285us/step - loss: 3455074.4659\n",
      "Epoch 1476/2000\n",
      "176/176 [==============================] - 0s 299us/step - loss: 3631528.1364\n",
      "Epoch 1477/2000\n",
      "176/176 [==============================] - 0s 320us/step - loss: 3997009.1136\n",
      "Epoch 1478/2000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 3669755.9545\n",
      "Epoch 1479/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3459517.2386\n",
      "Epoch 1480/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3398417.5227\n",
      "Epoch 1481/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3520706.0795\n",
      "Epoch 1482/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3493360.5227\n",
      "Epoch 1483/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3285769.3295\n",
      "Epoch 1484/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 3974117.0909\n",
      "Epoch 1485/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 4250641.6364\n",
      "Epoch 1486/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3624295.3977\n",
      "Epoch 1487/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3602650.9773\n",
      "Epoch 1488/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3729068.2045\n",
      "Epoch 1489/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3637814.2386\n",
      "Epoch 1490/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3325681.1023\n",
      "Epoch 1491/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3659337.6932\n",
      "Epoch 1492/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3659931.8409\n",
      "Epoch 1493/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3699716.8523\n",
      "Epoch 1494/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3498513.9659\n",
      "Epoch 1495/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3199767.3636\n",
      "Epoch 1496/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3412902.7955\n",
      "Epoch 1497/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3354748.3523\n",
      "Epoch 1498/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 4016891.5455\n",
      "Epoch 1499/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3485753.5909\n",
      "Epoch 1500/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3824596.7386\n",
      "Epoch 1501/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3451815.2500\n",
      "Epoch 1502/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3416651.9659\n",
      "Epoch 1503/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3515660.2727\n",
      "Epoch 1504/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3738883.6818\n",
      "Epoch 1505/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3493460.3182\n",
      "Epoch 1506/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3612907.9545\n",
      "Epoch 1507/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3510115.1818\n",
      "Epoch 1508/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3147201.2841\n",
      "Epoch 1509/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3631819.1818\n",
      "Epoch 1510/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3498982.8295\n",
      "Epoch 1511/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 2898325.4886\n",
      "Epoch 1512/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4048826.1364\n",
      "Epoch 1513/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3083668.4659\n",
      "Epoch 1514/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3471848.3864\n",
      "Epoch 1515/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 2978802.7500\n",
      "Epoch 1516/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3332623.1591\n",
      "Epoch 1517/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3963102.6932\n",
      "Epoch 1518/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3232322.7045\n",
      "Epoch 1519/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3895321.3750\n",
      "Epoch 1520/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 4127819.4091\n",
      "Epoch 1521/2000\n",
      "176/176 [==============================] - 0s 255us/step - loss: 3697982.8750\n",
      "Epoch 1522/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3797534.8977\n",
      "Epoch 1523/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3463073.2727\n",
      "Epoch 1524/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3232817.6477\n",
      "Epoch 1525/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4286026.3409\n",
      "Epoch 1526/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3729269.0227\n",
      "Epoch 1527/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3463970.7727\n",
      "Epoch 1528/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3441668.9545\n",
      "Epoch 1529/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3591195.6818\n",
      "Epoch 1530/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3613869.4545\n",
      "Epoch 1531/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3837031.3636\n",
      "Epoch 1532/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3395282.1477\n",
      "Epoch 1533/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4370378.2273\n",
      "Epoch 1534/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3107919.9318\n",
      "Epoch 1535/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3364577.5568\n",
      "Epoch 1536/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3638000.1932\n",
      "Epoch 1537/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3058880.4545\n",
      "Epoch 1538/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3880098.2159\n",
      "Epoch 1539/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3363186.6477\n",
      "Epoch 1540/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3606157.1136\n",
      "Epoch 1541/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3860981.3636\n",
      "Epoch 1542/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3251357.2045\n",
      "Epoch 1543/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4098191.5795\n",
      "Epoch 1544/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3600000.4091\n",
      "Epoch 1545/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3467289.4545\n",
      "Epoch 1546/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3749214.4545\n",
      "Epoch 1547/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 3030113.8182\n",
      "Epoch 1548/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3609048.3409\n",
      "Epoch 1549/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3823322.8523\n",
      "Epoch 1550/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3269437.4659\n",
      "Epoch 1551/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3133702.0000\n",
      "Epoch 1552/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3273595.3068\n",
      "Epoch 1553/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3312549.7955\n",
      "Epoch 1554/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3587455.2955\n",
      "Epoch 1555/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3763026.1591\n",
      "Epoch 1556/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3881749.1591\n",
      "Epoch 1557/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3585119.3636\n",
      "Epoch 1558/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3921775.2955\n",
      "Epoch 1559/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3859291.7273\n",
      "Epoch 1560/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 4103750.1023\n",
      "Epoch 1561/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3817634.0909\n",
      "Epoch 1562/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 2851457.2045\n",
      "Epoch 1563/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4071259.1591\n",
      "Epoch 1564/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3112353.0909\n",
      "Epoch 1565/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3955308.6818\n",
      "Epoch 1566/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 2923453.0682\n",
      "Epoch 1567/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 2949672.1705\n",
      "Epoch 1568/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3657530.0227\n",
      "Epoch 1569/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3237240.3409\n",
      "Epoch 1570/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2986237.7614\n",
      "Epoch 1571/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3407651.6932\n",
      "Epoch 1572/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3821863.5227\n",
      "Epoch 1573/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 2663893.4318\n",
      "Epoch 1574/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3632402.0455\n",
      "Epoch 1575/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3805307.9318\n",
      "Epoch 1576/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 217us/step - loss: 3789065.8409\n",
      "Epoch 1577/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3659088.3864\n",
      "Epoch 1578/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3934459.2727\n",
      "Epoch 1579/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3302353.4545\n",
      "Epoch 1580/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4233785.1591\n",
      "Epoch 1581/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3288278.9318\n",
      "Epoch 1582/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3538570.3409\n",
      "Epoch 1583/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3942371.6477\n",
      "Epoch 1584/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3093135.2500\n",
      "Epoch 1585/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3551065.3864\n",
      "Epoch 1586/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4010509.4318\n",
      "Epoch 1587/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3790520.5795\n",
      "Epoch 1588/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3955056.0455\n",
      "Epoch 1589/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3694309.6591\n",
      "Epoch 1590/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2769422.0568\n",
      "Epoch 1591/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3707478.2727\n",
      "Epoch 1592/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3559747.2045\n",
      "Epoch 1593/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2986528.3864\n",
      "Epoch 1594/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 4031365.6364\n",
      "Epoch 1595/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2661408.4318\n",
      "Epoch 1596/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3362998.7045\n",
      "Epoch 1597/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3200978.8750\n",
      "Epoch 1598/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3953307.6023\n",
      "Epoch 1599/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3842151.8750\n",
      "Epoch 1600/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3039750.9432\n",
      "Epoch 1601/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3261488.5909\n",
      "Epoch 1602/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3367476.8864\n",
      "Epoch 1603/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3433362.7727\n",
      "Epoch 1604/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3726744.8636\n",
      "Epoch 1605/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3285017.7159\n",
      "Epoch 1606/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3373413.5114\n",
      "Epoch 1607/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3871202.4773\n",
      "Epoch 1608/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3353169.2614\n",
      "Epoch 1609/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3542851.6023\n",
      "Epoch 1610/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3546921.5000\n",
      "Epoch 1611/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3856182.4318\n",
      "Epoch 1612/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4058595.9318\n",
      "Epoch 1613/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4305367.8182\n",
      "Epoch 1614/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3365453.4318\n",
      "Epoch 1615/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3448689.3864\n",
      "Epoch 1616/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4218594.9318\n",
      "Epoch 1617/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3588819.7273\n",
      "Epoch 1618/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 2983085.2273\n",
      "Epoch 1619/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 4133051.9773\n",
      "Epoch 1620/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3353466.5227\n",
      "Epoch 1621/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3401983.7614\n",
      "Epoch 1622/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3489079.3295\n",
      "Epoch 1623/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3110811.5000\n",
      "Epoch 1624/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3587074.0000\n",
      "Epoch 1625/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3993668.2500\n",
      "Epoch 1626/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3946692.2273\n",
      "Epoch 1627/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3915397.2727\n",
      "Epoch 1628/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4068369.6477\n",
      "Epoch 1629/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3402034.6591\n",
      "Epoch 1630/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3683207.7045\n",
      "Epoch 1631/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3580435.3864\n",
      "Epoch 1632/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3288572.4318\n",
      "Epoch 1633/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4113228.5909\n",
      "Epoch 1634/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3604205.2500\n",
      "Epoch 1635/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 4269950.3864\n",
      "Epoch 1636/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 2981377.6534\n",
      "Epoch 1637/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3780330.8977\n",
      "Epoch 1638/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3453779.8977\n",
      "Epoch 1639/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3074823.1932\n",
      "Epoch 1640/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3669758.3182\n",
      "Epoch 1641/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3940002.9545\n",
      "Epoch 1642/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3620203.0909\n",
      "Epoch 1643/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 4131257.1818\n",
      "Epoch 1644/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3957600.0000\n",
      "Epoch 1645/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3529695.7159\n",
      "Epoch 1646/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3829692.1477\n",
      "Epoch 1647/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 4011782.0568\n",
      "Epoch 1648/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4104481.0568\n",
      "Epoch 1649/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 3797947.4205\n",
      "Epoch 1650/2000\n",
      "176/176 [==============================] - 0s 142us/step - loss: 3575608.6705\n",
      "Epoch 1651/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3626198.9659\n",
      "Epoch 1652/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3945087.3636\n",
      "Epoch 1653/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3618974.2500\n",
      "Epoch 1654/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4059526.0000\n",
      "Epoch 1655/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3617440.0568\n",
      "Epoch 1656/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4203581.3182\n",
      "Epoch 1657/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4090891.9318\n",
      "Epoch 1658/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3389547.8295\n",
      "Epoch 1659/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 4008895.0000\n",
      "Epoch 1660/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3305761.5455\n",
      "Epoch 1661/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3748606.6591\n",
      "Epoch 1662/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3591535.4545\n",
      "Epoch 1663/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3591990.3636\n",
      "Epoch 1664/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3210784.6023\n",
      "Epoch 1665/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4279848.6591\n",
      "Epoch 1666/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3204703.3636\n",
      "Epoch 1667/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3578653.1364\n",
      "Epoch 1668/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3517520.8523\n",
      "Epoch 1669/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3788112.2386\n",
      "Epoch 1670/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3768874.6136\n",
      "Epoch 1671/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3675838.4318\n",
      "Epoch 1672/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3853196.4318\n",
      "Epoch 1673/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4018381.3864\n",
      "Epoch 1674/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3344818.5455\n",
      "Epoch 1675/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3105887.5455\n",
      "Epoch 1676/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3217342.5000\n",
      "Epoch 1677/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3676525.1591\n",
      "Epoch 1678/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 2775205.1705\n",
      "Epoch 1679/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3609754.8068\n",
      "Epoch 1680/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3200195.3409\n",
      "Epoch 1681/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 2723963.4318\n",
      "Epoch 1682/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3862210.3409\n",
      "Epoch 1683/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3512121.8636\n",
      "Epoch 1684/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3161583.2614\n",
      "Epoch 1685/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3800240.0795\n",
      "Epoch 1686/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4166439.2045\n",
      "Epoch 1687/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2957095.4545\n",
      "Epoch 1688/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3689622.2500\n",
      "Epoch 1689/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4282272.7045\n",
      "Epoch 1690/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 4238537.1818\n",
      "Epoch 1691/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3378435.1818\n",
      "Epoch 1692/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3364547.5000\n",
      "Epoch 1693/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3496108.4318\n",
      "Epoch 1694/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3643049.9773\n",
      "Epoch 1695/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2983036.4773\n",
      "Epoch 1696/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3187313.3409\n",
      "Epoch 1697/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4078593.6023\n",
      "Epoch 1698/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3386346.0341\n",
      "Epoch 1699/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3783874.4205\n",
      "Epoch 1700/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3100199.7500\n",
      "Epoch 1701/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3672641.5114\n",
      "Epoch 1702/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3022489.7614\n",
      "Epoch 1703/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3563554.6818\n",
      "Epoch 1704/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3315494.5682\n",
      "Epoch 1705/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 2645544.3636\n",
      "Epoch 1706/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3341641.0455\n",
      "Epoch 1707/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3538286.2273\n",
      "Epoch 1708/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3375734.4205\n",
      "Epoch 1709/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3320880.6364\n",
      "Epoch 1710/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3583038.1818\n",
      "Epoch 1711/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3615116.8864\n",
      "Epoch 1712/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3836143.2500\n",
      "Epoch 1713/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3559291.5227\n",
      "Epoch 1714/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3334309.4091\n",
      "Epoch 1715/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3861102.9318\n",
      "Epoch 1716/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3438739.1136\n",
      "Epoch 1717/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3292400.9545\n",
      "Epoch 1718/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3611043.6818\n",
      "Epoch 1719/2000\n",
      "176/176 [==============================] - 0s 119us/step - loss: 3280835.9659\n",
      "Epoch 1720/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3650019.6250\n",
      "Epoch 1721/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3923830.9886\n",
      "Epoch 1722/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4074323.6591\n",
      "Epoch 1723/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 4078772.8977\n",
      "Epoch 1724/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3619922.4545\n",
      "Epoch 1725/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3230420.1591\n",
      "Epoch 1726/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3562941.5227\n",
      "Epoch 1727/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4030566.3864\n",
      "Epoch 1728/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3886658.3750\n",
      "Epoch 1729/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3458890.8864\n",
      "Epoch 1730/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3856400.6250\n",
      "Epoch 1731/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 2609555.6705\n",
      "Epoch 1732/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3801781.5455\n",
      "Epoch 1733/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3185150.9091\n",
      "Epoch 1734/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3944539.2955\n",
      "Epoch 1735/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3505247.0568\n",
      "Epoch 1736/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3382137.9545\n",
      "Epoch 1737/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4081910.5682\n",
      "Epoch 1738/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3673924.9773\n",
      "Epoch 1739/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3401379.4659\n",
      "Epoch 1740/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 3743988.4318\n",
      "Epoch 1741/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 3746565.5455\n",
      "Epoch 1742/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3656916.9545\n",
      "Epoch 1743/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3921244.3125\n",
      "Epoch 1744/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3267076.2045\n",
      "Epoch 1745/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3050518.4091\n",
      "Epoch 1746/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3688424.2273\n",
      "Epoch 1747/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3394866.9318\n",
      "Epoch 1748/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3796145.9545\n",
      "Epoch 1749/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4198389.8409\n",
      "Epoch 1750/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 172us/step - loss: 3684800.8068\n",
      "Epoch 1751/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3396377.3977\n",
      "Epoch 1752/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4329633.6136\n",
      "Epoch 1753/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3578489.9318\n",
      "Epoch 1754/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3393957.2955\n",
      "Epoch 1755/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4045579.1705\n",
      "Epoch 1756/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3357638.8409\n",
      "Epoch 1757/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3433263.5909\n",
      "Epoch 1758/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3540546.4545\n",
      "Epoch 1759/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 4147025.9773\n",
      "Epoch 1760/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3361142.0341\n",
      "Epoch 1761/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2845218.9886\n",
      "Epoch 1762/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3829495.0455\n",
      "Epoch 1763/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3522106.7386\n",
      "Epoch 1764/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3923540.9545\n",
      "Epoch 1765/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3486773.4091\n",
      "Epoch 1766/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3227724.7727\n",
      "Epoch 1767/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3356741.5114\n",
      "Epoch 1768/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3847699.0455\n",
      "Epoch 1769/2000\n",
      "176/176 [==============================] - 0s 142us/step - loss: 2893675.3409\n",
      "Epoch 1770/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3342192.5000\n",
      "Epoch 1771/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 2916352.0227\n",
      "Epoch 1772/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3937332.4545\n",
      "Epoch 1773/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3428463.6023\n",
      "Epoch 1774/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3768218.0455\n",
      "Epoch 1775/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3685172.7273\n",
      "Epoch 1776/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3267180.9318\n",
      "Epoch 1777/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3640138.9375\n",
      "Epoch 1778/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3410252.1705\n",
      "Epoch 1779/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4399621.5227\n",
      "Epoch 1780/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3369904.5568\n",
      "Epoch 1781/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 4031689.0114\n",
      "Epoch 1782/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3324648.5341\n",
      "Epoch 1783/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3480459.5227\n",
      "Epoch 1784/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3289673.0227\n",
      "Epoch 1785/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3459140.0682\n",
      "Epoch 1786/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3282162.8523\n",
      "Epoch 1787/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3158536.3068\n",
      "Epoch 1788/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 4053544.8864\n",
      "Epoch 1789/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3362386.9205\n",
      "Epoch 1790/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3235013.0568\n",
      "Epoch 1791/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3063510.2614\n",
      "Epoch 1792/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 2906842.8977\n",
      "Epoch 1793/2000\n",
      "176/176 [==============================] - 0s 255us/step - loss: 3334199.0341\n",
      "Epoch 1794/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 4169428.3864\n",
      "Epoch 1795/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3887001.8636\n",
      "Epoch 1796/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3523878.1136\n",
      "Epoch 1797/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3662953.4659\n",
      "Epoch 1798/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3438165.7159\n",
      "Epoch 1799/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3744720.9205\n",
      "Epoch 1800/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3153915.6136\n",
      "Epoch 1801/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 4426192.2273\n",
      "Epoch 1802/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3484462.4205\n",
      "Epoch 1803/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3153580.1307\n",
      "Epoch 1804/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3346023.0114\n",
      "Epoch 1805/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 2990492.9659\n",
      "Epoch 1806/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3023947.1250\n",
      "Epoch 1807/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3281080.2045\n",
      "Epoch 1808/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 4552935.7614\n",
      "Epoch 1809/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 2965304.1136\n",
      "Epoch 1810/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 4033522.4545\n",
      "Epoch 1811/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3682911.4545\n",
      "Epoch 1812/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3638294.0455\n",
      "Epoch 1813/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3545389.2045\n",
      "Epoch 1814/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3552658.0227\n",
      "Epoch 1815/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 3530372.3636\n",
      "Epoch 1816/2000\n",
      "176/176 [==============================] - 0s 256us/step - loss: 3912178.2045\n",
      "Epoch 1817/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3681905.6136\n",
      "Epoch 1818/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3866136.6364\n",
      "Epoch 1819/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3570648.9659\n",
      "Epoch 1820/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3679516.8182\n",
      "Epoch 1821/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3138050.6477\n",
      "Epoch 1822/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3605263.1818\n",
      "Epoch 1823/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3336548.8636\n",
      "Epoch 1824/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3644941.3523\n",
      "Epoch 1825/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3314052.3977\n",
      "Epoch 1826/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 4107372.5227\n",
      "Epoch 1827/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3748719.3409\n",
      "Epoch 1828/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3325448.3295\n",
      "Epoch 1829/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4195865.7045\n",
      "Epoch 1830/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3916507.3068\n",
      "Epoch 1831/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3932429.1023\n",
      "Epoch 1832/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3647589.7045\n",
      "Epoch 1833/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3463554.5455\n",
      "Epoch 1834/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3122025.6932\n",
      "Epoch 1835/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3536044.0114\n",
      "Epoch 1836/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3297856.5455\n",
      "Epoch 1837/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3156543.0000\n",
      "Epoch 1838/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3353623.5568\n",
      "Epoch 1839/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3448176.8523\n",
      "Epoch 1840/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3185243.4318\n",
      "Epoch 1841/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 3590299.0795\n",
      "Epoch 1842/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 3344811.7955\n",
      "Epoch 1843/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3474722.1364\n",
      "Epoch 1844/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3334800.4318\n",
      "Epoch 1845/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3053241.4432\n",
      "Epoch 1846/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 2931766.5000\n",
      "Epoch 1847/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3608013.2273\n",
      "Epoch 1848/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3738584.4318\n",
      "Epoch 1849/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3332316.5909\n",
      "Epoch 1850/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3443685.8182\n",
      "Epoch 1851/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3173202.1364\n",
      "Epoch 1852/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3701995.1364\n",
      "Epoch 1853/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3040400.4545\n",
      "Epoch 1854/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3962509.4773\n",
      "Epoch 1855/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3788647.5909\n",
      "Epoch 1856/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 2619683.9886\n",
      "Epoch 1857/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3365025.4318\n",
      "Epoch 1858/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3591659.2386\n",
      "Epoch 1859/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3393134.4489\n",
      "Epoch 1860/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3643595.7273\n",
      "Epoch 1861/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 4257614.9318\n",
      "Epoch 1862/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3732295.5682\n",
      "Epoch 1863/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3554355.6818\n",
      "Epoch 1864/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3429757.0455\n",
      "Epoch 1865/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2150673.750 - 0s 211us/step - loss: 3544028.5909\n",
      "Epoch 1866/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3229795.0682\n",
      "Epoch 1867/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3162067.6932\n",
      "Epoch 1868/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3488936.1477\n",
      "Epoch 1869/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3376108.1818\n",
      "Epoch 1870/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3654762.9773\n",
      "Epoch 1871/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3496725.4545\n",
      "Epoch 1872/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3697182.3409\n",
      "Epoch 1873/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3679695.4545\n",
      "Epoch 1874/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3195237.2727\n",
      "Epoch 1875/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3852850.7955\n",
      "Epoch 1876/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 2961962.0227\n",
      "Epoch 1877/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3392567.8068\n",
      "Epoch 1878/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3645816.7386\n",
      "Epoch 1879/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3825659.2841\n",
      "Epoch 1880/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 2992120.9545\n",
      "Epoch 1881/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3169289.6023\n",
      "Epoch 1882/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3152691.5000\n",
      "Epoch 1883/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4050762.3750\n",
      "Epoch 1884/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3734375.4659\n",
      "Epoch 1885/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3904494.8750\n",
      "Epoch 1886/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3730582.4318\n",
      "Epoch 1887/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4172817.7045\n",
      "Epoch 1888/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 2885288.9432\n",
      "Epoch 1889/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3387807.4091\n",
      "Epoch 1890/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3287189.4773\n",
      "Epoch 1891/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3585764.2955\n",
      "Epoch 1892/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3813730.7955\n",
      "Epoch 1893/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3293248.2500\n",
      "Epoch 1894/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3602576.6136\n",
      "Epoch 1895/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3586819.6932\n",
      "Epoch 1896/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3571205.0909\n",
      "Epoch 1897/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4017438.2727\n",
      "Epoch 1898/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3255384.3977\n",
      "Epoch 1899/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 4078034.8409\n",
      "Epoch 1900/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3097343.0227\n",
      "Epoch 1901/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3666435.7955\n",
      "Epoch 1902/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3751216.6364\n",
      "Epoch 1903/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3602951.8977\n",
      "Epoch 1904/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3432942.0000\n",
      "Epoch 1905/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 2861864.3864\n",
      "Epoch 1906/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4021684.2727\n",
      "Epoch 1907/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3572333.5227\n",
      "Epoch 1908/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3673933.7500\n",
      "Epoch 1909/2000\n",
      "176/176 [==============================] - 0s 301us/step - loss: 2526368.3068\n",
      "Epoch 1910/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3689320.6364\n",
      "Epoch 1911/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3706763.4318\n",
      "Epoch 1912/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3614621.9659\n",
      "Epoch 1913/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3093677.8182\n",
      "Epoch 1914/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3469680.6477\n",
      "Epoch 1915/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3815699.6591\n",
      "Epoch 1916/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3386031.2273\n",
      "Epoch 1917/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3937800.1591\n",
      "Epoch 1918/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3518199.8409\n",
      "Epoch 1919/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3892973.2955\n",
      "Epoch 1920/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 2851962.7045\n",
      "Epoch 1921/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3561423.2727\n",
      "Epoch 1922/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3274305.3182\n",
      "Epoch 1923/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3664683.6477\n",
      "Epoch 1924/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 204us/step - loss: 3687443.5227\n",
      "Epoch 1925/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 4124277.4773\n",
      "Epoch 1926/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3642761.4773\n",
      "Epoch 1927/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3704136.1364\n",
      "Epoch 1928/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3730593.5455\n",
      "Epoch 1929/2000\n",
      "176/176 [==============================] - 0s 299us/step - loss: 3882928.0114\n",
      "Epoch 1930/2000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 2617095.6591\n",
      "Epoch 1931/2000\n",
      "176/176 [==============================] - 0s 303us/step - loss: 3619578.0909\n",
      "Epoch 1932/2000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 4249645.1136\n",
      "Epoch 1933/2000\n",
      "176/176 [==============================] - 0s 386us/step - loss: 3673601.5909\n",
      "Epoch 1934/2000\n",
      "176/176 [==============================] - 0s 405us/step - loss: 3566660.1818\n",
      "Epoch 1935/2000\n",
      "176/176 [==============================] - 0s 402us/step - loss: 3464232.5114\n",
      "Epoch 1936/2000\n",
      "176/176 [==============================] - 0s 276us/step - loss: 3712195.5227\n",
      "Epoch 1937/2000\n",
      "176/176 [==============================] - 0s 343us/step - loss: 2928053.9545\n",
      "Epoch 1938/2000\n",
      "176/176 [==============================] - 0s 368us/step - loss: 3457682.0909\n",
      "Epoch 1939/2000\n",
      "176/176 [==============================] - 0s 296us/step - loss: 3658645.2841\n",
      "Epoch 1940/2000\n",
      "176/176 [==============================] - 0s 391us/step - loss: 3735927.6136\n",
      "Epoch 1941/2000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 3139537.6364\n",
      "Epoch 1942/2000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 3703447.0227\n",
      "Epoch 1943/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3395289.1591\n",
      "Epoch 1944/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 4283448.9318\n",
      "Epoch 1945/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4121006.2841\n",
      "Epoch 1946/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 4663627.3182\n",
      "Epoch 1947/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3187743.9091\n",
      "Epoch 1948/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3646211.9091\n",
      "Epoch 1949/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3292877.2386\n",
      "Epoch 1950/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4066570.8864\n",
      "Epoch 1951/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3700774.3636\n",
      "Epoch 1952/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3798445.7614\n",
      "Epoch 1953/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3936138.1136\n",
      "Epoch 1954/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3749708.9318\n",
      "Epoch 1955/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3678171.6136\n",
      "Epoch 1956/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3906381.1364\n",
      "Epoch 1957/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3481620.5227\n",
      "Epoch 1958/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3948337.9034\n",
      "Epoch 1959/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3365458.6705\n",
      "Epoch 1960/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 4201816.6591\n",
      "Epoch 1961/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3517385.9545\n",
      "Epoch 1962/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3750013.7955\n",
      "Epoch 1963/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4265162.7955\n",
      "Epoch 1964/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3386341.6250\n",
      "Epoch 1965/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 2786311.1591\n",
      "Epoch 1966/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3093342.2727\n",
      "Epoch 1967/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3563398.1705\n",
      "Epoch 1968/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3329068.5909\n",
      "Epoch 1969/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3722192.3295\n",
      "Epoch 1970/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3634361.5000\n",
      "Epoch 1971/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3322860.3636\n",
      "Epoch 1972/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3343541.0795\n",
      "Epoch 1973/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3172279.2045\n",
      "Epoch 1974/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3854488.2955\n",
      "Epoch 1975/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3531550.4773\n",
      "Epoch 1976/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3759158.6250\n",
      "Epoch 1977/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3399407.8182\n",
      "Epoch 1978/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3294073.7500\n",
      "Epoch 1979/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3232306.8750\n",
      "Epoch 1980/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3701756.3068\n",
      "Epoch 1981/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3859722.7386\n",
      "Epoch 1982/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3601646.1364\n",
      "Epoch 1983/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3457586.8409\n",
      "Epoch 1984/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3387000.7500\n",
      "Epoch 1985/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3195045.3068\n",
      "Epoch 1986/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3482635.2614\n",
      "Epoch 1987/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3358197.0000\n",
      "Epoch 1988/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3878383.0682\n",
      "Epoch 1989/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3268170.9886\n",
      "Epoch 1990/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3476951.6818\n",
      "Epoch 1991/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3284494.5909\n",
      "Epoch 1992/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3362485.2500\n",
      "Epoch 1993/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3861434.0795\n",
      "Epoch 1994/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3370559.9432\n",
      "Epoch 1995/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3244164.1989\n",
      "Epoch 1996/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3765128.7386\n",
      "Epoch 1997/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3555057.4545\n",
      "Epoch 1998/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3180520.0227\n",
      "Epoch 1999/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3543362.0227\n",
      "Epoch 2000/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3494267.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e813bf9408>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=2000,batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "train_pred= model.predict(X_train)\n",
    "test_u =test_pred.flatten()\n",
    "test_u\n",
    "train_u = train_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.74\n",
      "Accuracy for Training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(r2_score(y_test,test_u)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(r2_score(y_train,train_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 5.6\n",
      "Tree on test set MAE%: 12.1\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_u))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_u))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2705.4700172946823"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor with K = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid of hyperparameters to search\n",
    "\n",
    "parameter_grid = {\n",
    "    'base_score':[0.25,0.5,0.75,1],\n",
    "    'n_estimators':[100, 500, 700, 1000, 1500] ,\n",
    "    'max_depth':[2, 3, 5, 9],\n",
    "    'learning_rate':[0.05,0.1,0.15,0.20],\n",
    "    'min_child_weight':[1,2,3,4],\n",
    "    'booster':['gbtree','gblinear'] ,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "ran = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=parameter_grid,cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5,\n",
    "            return_train_score = True,\n",
    "            random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=4)]: Done 196 tasks      | elapsed:   36.0s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:   45.5s finished\n",
      "C:\\Users\\amith\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\amith\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:53] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_st...\n",
       "                   iid='warn', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 9],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 700, 1000,\n",
       "                                                         1500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=35, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
       "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the best estimator\n",
    "\n",
    "ran.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model by passing the best estimator from the GridSearchCV method.\n",
    "\n",
    "\n",
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
    "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "             silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:55:54] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
       "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = regressor.predict(X_train)\n",
    "test_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152    19900\n",
       "74     14995\n",
       "71     12995\n",
       "161    15300\n",
       "162    23400\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.76\n",
      "Accuracy for Training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(regressor.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(regressor.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 3.1\n",
      "Tree on test set MAE%: 11.8\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2612.2167251606866"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the root mean square error value.\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
