{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Inv</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>Chrysler</td>\n",
       "      <td>Concorde LXi FWD</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>I</td>\n",
       "      <td>2C3HD36M32H196490</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Liberty Limited 4WD</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>black</td>\n",
       "      <td>205000</td>\n",
       "      <td>I</td>\n",
       "      <td>1J4GL58K74W203537</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Malibu LS FWD</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>I</td>\n",
       "      <td>1G1ZT52875F158217</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-150 XLT 4x4</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>I</td>\n",
       "      <td>1FTRW14W16KB59343</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Altima 2.5 S FWD</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Blue</td>\n",
       "      <td>206598</td>\n",
       "      <td>I</td>\n",
       "      <td>1N4AL11D96C124803</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year       Make                Model           Car Name Wheel Drive  \\\n",
       "0  2002   Chrysler     Concorde LXi FWD  Chrysler Concorde         FWD   \n",
       "1  2004       Jeep  Liberty Limited 4WD       Jeep Liberty         4WD   \n",
       "2  2005  Chevrolet        Malibu LS FWD   Chevrolet Malibu         FWD   \n",
       "3  2006       Ford        F-150 XLT 4x4         Ford F-150         4WD   \n",
       "4  2006     Nissan     Altima 2.5 S FWD      Nissan Altima         FWD   \n",
       "\n",
       "            Colour  Odometer Inv                VIN Retail  Price  \n",
       "0           SILVER    245305   I  2C3HD36M32H196490   AUTO   1200  \n",
       "1            black    205000   I  1J4GL58K74W203537   AUTO   1200  \n",
       "2            WHITE    199885   I  1G1ZT52875F158217   AUTO   1200  \n",
       "3  Black Clearcoat    176880   I  1FTRW14W16KB59343   AUTO      0  \n",
       "4             Blue    206598   I  1N4AL11D96C124803   AUTO   1200  "
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Inv</th>\n",
       "      <th>VIN</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>2019</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Spark LT FWD</td>\n",
       "      <td>Chevrolet Spark</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Blue</td>\n",
       "      <td>32700</td>\n",
       "      <td>I</td>\n",
       "      <td>KL8CD6SA1KC776013</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>2019</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Veloster 2.0 GL - RENTAL FWD</td>\n",
       "      <td>Hyundai Veloster</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47314</td>\n",
       "      <td>I</td>\n",
       "      <td>KMHTG6AF8KU008174</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>16995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>2019</td>\n",
       "      <td>Kia</td>\n",
       "      <td>Soul EX - RENTAL FWD</td>\n",
       "      <td>Kia Soul</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>38790</td>\n",
       "      <td>I</td>\n",
       "      <td>KNDJP3A50K7909751</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>17900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>2019</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Micra S Rental FWD</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>Black</td>\n",
       "      <td>17836</td>\n",
       "      <td>I</td>\n",
       "      <td>3N1CK3CP6KL214890</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>2019</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>Micra S - rental FWD</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>20225</td>\n",
       "      <td>I</td>\n",
       "      <td>3N1CK3CP3KL217164</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year       Make                         Model          Car Name  \\\n",
       "215  2019  Chevrolet                  Spark LT FWD   Chevrolet Spark   \n",
       "216  2019    Hyundai  Veloster 2.0 GL - RENTAL FWD  Hyundai Veloster   \n",
       "217  2019        Kia          Soul EX - RENTAL FWD          Kia Soul   \n",
       "218  2019     Nissan            Micra S Rental FWD      Nissan Micra   \n",
       "219  2019     Nissan          Micra S - rental FWD      Nissan Micra   \n",
       "\n",
       "    Wheel Drive Colour  Odometer Inv                VIN Retail  Price  \n",
       "215         FWD   Blue     32700   I  KL8CD6SA1KC776013   AUTO  14300  \n",
       "216         FWD  WHITE     47314   I  KMHTG6AF8KU008174   AUTO  16995  \n",
       "217         FWD  WHITE     38790   I  KNDJP3A50K7909751   AUTO  17900  \n",
       "218         FWD  Black     17836   I  3N1CK3CP6KL214890   AUTO  14700  \n",
       "219         FWD  WHITE     20225   I  3N1CK3CP3KL217164   AUTO  14300  "
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 11)"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 11 columns):\n",
      "Year           220 non-null int64\n",
      "Make           220 non-null object\n",
      "Model          220 non-null object\n",
      "Car Name       220 non-null object\n",
      "Wheel Drive    220 non-null object\n",
      "Colour         218 non-null object\n",
      "Odometer       220 non-null int64\n",
      "Inv            220 non-null object\n",
      "VIN            220 non-null object\n",
      "Retail         220 non-null object\n",
      "Price          220 non-null int64\n",
      "dtypes: int64(3), object(8)\n",
      "memory usage: 19.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>220.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2015.386364</td>\n",
       "      <td>70621.022727</td>\n",
       "      <td>16436.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.356531</td>\n",
       "      <td>46718.323024</td>\n",
       "      <td>5045.752147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>47590.000000</td>\n",
       "      <td>13700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>63728.000000</td>\n",
       "      <td>15995.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>81488.750000</td>\n",
       "      <td>19625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>494156.000000</td>\n",
       "      <td>30900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Year       Odometer         Price\n",
       "count   220.000000     220.000000    220.000000\n",
       "mean   2015.386364   70621.022727  16436.545455\n",
       "std       2.356531   46718.323024   5045.752147\n",
       "min    2002.000000       0.000000      0.000000\n",
       "25%    2015.000000   47590.000000  13700.000000\n",
       "50%    2016.000000   63728.000000  15995.000000\n",
       "75%    2017.000000   81488.750000  19625.000000\n",
       "max    2019.000000  494156.000000  30900.000000"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Make           0\n",
       "Model          0\n",
       "Car Name       0\n",
       "Wheel Drive    0\n",
       "Colour         2\n",
       "Odometer       0\n",
       "Inv            0\n",
       "VIN            0\n",
       "Retail         0\n",
       "Price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Colour'].fillna( method ='ffill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year           0\n",
       "Make           0\n",
       "Model          0\n",
       "Car Name       0\n",
       "Wheel Drive    0\n",
       "Colour         0\n",
       "Odometer       0\n",
       "Inv            0\n",
       "VIN            0\n",
       "Retail         0\n",
       "Price          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['Model'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Car Name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Make'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21]), <a list of 22 Text xticklabel objects>)"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAIiCAYAAAAzXfXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZhkVX3/8fcXBkURFMKIuACKKBLCogNBNC4oCm6AIEpAcUUTUXE3GuOCMWpUYtCoGCDjBrKIGFQEFXFBgWEH0Z+KGheEwQ3EjeX7++PcZmqanj4NU+feXt6v55ln+t7qqu/pma6qT517lshMJEmSJK3aGkM3QJIkSZrtDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVLBq6ATOx4YYb5mabbTZ0MyRJkjTPnXfeeddk5uLJ5+dEaN5ss81YtmzZ0M2QJEnSPBcRP5nqvMMzJEmSpIpmoTki1o6IcyLiooi4LCLe0p2/b0ScHRHfj4hPRcQdWrVBkiRJGoeWPc1/BnbJzG2B7YDdImIn4J3AYZm5BfAb4HkN2yBJkiSttmahOYvfd4drdX8S2AU4oTu/FNizVRskSZKkcWg6pjki1oyIC4GrgdOBHwK/zcwbu2/5GXCvVdz3oIhYFhHLli9f3rKZkiRJ0rSahubMvCkztwPuDewIPGiqb1vFfY/IzCWZuWTx4lut+iFJkiT1ppfVMzLzt8BXgZ2Au0XExFJ39wZ+0UcbJEmSpNur5eoZiyPibt3XdwIeC1wOnAHs033bgcDJrdogSZIkjUPLzU02BpZGxJqUcH5cZp4SEd8Bjo2ItwEXAEc2bIMkSZK02pqF5sy8GNh+ivNXUMY3S5IkSXOCOwJKkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSapouSNgE8s/+PGmj7/4Hw5o+viSJEmae+xpliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVSwaugFzxVUffEfzGhv9w+ua15AkSdJtZ0+zJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVi4ZugOp+ePgeTR9/85ec3PTxJUmS5jp7miVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFU0C80RcZ+IOCMiLo+IyyLiZd35N0fEzyPiwu7PE1q1QZIkSRqHRQ0f+0bglZl5fkSsC5wXEad3tx2Wme9uWFuSJEkam2ahOTOvBK7svr4uIi4H7tWqniRJktRKL2OaI2IzYHvg7O7UwRFxcUQcFRHrr+I+B0XEsohYtnz58j6aKUmSJE2peWiOiLsAJwKHZOa1wAeBzYHtKD3R75nqfpl5RGYuycwlixcvbt1MSZIkaZWahuaIWIsSmD+RmZ8GyMyrMvOmzLwZ+AiwY8s2SJIkSaur5eoZARwJXJ6Z7x05v/HIt+0FXNqqDZIkSdI4tFw942HAM4FLIuLC7tzrgf0iYjsggR8DL2zYBkmSJGm1tVw94xtATHHT51vVlCRJklpwR0BJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVJFs9AcEfeJiDMi4vKIuCwiXtad3yAiTo+I73d/r9+qDZIkSdI4tOxpvhF4ZWY+CNgJeHFEbAW8DvhyZm4BfLk7liRJkmatZqE5M6/MzPO7r68DLgfuBewBLO2+bSmwZ6s2SJIkSePQy5jmiNgM2B44G9goM6+EEqyBu/fRBkmSJOn2ah6aI+IuwInAIZl57W2430ERsSwili1fvrxdAyVJkqSKpqE5ItaiBOZPZOanu9NXRcTG3e0bA1dPdd/MPCIzl2TmksWLF7dspiRJkjStlqtnBHAkcHlmvnfkps8CB3ZfHwic3KoNkiRJ0jgsavjYDwOeCVwSERd2514PvAM4LiKeB/wf8LSGbZAkSZJWW7PQnJnfAGIVNz+mVV1JkiRp3NwRUJIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKhYN3QDNXmcd8aTmNXY+6JQpz59y1O5N6z7puV9o+viSJGl+sadZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVzCg0R8SXZ3JOkiRJmo8WTXdjRKwN3BnYMCLWB6K7aT3gno3bJkmSJM0K04Zm4IXAIZSAfB4rQvO1wAcatkuSJEmaNaYNzZn5PuB9EfGSzDy8pzZJkiRJs0qtpxmAzDw8InYGNhu9T2Z+tFG7JEmSpFljRqE5Ij4GbA5cCNzUnU7A0CxJkqR5b0ahGVgCbJWZ2bIxkiRJ0mw003WaLwXu0bIhkiRJ0mw1057mDYHvRMQ5wJ8nTmbmU5q0SpIkSZpFZhqa39yyEZIkSdJsNtPVM85s3RBJkiRptprpNtrXRcS13Z8/RcRNEXFt5T5HRcTVEXHpyLk3R8TPI+LC7s8TVvcHkCRJklqbaU/zuqPHEbEnsGPlbv8DvJ9bL0t3WGa+e6YNlCRJkoY209UzVpKZnwF2qXzP14Bf357HlyRJkmaTmW5u8tSRwzUo6zbf3jWbD46IZwHLgFdm5m9WUfMg4CCATTbZ5HaWkm6bpf/zuOY1Dnz2ac1rSJKk8ZppT/OTR/48HrgO2ON21PsgZWfB7YArgfes6hsz84jMXJKZSxYvXnw7SkmSJEnjMdMxzc8ZR7HMvGri64j4CHDKOB5XkiRJammmq2fcOyJO6lbDuCoiToyIe9/WYhGx8cjhXpSdBiVJkqRZbaabmxwNfBJ4Wnd8QHdu11XdISKOAR4FbBgRPwPeBDwqIrajjIf+MfDC29VqSZIkqUczDc2LM/PokeP/iYhDprtDZu43xekjZ9wySZIkaZaY6UTAayLigIhYs/tzAPCrlg2TJEmSZouZhubnAvsCv6SserEPMJbJgZIkSdJsN9PhGYcCB06sqRwRGwDvpoRpSZIkaV6baU/zNqObkGTmr4Ht2zRJkiRJml1mGprXiIj1Jw66nuaZ9lJLkiRJc9pMg+97gLMi4gTKcnH7Av/arFWSJEnSLDLTHQE/GhHLgF2AAJ6amd9p2jJJkiRplpjxEIsuJBuUJUmStOA4LlmaJQ775OObPv7L//6LTR9fkqT5bKYTASVJkqQFy9AsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklSxaOgGSBrWK07crenjv3fvU5s+viRJfbCnWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUkWz0BwRR0XE1RFx6ci5DSLi9Ij4fvf3+q3qS5IkSePSsqf5f4DdJp17HfDlzNwC+HJ3LEmSJM1qzUJzZn4N+PWk03sAS7uvlwJ7tqovSZIkjUvfY5o3yswrAbq/795zfUmSJOk2m7UTASPioIhYFhHLli9fPnRzJEmStID1HZqvioiNAbq/r17VN2bmEZm5JDOXLF68uLcGSpIkSZP1HZo/CxzYfX0gcHLP9SVJkqTbrOWSc8cA3wIeGBE/i4jnAe8Ado2I7wO7dseSJEnSrLao1QNn5n6ruOkxrWpKkiRJLczaiYCSJEnSbGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVi4ZugKSFafeTX9S8xhf2+NCU559w0jua1v38Xq+b8vwTT/xw07oAn9v7hc1rSNJCZE+zJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpYtHQDZAktfekEz7R9PFP2Wf/po8vSUOzp1mSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVg2yjHRE/Bq4DbgJuzMwlQ7RDkiRJmolBQnPn0Zl5zYD1JUmSpBlxeIYkSZJUMVRPcwKnRUQCH87MIyZ/Q0QcBBwEsMkmm/TcPEnSODzlhJOb1/jsPntMeX6vE7/atO5Jez+q6eNLml2G6ml+WGY+GNgdeHFEPGLyN2TmEZm5JDOXLF68uP8WSpIkSZ1BQnNm/qL7+2rgJGDHIdohSZIkzUTvoTki1omIdSe+Bh4HXNp3OyRJkqSZGmJM80bASRExUf+TmXnqAO2QJEmSZqT30JyZVwDb9l1XkiRJur1cck6SJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUsUQOwJKkjRvPe3ES5s+/vF7b73K2w496RdNa79xr3tOef64E69pWnffvTds+vjSTNjTLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqlg0dAMkSZJuj699bHnzGo945uIpz3/3v65qWnfLf9yo6ePrtrOnWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWGZkmSJKnC0CxJkiRVGJolSZKkikVDN0CSJEkz88t3X9G8xj1edb/mNeYie5olSZKkCkOzJEmSVGFoliRJkioMzZIkSVKFoVmSJEmqMDRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSapYNHQDJEmSNPtd9R/nNH38jQ7ZccrzV7//1KZ1Ae5+8G7V77GnWZIkSaowNEuSJEkVhmZJkiSpwtAsSZIkVRiaJUmSpApDsyRJklRhaJYkSZIqDM2SJElShaFZkiRJqjA0S5IkSRWDhOaI2C0ivhcRP4iI1w3RBkmSJGmmeg/NEbEm8AFgd2ArYL+I2KrvdkiSJEkzNURP847ADzLzisz8C3AssMcA7ZAkSZJmJDKz34IR+wC7Zebzu+NnAn+bmQdP+r6DgIO6wwcC37udJTcErrmd911dQ9VeaHWHrO3PvDBq+zPP/7pD1vZnXhi1F1rdIWuvbt1NM3Px5JOLVuMBb6+Y4tytkntmHgEcsdrFIpZl5pLVfZy5VHuh1R2ytj/zwqjtzzz/6w5Z2595YdReaHWHrN2q7hDDM34G3Gfk+N7ALwZohyRJkjQjQ4Tmc4EtIuK+EXEH4BnAZwdohyRJkjQjvQ/PyMwbI+Jg4IvAmsBRmXlZw5KrPcRjDtZeaHWHrO3PvDBq+zPP/7pD1vZnXhi1F1rdIWs3qdv7REBJkiRprnFHQEmSJKnC0CxJkiRVGJolSZKkCkPzGEXEHWdyTrqtIuKvIuLwiDg/Is6LiPdFxF8N3S5Jt88q3i82GKItkmZmXk0EjIinTnd7Zn66cf3zM/PBtXONat8R2BvYjJFVUTLzra1rd/XXyczr+6i1EEXE6cDXgI93p/YHHpWZj+2h9prAOzLz1a1rzTYR8UTgr4G1J8719ZxaKCJiB+Bw4EHAHSkbYP05M9drXPfgzHx/yxqV+p8D9szMG7rjjYFTMvMhDWv+Cvg2cBbwTeCczPxDq3ojdQ+g5I2PTTr/AuD6zPxk6zZ09Xw+9yAibgL+Hfin7EJmH1koItYB/piZN3fHawBrj/N3fIgdAVt6cvf33YGdga90x48Gvgo0Cc0RcQ/gXsCdImJ7Vux6uB5w5xY1p3Ay8DvgPODPPdUkInYG/hu4C7BJRGwLvDAz/7GH2msDz+PWL4LPbVTvNZn5rog4nKl3sXxpi7qdDTLz0JHjt0XEng3r3SIzb4qIh0RE5ACfsiNiMfACbv2BsMn/80jdD1Gev4+m/I7vA5zTsmZX93TgaZn52+54feDYzHx847pPBd5Jef2M7k+2Dq/AfwEHAMcCOwLPZuUNsFp5LjBYaAY+AxwfEXtTft7PAq9qXPO+wE6U98fXAw+JiCvoQnRmHteo7iuBR0xx/ljKe3Pz0Nz38zkirmOK9wl6el5FxBLgDcCmlNfNibrbtKzbuYwykuG0iHh6Zv6aqXeDHrcvA48Fft8d3xk4jfL7PhbzKjRn5nMAIuIUYKvMvLI73hj4QMPSj6e80N8beO/I+WspL0x9uHdm7tZTrVGHUX7+zwJk5kURMdWLYwsfA77b1X8rpff18ob1Jh57WcMaq3JGRDwDmHhT2wf4XI/1LwBOjojjgVuuKLS+etM5Gfg68CXgph7qTdg5M7eJiIsz8y0R8R4affCeZMOJwAyQmb+JiLv3UPddwJMzs+VzaCprZOb3ImJR1+v6kYg4C/iXntvRq8z8SLfB12coHwhfmJlnNa55LSVEnAa39Mw9BzgEOJgVry/jtmZmXjdFe66LiLUa1Zys1+dzZq7b6rFn6BPAq4FLgJt7rn1jZr4mIvYFvh4Rz2LqDxDjtnZmTgRmMvP3ETHWjst5FZpHbDYRmDtXAQ9oVSwzlwJLI2LvzDyxVZ2KsyLibzLzkr4LZ+ZPI1b6ENlXsLl/Zj4tIvbIzKUR8UnKpjlNZOb/dn8vbVVjGi8EXkEZnpGUjYGuj4hX0E9v4AbAr4BdRs4l/YTIO2fma3uoM9kfu7//EBH3pPz89+2h7s0RsUlm/h9ARGxKP284Vw0QmKH8Ht8BuCgi3g5cSbly1do2EXHtFOeb9gR2z9nRWvcBLgR2ioidMvO9U99zLLXvSel12xnYoTt9HvDPwLda1QXWmmoIX0SsC9yhYd1RQz2fh7I8M4fabTkAMvO4iLgMOAbYpIe610fEgzPzfICIeAgr/t/HYr6G5q9GxBcp/1FJ2ar7jB7qfjMijgTumZm7R8RWwEMz88geaj8ceHZE/IgyPKOvSzE/7YZoZPfG91La9vaOuqH7+7cRsTXwS0qPTVPdcIHXAlux8rCQXVZ5p9U0dK/FxFWcgZwSEU/IzM8PUPdulLF551NeS/67h7pvAL4REWd2x48ADuqh7rKI+BSl5/OWIV49XE14NuVS7sGUy/hbUOZntHZJZm7fQ53JJj+XT1rF+RZ+RvldPgx4XWb+pYeaAEcCJ0TEP2TmjwEiYjPKFeA+3h+h5+fzyPCM0R6lpOSuO2Rm6/z1poj4b8qQhT6fzwDPH6l3WUQ8HOhjOOEhlCFPv+iONwaePs4C82oi4KiI2IsVY6i+lpknTff9Y6r5BeBo4A2ZuW1ELAIuyMy/6aH2plOdz8yfNK67IfA+yjiioFz2e1lm/qpl3a7284ETgW0o/+53Af4lMz/UuO5pwKco4w9fBBxI+VTfrDc0Slf+/sB9M/PQiLgPsHFmNh9j29V/APBBYKPM3DoitgGekplv66H2dcA6lBf+G+hvrO1oG+5IufT3u57qbUgZexrAtzLzmh5qHj3F6exh7PitJuT1MUkvIi4YKDQPJiIeCjyU0tN8X+DHlB7mbwHLMrPZfJiIeBHwT6y4ivB7ygTjD7aqOU1ben0+dzXXBf6RctXwpMx8ZeN6Hwe2pIwvnhie0fz5PFJ/Z249D+WjPdRdC3gg5bXzuxMTbcf2+PMtNHcz/b/Yx6oCU9Q+NzN3GH0xjogLM3O7Httwd1bu/fy/vmovFBFxXmY+pBsbt0137szMfGTDmh+kvPDtkpkP6iaHnZaZO1TuOq76Z1LGx3145Hf70szcuo/6fYqBV+Hp2rA+pcd19Ln8tdZ1hzDVrPo+Am1EvD4z376K23bIzHMb1x9kwuekNmxGmUD/Msq8mLWnvcN4at6Fkj1uNca5Ub2hV9W6G6UH9FmUCY+H9dSpdEkfHXarqP0xYHPKsKOJ4ZqZbSfLT9TemltfBR5bWJ93wzOyzPT/Q0Tctc9PkZ3ro6ydO7HEyk6UFS2ai4inAO8B7glcTZkxezllZYmWdf9zitO/o/RanNyo5gGZ+fFJYwNv0XJMYGfik+uVUZYw+gVlEmhLf5uZD46IC+CWyWF9jQWEMq74nElj129sWTAipl2eaGLcWgODrMIzobuC8jLK79SFlB7nb7HyePIWdXu9mhART6cMnbtvRIz+m64H/Hbqe43P5MDcDad7BrAf5TVsSeMmLB5iwmdEbMmKcc0PA9an/H41u0I31Wv16GtJ49fsoVbV2pAy3OjpwFHA9j1nkm9HxFaZ+Z0ea05YQlmModde2Yh4E/AoSmj+PLA78A3A0FzxJ+CS7pP86Ez/1p9yXkFZRWLziPgmsJiyykEfDqW8uX4pM7ePiEdTXvxbW5tyCej47nhvyuWg50XEozPzkAY11+n+nmoMYB9P0rdFxF0pL4iHU97kX9645g3dVZSJD2SL6XdG9DURsflI/X0oE7Zaes80tyWNQmQOtwrPhJdRJml9OzMf3YWct/RQ9yN0VxMAMvPiKJNrWw3BOYcyGeverPzveh1ltZbmumFt+3V/bqR0NiyZGHfb2E3R84TPiLiG8rw9i7IizTsy8wcta3beTfkA+AVWzLnpxYDP558AyylDB/9AeU8cbVfrzp2HAwcOMM8J4FLgHrR/j5hsH2BbyrDY50TERox53Pp8Dc2fo9/luIDS8xURj2TFeJrvjXs8zTRuyMxfRcQaEbFGZp4REe/soe79KUMGboRbhhGcBuxKWeqmhc8BZOatgkREPPnW3z5emXlK9+XvKL0VffhPyoShjSLiXykvDv/cU22AFwNHAFtGxM+BH1HW1m0mM/v6t12VXlfhGfGnzPxTRBARd8zM70bEA3uo2+vVhMz8EeX36Etdr9xEz+4VfbxuRlnW7q6UtYL3yczvR8SPegrMMMyEz80HuAIL8GBKL/4TKat1HAN8ueeeyL6fz//Oig9BQ0zkHmIJ2gkbAt+JiHNYeRLiUxrX/WNm3hwRN0bEepSr7vcbZ4F5GZqzLD92B1Y8IZqG12nGTD0gIvqarfrbbqzY14BPRMTVNL583rkXped34oV4HcrqITdFRKtJJV+OiMdPfnOLiOdQguT/tigaq9jUZELLKxmZ+YmIOA94DOUD2Z7Z4/JgmXkF8Ngo67qu0dd4RLhlYsc/sGJi71cpY6tbB6uhVuH5WTcO8jPA6RHxG8oQoNaGuJow8fr5H5SezwA+FBEv72Hy9nJKL/dGlKuC36efK1UAZOap3RCkiQmfL+9hwuehkz4UTW5Tk9ewzLyQ0tP8um6C2H7A4RHx2uxvWbRen8+Z+eZWjz3D+j+BW89z6smbe643YVn32vkRyoez3zPmDWzm3URAgIh4FLCUMjN4Yh3MA1tNpImpZ51P6GW2aqYlAuQAABqkSURBVBdm/khZuml/Sg/KJ1pPOIiI51GC6lcp/9aPAN5OeWF6czbYejkinkBZseMJmfn97tw/AX8P7J6ZPxt3za7Ggd2XD6OMmfpUd/w04LzMbDpEI8qyPVtk5tHd8Iy7dL11LWtOOW58Qg+XGImybNJalOc0wDOBmzLz+au+19hqPxX4u+6wl1V4JtV/JOW5fGo2Xh4sIu5HuZqwM/AbuqsJrXteI+Ii4HGZeVV3vBFlkuu2Let2te5KGVK2H+Wq2d2Ax2fDVWkiYsvu6sGUY/YbjtUnIv5CuXR+HOWD2EoJOhuvQd+9bu1Lec28AXhjZn67Zc1J9XtbVWsV831u0Xq46KrmOWVm03lOI/U3pbxffSnKBiNTbnDTsP5mwHqZefFYH3eehubzgL/PzO91xw8AjsnMhwzbsnZiZM/17ufdEvhCT5c5N6ZsfxvAOZnZvFcsIh5DGXu5J2VNyB2AJ2Xmb3qofQblTf6G7ngtypt8s+EE3QSHJcADM/MBURbnPz4zH9aq5kjdVZpqiEyDNlw0OUBNdW6ui4gNprs9y1a0fbSj16sJMWmWf0SsAVzU98z/LqxPTE68T2Y22co7Io7IzIO615HJMhuu9x5lovrTKD/njZQP/ie2ft3srgI+ndLjeQJwXGZe3bLmFG14I/A/mfnTkXMHZeYRjeodON3tPXxAuYgy72OleU6Z2XzN94h4AWWo0QaZuXlEbAF8KDMf06hebx9E52tovmUpsOnONah7V+BNrPgkeybw1j7GkHUfFP6OMhP625Stnv+Qmfs3qjfUygajbXg45RL2WcC+mfmn1jW7ut+jbFrz6+54fcqkrWbjTiPiQmB74PxcseRb89/p2SAizqcszfXD7vh+wAk5aZmyBnWfCryTMus+oPlOcT/i1pshTMjMHOvYvCnqT3VV4XeUqygXNqz7XsqH/E92p55BWV/1Va1qzqBNm2bjNe6HFhH3ovSwvwJ4bWZ+rGGtmylzXCaWQF0pePQw1pVuyOI1wIsz84zu3K2WO5wvImJZZi7pwvP2XYfaOZm5Yw+1L6R0pJ098n7VbAm8Pj+IzssxzZRxLUcCEy8C+1PGt7R2FOXS177d8TMpM2enXSdyTCIz/9ANlzg8M98V3fJkjUysbLA2pQf0Isqb/TbA2ZSZu03Eyjst3ZEyzvfqKIP1moWaEe8ALhh5gj6S9mO4/pKZGRET403Xqd1hnCLiXZRVFP4InEqZoXxIZn68h/KvBs6IiCso/+ebAn3sUPgu4Ml9jR3PzKG39F3S/ZmYE/BE4FzgRRFxfGa+q1HdV1J6Px9O+f9dSumNbCoi/pfpxzA3DXIR8aypzmc/G0A8mBKYd6WsaNH6/XGqq3AT//Z9raTxc2APyo5xJ2Tmv7esHRHTjtXu4YPCUPOcAP6cmX+ZGD8fZaO3Zj20I73nu0/uPIuIsY7nnq89zXekzPafeBH+GvBf2XC3o67urTYymepco9oXUHYbOgx4XpatK5svbh4RxwL/mpmXdMdbA6/KzGe3rDu0iLgH8Lfd4dmZ+cvG9V5F2exiV+DfgOcBn8zMacfNjbH+hZm5XTcmcE/KEntn9DVEontOj+7y1PS53NX8ZuvhL5PqDXr1ppsktXdm/r47vgslvO5F6W3eqlHdF1GGz/W6qkM3XnyVMvPM6W4fQ/3DRw7Xpnz4Pz8zmy1TGhFvAZ5EWcP/WMpY+eZBKiL2oGye8oHu+BzK5Muk9HIfP939x9SGC7phCmtT1iO/C/A3mbllo3rLgZ9S5vecza3Hj7f+/RpknlNX+12UtdafBbyEkk2+k5lvaFx3qo2Sxno1YV71NEe35mX3hvre7k+f/hgRD8/Mb3TteRjll7YPh1C2KD2pC8z3o5+Z/ltOBGaAzLw0InrbAXFAa1Jm3y+irJLygGy4Y1tmvjsidgWupawK88+Z+aVW9aawVvf3EygB59cxzSz8cYqIF1Ne7C/ujtePiOdl5n81Lr0sIj5FGQI0umxSq9VwBlmXesQmwOhkwxuATTPzj9FuJRwoW+2eHxFnA0f1+Hv9oxxwx9TMfMnocTe8r9kQic4bgSsoV4q2Bd7ePY9br+H7Gsqwmwl3oFzVWIdyNbZ5aKYMWaTriXxO97rScp7TPSidHPtRJql/jvLaeVnDmrfIzIk9Km4GlkZZ5/8ZwCd6KP86SsfOJZRtwz/PmNdLHtV1Yt0LuFNEbM+KDyjrAXcea6351NM8+okiIk7MzL17rr8tZeeZu3anfkNZtWOsszdn0I41KCsrXNtDrWMoG8h8nPLGfkBXu4+NVQYRZf3rp1M2cZnYYCRbXG4bGYoCt76U+Cfgh8AbMvPL4649qR3voPQw/5EyVu1uwCmZ+bfT3nE8tae6gtPHNstTrYqT2cNqOEPoJkrtBUzs5PlkymZN7wGOaDU/oqu9BmX3rudQwtwxlAD944Y1B32/mKI9awEXZ+aDGtbYdLrbW43jjohzM3OHkeP3Z+bB3dffzsydWtSdLborZftR1m5+a2YeXrnL6tRaj3Kl/V6U5+/p3fGrgQszc49WtYcSZdLlsykfxJaN3HQdZfLn2Do65ltovuWNtI831Um116AskH9c90tLH6F1pP4ngRdR9nk/jxLc39uN22pZd21WXkP3a8AHJ48rmk+6iYDb9DFEoNKONYGtKb2wW/dQb33g2ixrcK8DrNt6WEpX92Jg2+xerLqf++LsaemkvkTELpn5lVjFuu8Ne7hH27CEsqRiAN/IzGWVu4yz9l9TQvOTKa8jOwKfz8x/alRvsPeLrubomOo1KMtYHpeZr+u5HRsCv8qGYSAifpCZ91/FbT/MzM1b1R6pswVlaNtWrFi3OFvW7sLyEymBeTNKiD0qM3/esObJlA67b1GG/KxP6dl/WTac0NvV3oKyac+vKVf6P0JZoOCHwPMz89zG9ffOzBNb1phXwzNYeaB5r58GssxMPZjyotdbWB6xVWZeGxH7Uy6FvJYSnpuG5iw7l30A+BLl37zPXRCHcgVluMKgoTkzbwIumjQ2somIWEaZ6HoM8Jvu0t/1099rbL4IHBcRH6L8jr2IMhmxqYi4N2Wb9Id1db9BeeNpsg44ZULpVyihcbIEmofmzFwWEf9HFypiZJvnViLiHym9RNcCR1KunPy564j4AWXYWQuDvV903j3y9Y3ATxr+bgEQETtRJjL/GjiUMhxkQ2CNiHhWZrZ6Xp0dES/IzI9Mas8LGfPmE9M4mrK61WGUiYnPoe1EwKWUTo0vAG/JzEtb1ZrkfhNzmaKscX8NsEn2s4Tk0ZSr7etRxnEfQrl69XfA+1kxD6iVUyLi7ykfUG7Jt5n51nEVmG89zTdR3sgDuBNlv3eg7VJRI/XfSLl8/SlGAkX2sL5qRFwGbEdZtun9mXlm9LCWbfS8kcxsEBEnUi4hf5mVx7o2Xax+SBFxf8qbzNMpl7+OpqxN3fwFpAtPL2TFboinAf/dfWhoWfd0yvNpYpzpAcD+mblry7pDiVtvhrAJZdJl0x79iHg75f/ziilu27pV2Bj6/WJSW5r39nZ1lgGvp1yJPIKy2sC3I2JLynjbJr3tUXalm5gbMDGh9SGU1Y/2zG5jm5Yi4rzMfEiMTJCPiK9n5t/V7ns7693Mihww+v/aeunKlSa+jXsiXKX2LUPpJl9dmGqYXYP6p9Itk0m56g5AZk43X+S21ZhPoXloUdZZnSyz8fqqXe2XUnqXL6JcDtoE+HirF4SRugtxI5kpF63PxovVzwZdgH0SZfb5zZTe5/f18cGwb6sYS93shT8G3n0xht0MYWtWLFP59b4mSw1hut5eoGVv7+RQc/no+Ome5gnsAkx8CLssM7/Sst6k2t+k9HieQLmi83PgHdlwff0hjHwYhJU/EDb/MDhpnkDv4T0iLm09VHG+Dc8YVA64zmqWpcdGlx/7Sfem19paE4G5a8f/6ya0zFsLIRxPJSK2ofQ2PwE4kTIL++GUN6BmPQhRVqF5M2V95kWsePFv/WH0mog4gDIkBcq4xJbLNa3b/f1Ayg6XE+u8Tozxbe2GzPxVRKwREWtk5hndpNemoqxi8GJKTySUoTgfyParowzl/azo7f0Kk3p7aTv06OaRryev7NS8B60Lyb0F5UkOoayk8FLKh5VdgGl37ZuLMnPNActv2c1BCWDz7mu64+adh8BZEfE3ObKi17jZ0zxGXU/NscCnprrU2KjmAZn58VX1UvXQO3UU5cV2dCOZRZnZx+YTg4gVO7etpI8rCkPprij8ljLm9MTRSZAR8enMbLaBT0R8l7Iu9ORLbk3XG42ITSgB56GU/++zKGOam+4UFxGnUdZLvq47XpeyZfpujet+ibJCyr9Rej6vBnbIzJ0b170Y2DlXXh/6rJynu10O2dtbGZKydmbO6w4PtRUDrc4yUv87wP2BH1GGAo19KUV7msfrKZQxn8d345k+RZkY2HIizcTOcOtO+13t/AOll+ilsGIjmYHa0pclI1+vTdnNbIOB2tJcNyTjxMx8+1S3twzMnd9l5hca17iV7nnbfHvfKUxeL/kvlIktre1B6X18OSs2QxjbBJppBGVN6Ak30HCC1iwwWG/vwL2Qg4jhd+ZbMKYKxRHxpMw8pacm7N66gD3NjXRLr7yRMnFoXr9QRcRigMxcPnRbhhIR38jMZluHDy0ivpaZj6h/Z5Pa76BsJvNpVp542WSHvG41klW+MLae8BkRbwD2BU7q2rEX5cP3lB9axlj3uZTxxN9vWWek3qLMvDEiXkMZ+jKxVNRelHkR7171vecue3v7FQPvzLfQ9TkRsau3LWXsOpTXs4vG+fj2NI9ZRGxGecN7OuVS8msa1/uXaW7OzDy0Ud2gLN9zMOVFKLo3g8PHubzLbBQrb3e8BqXneaie/r6cHmUr795XhmHFMkWjPfwtd8gbXZv4LZTf895k5r92s8AnPoQ9JzMv6KH0ZsAB3WvYMuDrlDedVmu7ngM8ODPfFRFnUN7oAnhRNl7PdUjzvRNlFhp0Zz71d9UoIl4GvIAVy3N+PCKOyDFuJmNP8xhF2QZ2LcqWoL2Ma46IV05xeh3KFpZ/lZl3aVT35ZQJYQdl5o+6c/ejrKpwamYe1qLubNC9wU+4kTJ+6j2jEyLnmyFXhhlSHysKTFP77qzYhGFiuEgfde9EeeN5FXCvViFvyH9bLUzR4858KiJix8zsZS3ubn7EQ7PbQjzKJlzfGueYZkPzGEXElpn53QHrrwu8jBKYj6MEuasb1boA2DUzr5l0fjFl/d55+2YYEWtm4zWCNfwk164NvV5a7GoOtV7yP1M2crkLcAFlM5evZ+aVjer9jLJr2JT6+P/VwhAD7My3kEXE0yidZ9dF2b9ie+BtrYbUjdS9hDJ5+U/d8drAudmtyz0ODs8Yr99ExJHAPTNz94jYivKp58iWRSNiA+AVlMk7SymXPH/TsiZlqblrJp/MzOXzfck54AcRcQLlRffyoRvTl4jYmVvvtPTRhiWnm+Q6nz/tHwrsxKT1knuo+1TKlZPPAWcC355482lkTUpAn8+T/jSwGG5nvoXsjZl5fEQ8nDI05j2Uq9CtdwQ8mrL75End8Z6UFZ/Gxp7mMYqIL1D+096QmdtGxCLggnF+ypmi5r9T3uyOAD4wsWxTa9P1wA3RO9enrkf/GZQ1i9egbPBxbA6zfXovIuJjwObAhaxY9i1bT4qbpj2HZOZ/NHrs61gRyu9M/zuLLsvMJd0Slttn5s0RcU5m7tiybld7XcpY6odT5mZc1WqC63x/ndDsEAPtzLeQTQy9ioh/Ay7JzE/2NRyrm3P0cLrVvMY9H8TQPEYRcW5m7jD6yxGNt47sXhD+TOkh6nOrztFdh1a6iQU0AzwiHkGZlX03yk5Th2bmD4Zt1fhFxOXAVjlLXjAi4v8yc5Oh29HCgOslb02ZjPdIyqTLn1KGZ0w32Xh16jmmWZqHIuIUyo6Lj6Vsl/5H4JzM3LZRvbWBF1HWaL4EODIzb2xRy+EZ43V9RPwVXXiNsl3q71oWzMw1Wj7+NHUX7AzwiFiTMj7uOZThCu+h7I73d8DngQcM1rh2LqXMQm8yvvV2mHeX9CPi/sBG3Hq95E2Bl/TQhHdShmX8J2Uc4A2V719dj2n8+JKGsS+wG/DuzPxtRGwMvLphvaWU9d2/Tlmr+UGUHSDHztA8Xq+gTDDYPMo+94uBfYZtkhr4PnAG8O+ZedbI+RO6nud5IyL+l/IhcF3gOxFxDiuvlTzUxgCzosd7zP4DeP3EzG/KJhhLI2IJZRvxJ7csnplPnPg6ItaPiPtk5sXT3Wc16/WxXKGknmXmHyLiasowie9TroS3XP99q4lhsN28smardRiaxygzz4+IRwIPpPSEfa+H3hr1b5tVjR0faoxvQ5+l9H5+fdL5R1IuvzUzaWzxSjdRNoWYbzabKqRm5rJu7eSmIuKrlB0QF1HGri+PiDMzc8rVSyRpKhHxJsoQrwdS5nmtBXycsjpPC7fkrG7DpEZlDM0t7MiKFQYeHBGtVxhQT0Z3ipvqSTkPAzOUoQKvnxzmIuJ6yqYfzVaGycz5vmHMZGtPc1sfHxLumpnXRsTzgaMz803duqeSdFvsRVlm7nyAzPxFN8m4lW0jYmIifgB36o7HPrfL0DxGq1phADA0zw+D7hQ3kEF7PxeYcyPiBZn5kdGTEfE84Lwe6i/qxh7uC7yhh3qS5qe/ZGZGxEQn0zq1O6yOPudYGZrHawmzaIUBjVdmLp34ulvybOl03z9PDN37uZAcApwUEfuzIiQvAe5A6blp7a3AF4FvZOa53Q6fLcchSpqfjouIDwN3i4gXAM8FPlK5z5zgknNjFBHHAy9ttYOWZo+FssZsRBwDfGUVvZ+Py8ynD9Oy+avbzGTr7vCyzPxKT3U3mDw5LyLum5lTbaEuSasUEbsCj6MMkfhiZp4+cJPGwtA8BpNWGNiOMnNzNqwwoEYWUGjeCDgJ+AtT9H5m5i+HapvGq1vxZ/eJTXq6HU2Py8ytp7+nJC0MDs8Yj8FWGFB/Ju8UN2niwbzcWSozrwJ2ntT7+bm+ej/Vq7cD/xsRT6TMev8oZZ1oSaqaZsUjAObDe6SheTwGW2FA/VmAqzncIjPPoKxNrXkqMz8XEWsBp1Gumu2ZmY5pljQjE++REfFW4JfAxyidSvtTXlPmPIdnjEFEXLqqS5gRccnEotuSNNuMLqXY2QW4AvgxzNulFCU1EhFnZ+bf1s7NRfY0j4crDEiaq5ZNOu5jeTtJ89dN3SpAx1I+kO/HimV45zR7msfAFQYkSZKgW8P/fZQdABP4JnBIZv54uFaNh6F5DFxhQNJcFRGXMP3knW16bI4kzVqG5jEaan1VSbq9ImLT6W7PzJ/01RZJc19EPAD4ILBRZm4dEdsAT8nMtw3ctNVmaJYkAbdcNduhOzwnM68esj2S5p6IOBN4NfDhzNy+O7fKBRPmkjWGboAkaXgRsS9lY6anAfsCZ0fEPsO2StIcdOfMPGfSuRsHacmYuXqGJAngDcAOE73LEbEY+BJwwqCtkjTXXBMRm9PNleg+fF85bJPGw9AsSQJYY9JwjF/h1UhJt92LgSOALSPi58CPgAOGbdJ4GJolSQCnRsQXgWO646cDnx+wPZLmoMy8AnhsRKxD+TB+3dBtGhd7ESRpAYuI90fEzpn5auDDwDbAtsARmfnaYVsnaa6JiLdHxN0y8/rMvC4i1o+IOb9yBrh6hiQtaBHxMuAZwMbAp4BjMvPCYVslaa6KiAsmVs0YOXd+Zj54qDaNiz3NkrSAZeb7MvOhwCOBXwNHR8TlEfEv3XqrknRbrBkRd5w4iIg7AXec5vvnDHuaJUkriYjtgaOAbTJzzaHbI2nuiIjXAE8BjqasoPFc4LOZ+a5BGzYGhmZJEhGxFrAbZajGY4AzKUM1PjNowyTNORGxG/BYIIDTMvOLAzdpLAzNkrSARcSuwH7AEymbmxwLfCYzrx+0YZLmnIhYE/hiZj526La04JJzkrSwvR74JPCqzPz10I2RNHdl5k0R8YeIuGtm/m7o9oyboVmSFrDMfPTQbZA0r/wJuCQiTgduuWKVmS8drknjYWiWJEnSuHyu+zPvOKZZkiRJY9MtM7dJZn5v6LaMk+s0S5IkaSwi4snAhcCp3fF2EfHZYVs1HoZmSZIkjcubgR2B3wJ0O4zed8gGjYuhWZIkSeNy4xQrZ8yLscBOBJQkSdK4XBoRf0/ZTnsL4KXAWQO3aSzsaZYkSdK4vAT4a+DPwDHAtcAhg7ZoTFw9Q5IkSapweIYkSZJWS22FjMx8Sl9tacXQLEmSpNX1UOCnlCEZZwMxbHPGz+EZkiRJWi0RsSawK7AfsA1lV8BjMvOyQRs2Rk4ElCRJ0mrJzJsy89TMPBDYCfgB8NWIeMnATRsbh2dIkiRptUXEHYEnUnqbNwP+E/j0kG0aJ4dnSJIkabVExFJga+ALwLGZeenATRo7Q7MkSZJWS0TcDFzfHY6GywAyM9frv1XjZWiWJEmSKpwIKEmSJFUYmiVJkqQKQ7MkzQERkRHxsZHjRRGxPCJOqdzv2RHx/vYtlKT5zdAsSXPD9cDWEXGn7nhX4OcDtkeSFhRDsyTNHV+grIEKZR3UYyZuiIgdI+KsiLig+/uBk+8cEU+MiG9FxIYRsTgiToyIc7s/D+vpZ5CkOcnQLElzx7HAMyJibco2tWeP3PZd4BGZuT3wL8DbR+8YEXsBrwOekJnXAO8DDsvMHYC9gf/uof2SNGe5I6AkzRGZeXFEbEbpZf78pJvvCiyNiC0oa6SuNXLbo4ElwOMy89ru3GOBrSJi4nvWi4h1M/O6Rs2XpDnN0CxJc8tngXcDjwL+auT8ocAZmblXF6y/OnLbFcD9gAcAy7pzawAPzcw/tm2uJM0PDs+QpLnlKOCtmXnJpPN3ZcXEwGdPuu0nwFOBj0bEX3fnTgMOnviGiNhu/E2VpPnD0CxJc0hm/iwz3zfFTe8C/i0ivgmsOcX9vgfsDxwfEZsDLwWWRMTFEfEd4EUt2y1Jc53baEuSJEkV9jRLkiRJFYZmSZIkqcLQLEmSJFUYmiVJkqQKQ7MkSZJUYWiWJEmSKgzNkiRJUoWhWZIkSar4/wLUYpu7Qg/GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Make'], data = data,order = data['Make'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), <a list of 4 Text xticklabel objects>)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Wheel Drive'], data = data,order = data['Wheel Drive'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), <a list of 2 Text xticklabel objects>)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Retail'], data = data,order = data['Retail'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Names:  ['SILVER' 'black' 'WHITE' 'Black Clearcoat' 'Blue' 'Copper' 'silver'\n",
      " 'Green' 'Black' 'BLACK' 'Red' 'White' 'Grey' 'Silver' 'Maroon'\n",
      " 'Summit White' 'Yellow' 'GRAY' 'BROWN' 'P8163' 'Billet Metallic' 'GREY'\n",
      " 'Brown' 'BLUE' 'Beige' 'RED' 'Cream' 'Gold' 'Black Cherry']\n"
     ]
    }
   ],
   "source": [
    "# Unique Manufacture names.\n",
    "print(\"Color Names: \" , data['Colour'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Colour'].replace(to_replace =[\"silver\"],  \n",
    "                            value =\"SILVER\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Silver\"],  \n",
    "                            value =\"SILVER\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"black\"],  \n",
    "                            value =\"BLACK\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Black\"],  \n",
    "                            value =\"BLACK\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"White\"],  \n",
    "                            value =\"WHITE\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Blue\"],  \n",
    "                            value =\"BLUE\",inplace=True) \n",
    "data['Colour'].replace(to_replace =[\"Red\"],  \n",
    "                            value =\"RED\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Grey\"],  \n",
    "                            value =\"GREY\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"GRAY\"],  \n",
    "                            value =\"GREY\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"Brown\"],  \n",
    "                            value =\"BROWN\",inplace=True)\n",
    "data['Colour'].replace(to_replace =[\"P8163\"],  \n",
    "                            value =\"GREY\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Names:  ['SILVER' 'BLACK' 'WHITE' 'Black Clearcoat' 'BLUE' 'Copper' 'Green' 'RED'\n",
      " 'GREY' 'Maroon' 'Summit White' 'Yellow' 'BROWN' 'Billet Metallic' 'Beige'\n",
      " 'Cream' 'Gold' 'Black Cherry']\n"
     ]
    }
   ],
   "source": [
    "# Unique Manufacture names.\n",
    "print(\"Color Names: \" , data['Colour'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17]), <a list of 18 Text xticklabel objects>)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "plot = sns.countplot(x = data['Colour'], data = data,order = data['Colour'].value_counts(ascending=False).index)\n",
    "plt.xticks(rotation = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = data.drop(['Make','Model','Inv','VIN',],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>205000</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>206598</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Car Name Wheel Drive           Colour  Odometer Retail  \\\n",
       "0  2002  Chrysler Concorde         FWD           SILVER    245305   AUTO   \n",
       "1  2004       Jeep Liberty         4WD            BLACK    205000   AUTO   \n",
       "2  2005   Chevrolet Malibu         FWD            WHITE    199885   AUTO   \n",
       "3  2006         Ford F-150         4WD  Black Clearcoat    176880   AUTO   \n",
       "4  2006      Nissan Altima         FWD             BLUE    206598   AUTO   \n",
       "\n",
       "   Price  \n",
       "0   1200  \n",
       "1   1200  \n",
       "2   1200  \n",
       "3      0  \n",
       "4   1200  "
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Wheel Drive</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Retail</th>\n",
       "      <th>Price</th>\n",
       "      <th>No_of_Years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Chrysler Concorde</td>\n",
       "      <td>FWD</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>245305</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jeep Liberty</td>\n",
       "      <td>4WD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>205000</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Chevrolet Malibu</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>199885</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Ford F-150</td>\n",
       "      <td>4WD</td>\n",
       "      <td>Black Clearcoat</td>\n",
       "      <td>176880</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Nissan Altima</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>206598</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>Chevrolet Spark</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>32700</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>Hyundai Veloster</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>47314</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>16995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>Kia Soul</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>38790</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>17900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>17836</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>Nissan Micra</td>\n",
       "      <td>FWD</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>20225</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>14300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Car Name Wheel Drive           Colour  Odometer Retail  Price  \\\n",
       "0    Chrysler Concorde         FWD           SILVER    245305   AUTO   1200   \n",
       "1         Jeep Liberty         4WD            BLACK    205000   AUTO   1200   \n",
       "2     Chevrolet Malibu         FWD            WHITE    199885   AUTO   1200   \n",
       "3           Ford F-150         4WD  Black Clearcoat    176880   AUTO      0   \n",
       "4        Nissan Altima         FWD             BLUE    206598   AUTO   1200   \n",
       "..                 ...         ...              ...       ...    ...    ...   \n",
       "215    Chevrolet Spark         FWD             BLUE     32700   AUTO  14300   \n",
       "216   Hyundai Veloster         FWD            WHITE     47314   AUTO  16995   \n",
       "217           Kia Soul         FWD            WHITE     38790   AUTO  17900   \n",
       "218       Nissan Micra         FWD            BLACK     17836   AUTO  14700   \n",
       "219       Nissan Micra         FWD            WHITE     20225   AUTO  14300   \n",
       "\n",
       "     No_of_Years  \n",
       "0             18  \n",
       "1             16  \n",
       "2             15  \n",
       "3             14  \n",
       "4             14  \n",
       "..           ...  \n",
       "215            1  \n",
       "216            1  \n",
       "217            1  \n",
       "218            1  \n",
       "219            1  \n",
       "\n",
       "[220 rows x 7 columns]"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column showing the number of years. \n",
    "year = 2020\n",
    "cars['No_of_Years'] = cars['Year'].apply(lambda x :year - x)\n",
    "cars.drop('Year',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the categorical values into dummies using the get_dummies function  \n",
    "df=pd.get_dummies(cars['Car Name'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Car Name'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Wheel Drive'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Wheel Drive'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Colour'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Colour'],axis=1,inplace=True)\n",
    "df=pd.get_dummies(cars['Retail'])\n",
    "cars=pd.concat([cars,df.iloc[:,:-1]],axis=1)\n",
    "cars.drop(['Retail'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odometer</th>\n",
       "      <th>Price</th>\n",
       "      <th>No_of_Years</th>\n",
       "      <th>BMW 3</th>\n",
       "      <th>BMW X3</th>\n",
       "      <th>Buick Encore</th>\n",
       "      <th>Buick Regal</th>\n",
       "      <th>Buick Verano</th>\n",
       "      <th>Cadillac ATS</th>\n",
       "      <th>Cadillac SRX</th>\n",
       "      <th>...</th>\n",
       "      <th>Cream</th>\n",
       "      <th>GREY</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Green</th>\n",
       "      <th>Maroon</th>\n",
       "      <th>RED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>Summit White</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>AUTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>245305</td>\n",
       "      <td>1200</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>205000</td>\n",
       "      <td>1200</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199885</td>\n",
       "      <td>1200</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>176880</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>206598</td>\n",
       "      <td>1200</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Odometer  Price  No_of_Years  BMW 3  BMW X3  Buick Encore  Buick Regal  \\\n",
       "0    245305   1200           18      0       0             0            0   \n",
       "1    205000   1200           16      0       0             0            0   \n",
       "2    199885   1200           15      0       0             0            0   \n",
       "3    176880      0           14      0       0             0            0   \n",
       "4    206598   1200           14      0       0             0            0   \n",
       "\n",
       "   Buick Verano  Cadillac ATS  Cadillac SRX  ...  Cream  GREY  Gold  Green  \\\n",
       "0             0             0             0  ...      0     0     0      0   \n",
       "1             0             0             0  ...      0     0     0      0   \n",
       "2             0             0             0  ...      0     0     0      0   \n",
       "3             0             0             0  ...      0     0     0      0   \n",
       "4             0             0             0  ...      0     0     0      0   \n",
       "\n",
       "   Maroon  RED  SILVER  Summit White  WHITE  AUTO  \n",
       "0       0    0       1             0      0     1  \n",
       "1       0    0       0             0      0     1  \n",
       "2       0    0       0             0      1     1  \n",
       "3       0    0       0             0      0     1  \n",
       "4       0    0       0             0      0     1  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.drop(['Year'],axis=1,inplace=True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars.drop('Price',axis=1)\n",
    "Y = cars['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Odometer</th>\n",
       "      <th>No_of_Years</th>\n",
       "      <th>BMW 3</th>\n",
       "      <th>BMW X3</th>\n",
       "      <th>Buick Encore</th>\n",
       "      <th>Buick Regal</th>\n",
       "      <th>Buick Verano</th>\n",
       "      <th>Cadillac ATS</th>\n",
       "      <th>Cadillac SRX</th>\n",
       "      <th>Cadillac XTS</th>\n",
       "      <th>...</th>\n",
       "      <th>Cream</th>\n",
       "      <th>GREY</th>\n",
       "      <th>Gold</th>\n",
       "      <th>Green</th>\n",
       "      <th>Maroon</th>\n",
       "      <th>RED</th>\n",
       "      <th>SILVER</th>\n",
       "      <th>Summit White</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>AUTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>245305</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>205000</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>199885</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>176880</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>206598</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Odometer  No_of_Years  BMW 3  BMW X3  Buick Encore  Buick Regal  \\\n",
       "0    245305           18      0       0             0            0   \n",
       "1    205000           16      0       0             0            0   \n",
       "2    199885           15      0       0             0            0   \n",
       "3    176880           14      0       0             0            0   \n",
       "4    206598           14      0       0             0            0   \n",
       "\n",
       "   Buick Verano  Cadillac ATS  Cadillac SRX  Cadillac XTS  ...  Cream  GREY  \\\n",
       "0             0             0             0             0  ...      0     0   \n",
       "1             0             0             0             0  ...      0     0   \n",
       "2             0             0             0             0  ...      0     0   \n",
       "3             0             0             0             0  ...      0     0   \n",
       "4             0             0             0             0  ...      0     0   \n",
       "\n",
       "   Gold  Green  Maroon  RED  SILVER  Summit White  WHITE  AUTO  \n",
       "0     0      0       0    0       1             0      0     1  \n",
       "1     0      0       0    0       0             0      0     1  \n",
       "2     0      0       0    0       0             0      1     1  \n",
       "3     0      0       0    0       0             0      0     1  \n",
       "4     0      0       0    0       0             0      0     1  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1200\n",
       "1    1200\n",
       "2    1200\n",
       "3       0\n",
       "4    1200\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "minma = MinMaxScaler()\n",
    "minma.fit(X_train)\n",
    "X_train = minma.transform(X_train)\n",
    "X_test = minma.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.73\n",
      "Accuracy for Training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(n_estimators=200)\n",
    "rf_reg.fit(X_train,y_train)\n",
    "train_pred = rf_reg.predict(X_train)\n",
    "test_pred=rf_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(rf_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(rf_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 4.5\n",
      "Tree on test set MAE%: 12.0\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2720.8104523519896"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.49\n",
      "Accuracy for Training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "dec_reg = DecisionTreeRegressor()\n",
    "dec_reg.fit(X_train,y_train)\n",
    "train_pred = dec_reg.predict(X_train)\n",
    "test_pred=dec_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(dec_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(dec_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 0.0\n",
      "Tree on test set MAE%: 16.4\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3771.415667407086"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: -790058709270002982191104.00\n",
      "Accuracy for Training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg = reg.fit(X_train,y_train)\n",
    "train_pred = reg.predict(X_train)\n",
    "test_pred = reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 5.2\n",
      "Tree on test set MAE%: 6782234639112.4\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4695386783326496.0"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Neighbor Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.54\n",
      "Accuracy for Training set: 0.58\n"
     ]
    }
   ],
   "source": [
    "k_reg=KNeighborsRegressor()\n",
    "k_reg = k_reg.fit(X_train,y_train)\n",
    "train_pred = k_reg.predict(X_train)\n",
    "test_pred=k_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(k_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(k_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 14.2\n",
      "Tree on test set MAE%: 16.3\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3595.8954757789156"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.44\n",
      "Accuracy for Training set: 0.57\n"
     ]
    }
   ],
   "source": [
    "gb_reg = GradientBoostingRegressor(max_features=4,\n",
    "                                learning_rate=0.01,\n",
    "                                n_estimators=300,\n",
    "                                random_state=10)\n",
    "gb_reg.fit(X_train,y_train)\n",
    "train_pred = gb_reg.predict(X_train)\n",
    "test_pred=gb_reg.predict(X_test)\n",
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(gb_reg.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(gb_reg.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 15.2\n",
      "Tree on test set MAE%: 18.2\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3935.6608373117283"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network (keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "model = Sequential()\n",
    "model.add(Dense(200,activation='relu',input_dim=104))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 290606891.6364\n",
      "Epoch 2/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 290552674.9091\n",
      "Epoch 3/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 290448769.4545\n",
      "Epoch 4/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 290252686.5455\n",
      "Epoch 5/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 289906241.4545\n",
      "Epoch 6/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 289315038.5455\n",
      "Epoch 7/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 288389211.6364\n",
      "Epoch 8/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 287004266.1818\n",
      "Epoch 9/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 285086180.3636\n",
      "Epoch 10/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 282458980.3636\n",
      "Epoch 11/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 279035752.7273\n",
      "Epoch 12/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 274739265.4545\n",
      "Epoch 13/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 269523834.1818\n",
      "Epoch 14/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 263554717.0909\n",
      "Epoch 15/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 255663704.7273\n",
      "Epoch 16/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 247967642.1818\n",
      "Epoch 17/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 237821565.0909\n",
      "Epoch 18/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 227109963.6364\n",
      "Epoch 19/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 215821636.3636\n",
      "Epoch 20/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 203947946.1818\n",
      "Epoch 21/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 189515408.0000\n",
      "Epoch 22/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 176696644.3636\n",
      "Epoch 23/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 161277382.5455\n",
      "Epoch 24/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 148230125.8182\n",
      "Epoch 25/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 136119557.8182\n",
      "Epoch 26/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 121458679.2727\n",
      "Epoch 27/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 107810914.1818\n",
      "Epoch 28/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 94590864.0000\n",
      "Epoch 29/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 84044531.2727\n",
      "Epoch 30/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 73585894.5455\n",
      "Epoch 31/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 64775252.7273\n",
      "Epoch 32/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 58442911.0909\n",
      "Epoch 33/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 51196455.2727\n",
      "Epoch 34/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 46747244.3636\n",
      "Epoch 35/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 42653753.2727\n",
      "Epoch 36/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 39833209.5455\n",
      "Epoch 37/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 38277071.0000\n",
      "Epoch 38/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 34427755.6364\n",
      "Epoch 39/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 32607889.5455\n",
      "Epoch 40/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 33597077.3636\n",
      "Epoch 41/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 31451716.0000\n",
      "Epoch 42/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 32411694.5909\n",
      "Epoch 43/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 32577787.5000\n",
      "Epoch 44/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 32934060.00 - 0s 179us/step - loss: 29421402.5909\n",
      "Epoch 45/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 31560641.9091\n",
      "Epoch 46/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 28188653.0455\n",
      "Epoch 47/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 31279992.0455\n",
      "Epoch 48/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 30226089.8182\n",
      "Epoch 49/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 29314576.0000\n",
      "Epoch 50/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 31436456.6364\n",
      "Epoch 51/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 28774625.2727\n",
      "Epoch 52/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 28176291.7727\n",
      "Epoch 53/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 28313640.4545\n",
      "Epoch 54/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 28126837.0000\n",
      "Epoch 55/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 28696425.8636\n",
      "Epoch 56/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 28740558.6364\n",
      "Epoch 57/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 29804126.2045\n",
      "Epoch 58/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 25402092.5909\n",
      "Epoch 59/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 25328416.9318\n",
      "Epoch 60/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 26187698.5455\n",
      "Epoch 61/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 26922698.0000\n",
      "Epoch 62/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 25582193.8636\n",
      "Epoch 63/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 27387303.0909\n",
      "Epoch 64/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 23320260.3182\n",
      "Epoch 65/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 25830182.3636\n",
      "Epoch 66/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 24647412.0000\n",
      "Epoch 67/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 24992525.1818\n",
      "Epoch 68/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 24412393.0909\n",
      "Epoch 69/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 23553446.8636\n",
      "Epoch 70/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 23215194.7273\n",
      "Epoch 71/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 25956145.5455\n",
      "Epoch 72/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 22934984.9091\n",
      "Epoch 73/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 22401639.1364\n",
      "Epoch 74/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 22191303.7273\n",
      "Epoch 75/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 22860656.0000\n",
      "Epoch 76/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 23642551.5000\n",
      "Epoch 77/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 22807975.3636\n",
      "Epoch 78/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 24071577.2727\n",
      "Epoch 79/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 22568147.2273\n",
      "Epoch 80/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 21078848.1818\n",
      "Epoch 81/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 21748336.0909\n",
      "Epoch 82/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 21806940.2273\n",
      "Epoch 83/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 19293367.8182\n",
      "Epoch 84/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 21246857.5455\n",
      "Epoch 85/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 20689837.3182\n",
      "Epoch 86/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 20007189.8182\n",
      "Epoch 87/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 21910352.5909\n",
      "Epoch 88/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 186us/step - loss: 20912833.5000\n",
      "Epoch 89/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 21622097.7727\n",
      "Epoch 90/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 19472466.0909\n",
      "Epoch 91/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 19121891.9091\n",
      "Epoch 92/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 18223409.5000\n",
      "Epoch 93/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 19078757.3636\n",
      "Epoch 94/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 20275388.8182\n",
      "Epoch 95/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 19096959.9545\n",
      "Epoch 96/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 18382501.4091\n",
      "Epoch 97/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 19746072.7727\n",
      "Epoch 98/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 17922376.6818\n",
      "Epoch 99/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 17228256.5455\n",
      "Epoch 100/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 19287646.1818\n",
      "Epoch 101/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 17337742.9545\n",
      "Epoch 102/2000\n",
      "176/176 [==============================] - 0s 152us/step - loss: 17851891.7727\n",
      "Epoch 103/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 18484738.2727\n",
      "Epoch 104/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 18207626.0909\n",
      "Epoch 105/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 16781824.3636\n",
      "Epoch 106/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 16930441.9091\n",
      "Epoch 107/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 16827245.7273\n",
      "Epoch 108/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 16931019.9545\n",
      "Epoch 109/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 17954078.5000\n",
      "Epoch 110/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 16798929.8864\n",
      "Epoch 111/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 16922568.2273\n",
      "Epoch 112/2000\n",
      "176/176 [==============================] - 0s 142us/step - loss: 17558245.9091\n",
      "Epoch 113/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 14363552.8636\n",
      "Epoch 114/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 15934330.8182\n",
      "Epoch 115/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 17843260.0909\n",
      "Epoch 116/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 15669745.2273\n",
      "Epoch 117/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 17110185.9091\n",
      "Epoch 118/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 15477798.9091\n",
      "Epoch 119/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 14819935.6818\n",
      "Epoch 120/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 15330973.2727\n",
      "Epoch 121/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 16153807.0000\n",
      "Epoch 122/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 14519328.7273\n",
      "Epoch 123/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 13976026.6364\n",
      "Epoch 124/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 14558809.5000\n",
      "Epoch 125/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 14488753.9091\n",
      "Epoch 126/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 15382426.3636\n",
      "Epoch 127/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 15250391.9091\n",
      "Epoch 128/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 15112040.8636\n",
      "Epoch 129/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 14489220.4091\n",
      "Epoch 130/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 15397229.0909\n",
      "Epoch 131/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 13615271.5909\n",
      "Epoch 132/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 13230994.3636\n",
      "Epoch 133/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 14401011.2273\n",
      "Epoch 134/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 13486643.2727\n",
      "Epoch 135/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 13921256.1818\n",
      "Epoch 136/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 13569039.8182\n",
      "Epoch 137/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 12251674.8182\n",
      "Epoch 138/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 12370591.8409\n",
      "Epoch 139/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 11980933.0909\n",
      "Epoch 140/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 12332398.9545\n",
      "Epoch 141/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 13214788.4545\n",
      "Epoch 142/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 13205936.8182\n",
      "Epoch 143/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 12330476.9545\n",
      "Epoch 144/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 12157070.9091\n",
      "Epoch 145/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 11923719.0909\n",
      "Epoch 146/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 12893745.3636\n",
      "Epoch 147/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 12699987.6364\n",
      "Epoch 148/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 12019672.7727\n",
      "Epoch 149/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 12014081.8636\n",
      "Epoch 150/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 12571592.0455\n",
      "Epoch 151/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 12333562.3636\n",
      "Epoch 152/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 12626143.3636\n",
      "Epoch 153/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 11727927.6818\n",
      "Epoch 154/2000\n",
      "176/176 [==============================] - 0s 269us/step - loss: 11322965.1818\n",
      "Epoch 155/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 11579074.2500\n",
      "Epoch 156/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 11372078.3523\n",
      "Epoch 157/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 11085079.1364\n",
      "Epoch 158/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 10833600.7727\n",
      "Epoch 159/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 11069095.3636\n",
      "Epoch 160/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 10659977.5909\n",
      "Epoch 161/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 10965742.0000\n",
      "Epoch 162/2000\n",
      "176/176 [==============================] - 0s 284us/step - loss: 9549062.0455\n",
      "Epoch 163/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 10824459.8636\n",
      "Epoch 164/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 11237141.2273\n",
      "Epoch 165/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 9609256.1818\n",
      "Epoch 166/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 9800582.0455\n",
      "Epoch 167/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 11248440.9545\n",
      "Epoch 168/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 9209659.8864\n",
      "Epoch 169/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 10426134.0455\n",
      "Epoch 170/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 10373428.6364\n",
      "Epoch 171/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 9641371.0455\n",
      "Epoch 172/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 8938410.1818\n",
      "Epoch 173/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 9411137.6818\n",
      "Epoch 174/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 9778870.2500\n",
      "Epoch 175/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 205us/step - loss: 10380369.7955\n",
      "Epoch 176/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 9456204.4091\n",
      "Epoch 177/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 9179508.5455\n",
      "Epoch 178/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 9585295.8182\n",
      "Epoch 179/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 9369553.3636\n",
      "Epoch 180/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 9109042.8182\n",
      "Epoch 181/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 8872837.1364\n",
      "Epoch 182/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 8970039.1591\n",
      "Epoch 183/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 10017828.4091\n",
      "Epoch 184/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 9422095.7727\n",
      "Epoch 185/2000\n",
      "176/176 [==============================] - 0s 268us/step - loss: 9411299.5000\n",
      "Epoch 186/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 8248908.6364\n",
      "Epoch 187/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 9276855.9545\n",
      "Epoch 188/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 8561662.7273\n",
      "Epoch 189/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 8108570.5000\n",
      "Epoch 190/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 8045438.1591\n",
      "Epoch 191/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 8531987.3636\n",
      "Epoch 192/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 7938606.1818\n",
      "Epoch 193/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 8402993.2273\n",
      "Epoch 194/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 9217710.0455\n",
      "Epoch 195/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 8725347.2727\n",
      "Epoch 196/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 6952631.4091\n",
      "Epoch 197/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 7996489.7273\n",
      "Epoch 198/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 8336529.8182\n",
      "Epoch 199/2000\n",
      "176/176 [==============================] - 0s 284us/step - loss: 7170831.1364\n",
      "Epoch 200/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 7220160.6591\n",
      "Epoch 201/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 6742754.6818\n",
      "Epoch 202/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 6915901.3636\n",
      "Epoch 203/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 6648897.9091\n",
      "Epoch 204/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 6827155.9091\n",
      "Epoch 205/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 7538046.0227\n",
      "Epoch 206/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 7970815.7273\n",
      "Epoch 207/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 7001223.7273\n",
      "Epoch 208/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 7413729.6364\n",
      "Epoch 209/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 7871604.8409\n",
      "Epoch 210/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 6323389.8636\n",
      "Epoch 211/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 6252312.4091\n",
      "Epoch 212/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 6776682.3182\n",
      "Epoch 213/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 7134268.6364\n",
      "Epoch 214/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 6174058.9545\n",
      "Epoch 215/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 7981694.8182\n",
      "Epoch 216/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 6656193.5455\n",
      "Epoch 217/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 7227368.2273\n",
      "Epoch 218/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 6937964.7955\n",
      "Epoch 219/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 6235647.0682\n",
      "Epoch 220/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 6555162.7955\n",
      "Epoch 221/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 6099083.3636\n",
      "Epoch 222/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 7258387.8182\n",
      "Epoch 223/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 7148144.4091\n",
      "Epoch 224/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 6674801.4318\n",
      "Epoch 225/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 7060531.6818\n",
      "Epoch 226/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 6918106.4545\n",
      "Epoch 227/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 6894302.2727\n",
      "Epoch 228/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 5888324.2273\n",
      "Epoch 229/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 5794803.9091\n",
      "Epoch 230/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 6443228.8636\n",
      "Epoch 231/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 6626012.7727\n",
      "Epoch 232/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 6508242.6136\n",
      "Epoch 233/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 6144091.0455\n",
      "Epoch 234/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 5861957.7727\n",
      "Epoch 235/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 5680978.3750\n",
      "Epoch 236/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 6803058.0000\n",
      "Epoch 237/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 5375101.1591\n",
      "Epoch 238/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 6128696.1591\n",
      "Epoch 239/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 6022245.5000\n",
      "Epoch 240/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 6060286.3409\n",
      "Epoch 241/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 5901545.5682\n",
      "Epoch 242/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 5636248.4318\n",
      "Epoch 243/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 6014171.2955\n",
      "Epoch 244/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 6271487.9091\n",
      "Epoch 245/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 6555888.2273\n",
      "Epoch 246/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 6391254.3636\n",
      "Epoch 247/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 6096210.5000\n",
      "Epoch 248/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 6119907.5000\n",
      "Epoch 249/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 5294029.0000\n",
      "Epoch 250/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 5437568.4545\n",
      "Epoch 251/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 5799374.8182\n",
      "Epoch 252/2000\n",
      "176/176 [==============================] - 0s 246us/step - loss: 5724668.7500\n",
      "Epoch 253/2000\n",
      "176/176 [==============================] - 0s 255us/step - loss: 5980484.7045\n",
      "Epoch 254/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 4958200.3409\n",
      "Epoch 255/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 5252540.3409\n",
      "Epoch 256/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 6316216.8182\n",
      "Epoch 257/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 5190929.4773\n",
      "Epoch 258/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 5000114.2955\n",
      "Epoch 259/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 5522148.5000\n",
      "Epoch 260/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 6292128.9773\n",
      "Epoch 261/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 5374146.9545\n",
      "Epoch 262/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 5527820.1136\n",
      "Epoch 263/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 233us/step - loss: 6100865.5000\n",
      "Epoch 264/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 5148392.5455\n",
      "Epoch 265/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 5127197.1932\n",
      "Epoch 266/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 5204670.3636\n",
      "Epoch 267/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 5602770.7273\n",
      "Epoch 268/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 4246149.8864\n",
      "Epoch 269/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 5165266.0682\n",
      "Epoch 270/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 5419121.1364\n",
      "Epoch 271/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 5332358.9318\n",
      "Epoch 272/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4671102.3409\n",
      "Epoch 273/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 4730148.4091\n",
      "Epoch 274/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 5173627.8864\n",
      "Epoch 275/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 4520292.2727\n",
      "Epoch 276/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4580254.1364\n",
      "Epoch 277/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 4320593.2614\n",
      "Epoch 278/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4753779.9886\n",
      "Epoch 279/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 4634086.2273\n",
      "Epoch 280/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 4632038.8182\n",
      "Epoch 281/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 5117377.7727\n",
      "Epoch 282/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 5097680.8409\n",
      "Epoch 283/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 4342309.8977\n",
      "Epoch 284/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 5274355.7500\n",
      "Epoch 285/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4588031.0000\n",
      "Epoch 286/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4109319.7955\n",
      "Epoch 287/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4828460.2955\n",
      "Epoch 288/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4618594.1818\n",
      "Epoch 289/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2903609.000 - 0s 206us/step - loss: 4355062.0909\n",
      "Epoch 290/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4603419.0568\n",
      "Epoch 291/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 5262888.5000\n",
      "Epoch 292/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 4762125.0455\n",
      "Epoch 293/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 4728811.7273\n",
      "Epoch 294/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4931806.9318\n",
      "Epoch 295/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 5106883.7045\n",
      "Epoch 296/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 4507510.3864\n",
      "Epoch 297/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 4564215.0455\n",
      "Epoch 298/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 4356217.6250\n",
      "Epoch 299/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 5269451.6818\n",
      "Epoch 300/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 4232356.8295\n",
      "Epoch 301/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 4379811.0000\n",
      "Epoch 302/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 5468708.7500\n",
      "Epoch 303/2000\n",
      "176/176 [==============================] - 0s 246us/step - loss: 4488866.2045\n",
      "Epoch 304/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 4463680.1364\n",
      "Epoch 305/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4920010.6818\n",
      "Epoch 306/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4368034.3182\n",
      "Epoch 307/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 4056030.1364\n",
      "Epoch 308/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 4665382.2500\n",
      "Epoch 309/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4006583.3182\n",
      "Epoch 310/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4328085.7500\n",
      "Epoch 311/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 4417195.8182\n",
      "Epoch 312/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4473427.6705\n",
      "Epoch 313/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 4622424.9545\n",
      "Epoch 314/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3860045.1818\n",
      "Epoch 315/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4285601.0455\n",
      "Epoch 316/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 4927735.8750\n",
      "Epoch 317/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 4347374.0455\n",
      "Epoch 318/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 4970673.8864\n",
      "Epoch 319/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 4116267.3864\n",
      "Epoch 320/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 4345606.2500\n",
      "Epoch 321/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 4007612.8182\n",
      "Epoch 322/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3854730.9886\n",
      "Epoch 323/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 4056101.0000\n",
      "Epoch 324/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4535055.7500\n",
      "Epoch 325/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4172846.0455\n",
      "Epoch 326/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 4397836.9545\n",
      "Epoch 327/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 4582228.1136\n",
      "Epoch 328/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 4446643.3409\n",
      "Epoch 329/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 4585959.1364\n",
      "Epoch 330/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 4202186.4545\n",
      "Epoch 331/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 4961701.0000\n",
      "Epoch 332/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 4845069.1136\n",
      "Epoch 333/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4270521.2273\n",
      "Epoch 334/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 4330609.1591\n",
      "Epoch 335/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4579501.0682\n",
      "Epoch 336/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3725698.4432\n",
      "Epoch 337/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3778770.2727\n",
      "Epoch 338/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 4947553.0909\n",
      "Epoch 339/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4475816.5682\n",
      "Epoch 340/2000\n",
      "176/176 [==============================] - 0s 273us/step - loss: 4153434.5000\n",
      "Epoch 341/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 4015465.8636\n",
      "Epoch 342/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3903553.9318\n",
      "Epoch 343/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3997093.9773\n",
      "Epoch 344/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4860722.8182\n",
      "Epoch 345/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 4301460.0455\n",
      "Epoch 346/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 4712571.7500\n",
      "Epoch 347/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4580287.3864\n",
      "Epoch 348/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4056516.1250\n",
      "Epoch 349/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3908123.6023\n",
      "Epoch 350/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3853942.6136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3923008.5341\n",
      "Epoch 352/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3927836.1477\n",
      "Epoch 353/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3748998.9886\n",
      "Epoch 354/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3605048.0795\n",
      "Epoch 355/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3975976.0455\n",
      "Epoch 356/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 4216417.4318\n",
      "Epoch 357/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 4052583.3523\n",
      "Epoch 358/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3500517.7273\n",
      "Epoch 359/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 4688210.3977\n",
      "Epoch 360/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 4738100.4318\n",
      "Epoch 361/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3624387.6023\n",
      "Epoch 362/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3946843.6477\n",
      "Epoch 363/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 4213880.6818\n",
      "Epoch 364/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 4102033.1136\n",
      "Epoch 365/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3121582.5341\n",
      "Epoch 366/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3974279.4886\n",
      "Epoch 367/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 4544354.7273\n",
      "Epoch 368/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3916337.1364\n",
      "Epoch 369/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4621251.5227\n",
      "Epoch 370/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3804160.8068\n",
      "Epoch 371/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3834227.4886\n",
      "Epoch 372/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 4168703.5227\n",
      "Epoch 373/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3849968.9432\n",
      "Epoch 374/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3340989.5795\n",
      "Epoch 375/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 4159514.8636\n",
      "Epoch 376/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3859070.0341\n",
      "Epoch 377/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3832177.9773\n",
      "Epoch 378/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 4053531.3409\n",
      "Epoch 379/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4147040.3182\n",
      "Epoch 380/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3877011.3977\n",
      "Epoch 381/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 4109595.7045\n",
      "Epoch 382/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3773871.7955\n",
      "Epoch 383/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3769461.2500\n",
      "Epoch 384/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 4126489.4545\n",
      "Epoch 385/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 4201022.7614\n",
      "Epoch 386/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 4016236.0455\n",
      "Epoch 387/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4153003.2045\n",
      "Epoch 388/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 4166033.5227\n",
      "Epoch 389/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4231522.3636\n",
      "Epoch 390/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 4093038.2045\n",
      "Epoch 391/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3853673.0568\n",
      "Epoch 392/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3716399.6364\n",
      "Epoch 393/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3897675.8182\n",
      "Epoch 394/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4194771.3409\n",
      "Epoch 395/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3160291.6477\n",
      "Epoch 396/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3436912.4432\n",
      "Epoch 397/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3764306.6136\n",
      "Epoch 398/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3665627.3636\n",
      "Epoch 399/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3983252.4545\n",
      "Epoch 400/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3392629.0000\n",
      "Epoch 401/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3259907.4318\n",
      "Epoch 402/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3955587.0568\n",
      "Epoch 403/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 4056465.7273\n",
      "Epoch 404/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3593916.9773\n",
      "Epoch 405/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3806890.5000\n",
      "Epoch 406/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3959922.7045\n",
      "Epoch 407/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3523929.8409\n",
      "Epoch 408/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3721889.9886\n",
      "Epoch 409/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3526846.7727\n",
      "Epoch 410/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3646410.7500\n",
      "Epoch 411/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3814018.6250\n",
      "Epoch 412/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2738792.000 - 0s 200us/step - loss: 3573623.3636\n",
      "Epoch 413/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 4134129.0682\n",
      "Epoch 414/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3898828.7727\n",
      "Epoch 415/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3797455.7273\n",
      "Epoch 416/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 4347826.2955\n",
      "Epoch 417/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3794807.5455\n",
      "Epoch 418/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3545009.9886\n",
      "Epoch 419/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3723034.9432\n",
      "Epoch 420/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 4043989.0000\n",
      "Epoch 421/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3962619.4773\n",
      "Epoch 422/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3466629.1705\n",
      "Epoch 423/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3998574.1364\n",
      "Epoch 424/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3665951.3182\n",
      "Epoch 425/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3488166.5227\n",
      "Epoch 426/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3801325.1591\n",
      "Epoch 427/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3324810.6136\n",
      "Epoch 428/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3549897.2955\n",
      "Epoch 429/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3249722.7955\n",
      "Epoch 430/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3931338.9318\n",
      "Epoch 431/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3889640.6591\n",
      "Epoch 432/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3713685.5795\n",
      "Epoch 433/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3062659.0341\n",
      "Epoch 434/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3999967.0682\n",
      "Epoch 435/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3581629.4091\n",
      "Epoch 436/2000\n",
      "176/176 [==============================] - 0s 70us/step - loss: 3694833.1477\n",
      "Epoch 437/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3240256.5568\n",
      "Epoch 438/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 180us/step - loss: 3939943.5682\n",
      "Epoch 439/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3406627.5909\n",
      "Epoch 440/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 4294140.0227\n",
      "Epoch 441/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3477293.5568\n",
      "Epoch 442/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3522444.2841\n",
      "Epoch 443/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3735249.9773\n",
      "Epoch 444/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3421821.0114\n",
      "Epoch 445/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3663667.0568\n",
      "Epoch 446/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3736586.0000\n",
      "Epoch 447/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3502663.1364\n",
      "Epoch 448/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3659432.7273\n",
      "Epoch 449/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 4106401.2273\n",
      "Epoch 450/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3308105.4318\n",
      "Epoch 451/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3513953.1591\n",
      "Epoch 452/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3759940.5455\n",
      "Epoch 453/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3952388.6136\n",
      "Epoch 454/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3399587.7955\n",
      "Epoch 455/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3790698.3636\n",
      "Epoch 456/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3037329.7159\n",
      "Epoch 457/2000\n",
      "176/176 [==============================] - 0s 152us/step - loss: 3811900.5795\n",
      "Epoch 458/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 4090137.2500\n",
      "Epoch 459/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3631623.9318\n",
      "Epoch 460/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3304377.4091\n",
      "Epoch 461/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 4024302.0682\n",
      "Epoch 462/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 4249190.2614\n",
      "Epoch 463/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 4194153.5455\n",
      "Epoch 464/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3022339.4886\n",
      "Epoch 465/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3263914.5227\n",
      "Epoch 466/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3343502.7727\n",
      "Epoch 467/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 4026110.7727\n",
      "Epoch 468/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 4150297.0682\n",
      "Epoch 469/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3860872.1591\n",
      "Epoch 470/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3491341.0227\n",
      "Epoch 471/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 3639554.7273\n",
      "Epoch 472/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3510433.9773\n",
      "Epoch 473/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3917132.5114\n",
      "Epoch 474/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3040680.2614\n",
      "Epoch 475/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3510387.8068\n",
      "Epoch 476/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 2726261.8409\n",
      "Epoch 477/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3448900.8182\n",
      "Epoch 478/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3735380.6932\n",
      "Epoch 479/2000\n",
      "176/176 [==============================] - 0s 259us/step - loss: 3615581.0000\n",
      "Epoch 480/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3818759.8636\n",
      "Epoch 481/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 4237557.7727\n",
      "Epoch 482/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3506983.7614\n",
      "Epoch 483/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3788973.1818\n",
      "Epoch 484/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3976900.3977\n",
      "Epoch 485/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3574227.1591\n",
      "Epoch 486/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3439182.6932\n",
      "Epoch 487/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3517807.9091\n",
      "Epoch 488/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3702689.6818\n",
      "Epoch 489/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3858547.7386\n",
      "Epoch 490/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3724876.4318\n",
      "Epoch 491/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3335538.8864\n",
      "Epoch 492/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3746315.8636\n",
      "Epoch 493/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3248487.9545\n",
      "Epoch 494/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3208679.9545\n",
      "Epoch 495/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3189271.5795\n",
      "Epoch 496/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3658382.6818\n",
      "Epoch 497/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3136553.5000\n",
      "Epoch 498/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3568784.3409\n",
      "Epoch 499/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 2882704.8409\n",
      "Epoch 500/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3836994.8182\n",
      "Epoch 501/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3323521.7273\n",
      "Epoch 502/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 3484106.8182\n",
      "Epoch 503/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3517679.7841\n",
      "Epoch 504/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3342058.7727\n",
      "Epoch 505/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3537479.3977\n",
      "Epoch 506/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3230771.0682\n",
      "Epoch 507/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3220092.0795\n",
      "Epoch 508/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3491222.9318\n",
      "Epoch 509/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3741228.3636\n",
      "Epoch 510/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3756927.9773\n",
      "Epoch 511/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3826671.2045\n",
      "Epoch 512/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3425635.9091\n",
      "Epoch 513/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3639969.1364\n",
      "Epoch 514/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3528110.4318\n",
      "Epoch 515/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3408884.2500\n",
      "Epoch 516/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3745620.4318\n",
      "Epoch 517/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3467050.8409\n",
      "Epoch 518/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3613334.9318\n",
      "Epoch 519/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3259297.4205\n",
      "Epoch 520/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 2903354.4432\n",
      "Epoch 521/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 2966495.8182\n",
      "Epoch 522/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3321249.7045\n",
      "Epoch 523/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3469740.2500\n",
      "Epoch 524/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3303717.5227\n",
      "Epoch 525/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 4029407.9659\n",
      "Epoch 526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 194us/step - loss: 3195389.1364\n",
      "Epoch 527/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3941269.6591\n",
      "Epoch 528/2000\n",
      "176/176 [==============================] - 0s 279us/step - loss: 3695635.1705\n",
      "Epoch 529/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3206755.4432\n",
      "Epoch 530/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3382716.0114\n",
      "Epoch 531/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3624822.0568\n",
      "Epoch 532/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3391527.5795\n",
      "Epoch 533/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3930666.9545\n",
      "Epoch 534/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3943831.7955\n",
      "Epoch 535/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3484637.8068\n",
      "Epoch 536/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3585912.5000\n",
      "Epoch 537/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3587647.7500\n",
      "Epoch 538/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3633048.6136\n",
      "Epoch 539/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3974515.4545\n",
      "Epoch 540/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3425447.5909\n",
      "Epoch 541/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3332768.8636\n",
      "Epoch 542/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3295898.7500\n",
      "Epoch 543/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3261107.5455\n",
      "Epoch 544/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3342846.4091\n",
      "Epoch 545/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3096848.6818\n",
      "Epoch 546/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3082940.4659\n",
      "Epoch 547/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3289240.9773\n",
      "Epoch 548/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3570572.7273\n",
      "Epoch 549/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3359740.7614\n",
      "Epoch 550/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3669632.0909\n",
      "Epoch 551/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3464697.3523\n",
      "Epoch 552/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3547468.0455\n",
      "Epoch 553/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3719035.9659\n",
      "Epoch 554/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3068563.9205\n",
      "Epoch 555/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3427119.9091\n",
      "Epoch 556/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3225839.8523\n",
      "Epoch 557/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3547426.8295\n",
      "Epoch 558/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 4061608.5227\n",
      "Epoch 559/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3681487.3636\n",
      "Epoch 560/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3446615.2500\n",
      "Epoch 561/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3545431.9205\n",
      "Epoch 562/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3408386.0227\n",
      "Epoch 563/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3526328.9205\n",
      "Epoch 564/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3454016.9545\n",
      "Epoch 565/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3476063.3864\n",
      "Epoch 566/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2825029.3068\n",
      "Epoch 567/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3666834.7045\n",
      "Epoch 568/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3354332.5114\n",
      "Epoch 569/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3411481.0909\n",
      "Epoch 570/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3400631.2500\n",
      "Epoch 571/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3782883.0568\n",
      "Epoch 572/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3064071.2386\n",
      "Epoch 573/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3905231.9261\n",
      "Epoch 574/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3790454.1250\n",
      "Epoch 575/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3688678.4545\n",
      "Epoch 576/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3503154.3636\n",
      "Epoch 577/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3075682.1591\n",
      "Epoch 578/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3022923.1364\n",
      "Epoch 579/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3537016.0568\n",
      "Epoch 580/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3818008.7045\n",
      "Epoch 581/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3218590.9091\n",
      "Epoch 582/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 2951516.8864\n",
      "Epoch 583/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3387520.6591\n",
      "Epoch 584/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3352847.0682\n",
      "Epoch 585/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3360589.7273\n",
      "Epoch 586/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3484287.5455\n",
      "Epoch 587/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3297377.5909\n",
      "Epoch 588/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3014598.1364\n",
      "Epoch 589/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3391540.2841\n",
      "Epoch 590/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3217218.3068\n",
      "Epoch 591/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3440627.6023\n",
      "Epoch 592/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 2964054.2330\n",
      "Epoch 593/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3300089.4148\n",
      "Epoch 594/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 4035202.0000\n",
      "Epoch 595/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3262284.8636\n",
      "Epoch 596/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3111010.9545\n",
      "Epoch 597/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3055889.1591\n",
      "Epoch 598/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3518472.2727\n",
      "Epoch 599/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3356667.3636\n",
      "Epoch 600/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3311658.0227\n",
      "Epoch 601/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3255159.7955\n",
      "Epoch 602/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3654736.1591\n",
      "Epoch 603/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3708652.7386\n",
      "Epoch 604/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3444964.6023\n",
      "Epoch 605/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3030318.7727\n",
      "Epoch 606/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3177814.4545\n",
      "Epoch 607/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 2995767.3409\n",
      "Epoch 608/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3861656.3068\n",
      "Epoch 609/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3749529.8409\n",
      "Epoch 610/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3163287.8295\n",
      "Epoch 611/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3399143.9318\n",
      "Epoch 612/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3422194.9318\n",
      "Epoch 613/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3415885.1250\n",
      "Epoch 614/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 152us/step - loss: 2820784.0341\n",
      "Epoch 615/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 4029845.6818\n",
      "Epoch 616/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3620954.1591\n",
      "Epoch 617/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3370839.1136\n",
      "Epoch 618/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3571735.7045\n",
      "Epoch 619/2000\n",
      "176/176 [==============================] - 0s 257us/step - loss: 3392074.8068\n",
      "Epoch 620/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3004486.0909\n",
      "Epoch 621/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3621448.5682\n",
      "Epoch 622/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3412030.0682\n",
      "Epoch 623/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3629138.2727\n",
      "Epoch 624/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3207630.0682\n",
      "Epoch 625/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3054934.3977\n",
      "Epoch 626/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 3221250.8295\n",
      "Epoch 627/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3401958.8182\n",
      "Epoch 628/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3313145.9205\n",
      "Epoch 629/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3250068.3523\n",
      "Epoch 630/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3103461.0114\n",
      "Epoch 631/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2998228.3977\n",
      "Epoch 632/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3186076.5909\n",
      "Epoch 633/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 4218801.2841\n",
      "Epoch 634/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3279279.8409\n",
      "Epoch 635/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3802731.2955\n",
      "Epoch 636/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 2870661.6932\n",
      "Epoch 637/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 2706002.5568\n",
      "Epoch 638/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3571345.7045\n",
      "Epoch 639/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3115569.5341\n",
      "Epoch 640/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 4290974.0795\n",
      "Epoch 641/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3338684.9318\n",
      "Epoch 642/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 4045490.3864\n",
      "Epoch 643/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3115809.0568\n",
      "Epoch 644/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2626266.2955\n",
      "Epoch 645/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3388520.4545\n",
      "Epoch 646/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3312279.7500\n",
      "Epoch 647/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3037452.1818\n",
      "Epoch 648/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 2810891.1591\n",
      "Epoch 649/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 2927602.9545\n",
      "Epoch 650/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3559621.0227\n",
      "Epoch 651/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3064689.9545\n",
      "Epoch 652/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 2628481.1364\n",
      "Epoch 653/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3681986.0455\n",
      "Epoch 654/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 2904339.6818\n",
      "Epoch 655/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3109692.3977\n",
      "Epoch 656/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3149550.8864\n",
      "Epoch 657/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 2950250.6136\n",
      "Epoch 658/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3637645.0568\n",
      "Epoch 659/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3160182.2841\n",
      "Epoch 660/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3429154.3182\n",
      "Epoch 661/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3483727.8636\n",
      "Epoch 662/2000\n",
      "176/176 [==============================] - 0s 83us/step - loss: 3443914.7727\n",
      "Epoch 663/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3223637.1364\n",
      "Epoch 664/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3079986.8182\n",
      "Epoch 665/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3424495.7500\n",
      "Epoch 666/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3826211.0568\n",
      "Epoch 667/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3491203.0000\n",
      "Epoch 668/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3382255.7045\n",
      "Epoch 669/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3334181.2727\n",
      "Epoch 670/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3300748.6364\n",
      "Epoch 671/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3349483.6818\n",
      "Epoch 672/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 2917345.1818\n",
      "Epoch 673/2000\n",
      "176/176 [==============================] - 0s 293us/step - loss: 3521178.7500\n",
      "Epoch 674/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2943069.5909\n",
      "Epoch 675/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 2865571.1477\n",
      "Epoch 676/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3269510.7955\n",
      "Epoch 677/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3563413.6591\n",
      "Epoch 678/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3162727.4886\n",
      "Epoch 679/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3218843.9432\n",
      "Epoch 680/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3284792.8068\n",
      "Epoch 681/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3525355.3182\n",
      "Epoch 682/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 3416837.7273\n",
      "Epoch 683/2000\n",
      "176/176 [==============================] - 0s 116us/step - loss: 3418111.3864\n",
      "Epoch 684/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3694583.3977\n",
      "Epoch 685/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3198430.7955\n",
      "Epoch 686/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3257594.4205\n",
      "Epoch 687/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3151436.3182\n",
      "Epoch 688/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 2988730.7841\n",
      "Epoch 689/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3312640.8182\n",
      "Epoch 690/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3816026.5455\n",
      "Epoch 691/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 2871637.0341\n",
      "Epoch 692/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3357833.5682\n",
      "Epoch 693/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2621786.2614\n",
      "Epoch 694/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3069863.8409\n",
      "Epoch 695/2000\n",
      "176/176 [==============================] - 0s 138us/step - loss: 3103768.8409\n",
      "Epoch 696/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3054404.2500\n",
      "Epoch 697/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3301605.9091\n",
      "Epoch 698/2000\n",
      "176/176 [==============================] - 0s 284us/step - loss: 2774815.5227\n",
      "Epoch 699/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3165779.5000\n",
      "Epoch 700/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3240844.6818\n",
      "Epoch 701/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3339460.2159\n",
      "Epoch 702/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 250us/step - loss: 2730545.3750\n",
      "Epoch 703/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3550569.6591\n",
      "Epoch 704/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3744194.9773\n",
      "Epoch 705/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3193111.0795\n",
      "Epoch 706/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3440440.7500\n",
      "Epoch 707/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3281594.1364\n",
      "Epoch 708/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3503761.6818\n",
      "Epoch 709/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3585242.0455\n",
      "Epoch 710/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3002965.9659\n",
      "Epoch 711/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3208454.1932\n",
      "Epoch 712/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3104948.1136\n",
      "Epoch 713/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3358367.0000\n",
      "Epoch 714/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3538591.8182\n",
      "Epoch 715/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3342049.8580\n",
      "Epoch 716/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3369070.0000\n",
      "Epoch 717/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3320043.1250\n",
      "Epoch 718/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3018311.6932\n",
      "Epoch 719/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3404794.5909\n",
      "Epoch 720/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2838242.7727\n",
      "Epoch 721/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3372583.5682\n",
      "Epoch 722/2000\n",
      "176/176 [==============================] - 0s 126us/step - loss: 3513459.5000\n",
      "Epoch 723/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3543522.2045\n",
      "Epoch 724/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3291469.2386\n",
      "Epoch 725/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3303250.5682\n",
      "Epoch 726/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3091627.0795\n",
      "Epoch 727/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 2943951.8409\n",
      "Epoch 728/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3308925.6364\n",
      "Epoch 729/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3778867.9318\n",
      "Epoch 730/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3975252.4091\n",
      "Epoch 731/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3520115.4886\n",
      "Epoch 732/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 2996842.2727\n",
      "Epoch 733/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3729843.6136\n",
      "Epoch 734/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3346392.7727\n",
      "Epoch 735/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2955928.1023\n",
      "Epoch 736/2000\n",
      "176/176 [==============================] - 0s 139us/step - loss: 3246851.3636\n",
      "Epoch 737/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3041830.3182\n",
      "Epoch 738/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3198258.7500\n",
      "Epoch 739/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3145960.1250\n",
      "Epoch 740/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 3263267.7614\n",
      "Epoch 741/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2750410.7159\n",
      "Epoch 742/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3183654.8636\n",
      "Epoch 743/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3338520.0000\n",
      "Epoch 744/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3802230.1136\n",
      "Epoch 745/2000\n",
      "176/176 [==============================] - 0s 275us/step - loss: 3285851.8409\n",
      "Epoch 746/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3923986.5682\n",
      "Epoch 747/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3522570.7500\n",
      "Epoch 748/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3130801.1250\n",
      "Epoch 749/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3466354.7273\n",
      "Epoch 750/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3555047.1705\n",
      "Epoch 751/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3393517.9716\n",
      "Epoch 752/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 2783044.6705\n",
      "Epoch 753/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3551928.5227\n",
      "Epoch 754/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 2952915.1250\n",
      "Epoch 755/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3377957.1136\n",
      "Epoch 756/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3687564.3636\n",
      "Epoch 757/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3239409.5795\n",
      "Epoch 758/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3499638.2841\n",
      "Epoch 759/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 3212234.5682\n",
      "Epoch 760/2000\n",
      "176/176 [==============================] - 0s 278us/step - loss: 3293194.7159\n",
      "Epoch 761/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 2931510.5568\n",
      "Epoch 762/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3151652.9545\n",
      "Epoch 763/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3096812.2727\n",
      "Epoch 764/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 3765647.0000\n",
      "Epoch 765/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3106702.0568\n",
      "Epoch 766/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3070255.2955\n",
      "Epoch 767/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2935525.4773\n",
      "Epoch 768/2000\n",
      "176/176 [==============================] - 0s 299us/step - loss: 3748902.2955\n",
      "Epoch 769/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3492063.7500\n",
      "Epoch 770/2000\n",
      "176/176 [==============================] - 0s 270us/step - loss: 3287137.1136\n",
      "Epoch 771/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 2941056.2955\n",
      "Epoch 772/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3553099.0341\n",
      "Epoch 773/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3574287.1818\n",
      "Epoch 774/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 2880649.0455\n",
      "Epoch 775/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3138057.2500\n",
      "Epoch 776/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3939088.9318\n",
      "Epoch 777/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3160320.0000\n",
      "Epoch 778/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3677891.0909\n",
      "Epoch 779/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3480472.1136\n",
      "Epoch 780/2000\n",
      "176/176 [==============================] - 0s 285us/step - loss: 2755766.7727\n",
      "Epoch 781/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3292341.1591\n",
      "Epoch 782/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3462483.9659\n",
      "Epoch 783/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3196730.0455\n",
      "Epoch 784/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3558880.6818\n",
      "Epoch 785/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3365062.6136\n",
      "Epoch 786/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3429749.7727\n",
      "Epoch 787/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3486321.1818\n",
      "Epoch 788/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3555701.2614\n",
      "Epoch 789/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3541034.6477\n",
      "Epoch 790/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 229us/step - loss: 3588356.7614\n",
      "Epoch 791/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3319595.8636\n",
      "Epoch 792/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3699024.7500\n",
      "Epoch 793/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2851492.2841\n",
      "Epoch 794/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3049012.2614\n",
      "Epoch 795/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 2824380.2045\n",
      "Epoch 796/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3431186.0114\n",
      "Epoch 797/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3308560.4205\n",
      "Epoch 798/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3854564.8523\n",
      "Epoch 799/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3183807.6818\n",
      "Epoch 800/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3534315.9318\n",
      "Epoch 801/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3373718.9205\n",
      "Epoch 802/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3453523.1136\n",
      "Epoch 803/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3263972.0227\n",
      "Epoch 804/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3729656.3409\n",
      "Epoch 805/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2924788.9886\n",
      "Epoch 806/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3523478.3182\n",
      "Epoch 807/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3236753.9432\n",
      "Epoch 808/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3666620.2273\n",
      "Epoch 809/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3248476.2500\n",
      "Epoch 810/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2742310.5341\n",
      "Epoch 811/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3596242.0909\n",
      "Epoch 812/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3121574.3068\n",
      "Epoch 813/2000\n",
      "176/176 [==============================] - 0s 248us/step - loss: 3207905.2727\n",
      "Epoch 814/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3385679.5000\n",
      "Epoch 815/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2682455.2045\n",
      "Epoch 816/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3446959.7386\n",
      "Epoch 817/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3529078.3239\n",
      "Epoch 818/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2789701.9545\n",
      "Epoch 819/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3588066.2727\n",
      "Epoch 820/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3778123.9432\n",
      "Epoch 821/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3348587.8409\n",
      "Epoch 822/2000\n",
      "176/176 [==============================] - 0s 251us/step - loss: 3404746.1136\n",
      "Epoch 823/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3132014.1591\n",
      "Epoch 824/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3391144.9318\n",
      "Epoch 825/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3049759.8409\n",
      "Epoch 826/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3708129.0114\n",
      "Epoch 827/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3362145.7045\n",
      "Epoch 828/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3462148.5000\n",
      "Epoch 829/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3276117.6818\n",
      "Epoch 830/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3069454.3523\n",
      "Epoch 831/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2909213.1591\n",
      "Epoch 832/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3756839.3750\n",
      "Epoch 833/2000\n",
      "176/176 [==============================] - 0s 126us/step - loss: 2919800.7614\n",
      "Epoch 834/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 4009122.0909\n",
      "Epoch 835/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3070510.8182\n",
      "Epoch 836/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2172000.500 - 0s 204us/step - loss: 3142640.6591\n",
      "Epoch 837/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3186902.7614\n",
      "Epoch 838/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 2442476.9773\n",
      "Epoch 839/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 1701055.250 - 0s 193us/step - loss: 3343071.4545\n",
      "Epoch 840/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3784119.5227\n",
      "Epoch 841/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3785201.3182\n",
      "Epoch 842/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3754952.8182\n",
      "Epoch 843/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3464158.2955\n",
      "Epoch 844/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3757292.9432\n",
      "Epoch 845/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2690295.9773\n",
      "Epoch 846/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3859630.9318\n",
      "Epoch 847/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 3404334.4886\n",
      "Epoch 848/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3197225.2045\n",
      "Epoch 849/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 2561612.7216\n",
      "Epoch 850/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2949168.3523\n",
      "Epoch 851/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3109411.6250\n",
      "Epoch 852/2000\n",
      "176/176 [==============================] - 0s 259us/step - loss: 3288989.3750\n",
      "Epoch 853/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3396361.1136\n",
      "Epoch 854/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3396132.6023\n",
      "Epoch 855/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3531747.7614\n",
      "Epoch 856/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3416396.1591\n",
      "Epoch 857/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3073088.2159\n",
      "Epoch 858/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3633108.0341\n",
      "Epoch 859/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 2901464.4205\n",
      "Epoch 860/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3616153.9318\n",
      "Epoch 861/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3187999.3636\n",
      "Epoch 862/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3217531.2045\n",
      "Epoch 863/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 2870831.5341\n",
      "Epoch 864/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3294982.5795\n",
      "Epoch 865/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3110318.1136\n",
      "Epoch 866/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3409534.9545\n",
      "Epoch 867/2000\n",
      "176/176 [==============================] - 0s 260us/step - loss: 2684225.1023\n",
      "Epoch 868/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3149692.1364\n",
      "Epoch 869/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3777842.4318\n",
      "Epoch 870/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3157092.0114\n",
      "Epoch 871/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 2890316.1591\n",
      "Epoch 872/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3427523.0795\n",
      "Epoch 873/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3028278.2614\n",
      "Epoch 874/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2877985.9943\n",
      "Epoch 875/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3353687.8636\n",
      "Epoch 876/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 2948816.3068\n",
      "Epoch 877/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 185us/step - loss: 3014231.0909\n",
      "Epoch 878/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3121628.3750\n",
      "Epoch 879/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 2761400.8523\n",
      "Epoch 880/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3159657.8409\n",
      "Epoch 881/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3005956.6364\n",
      "Epoch 882/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3522357.0455\n",
      "Epoch 883/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3269315.6818\n",
      "Epoch 884/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3378849.4545\n",
      "Epoch 885/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3093800.5341\n",
      "Epoch 886/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3829205.9432\n",
      "Epoch 887/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3276425.8636\n",
      "Epoch 888/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3637383.4318\n",
      "Epoch 889/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3735636.3523\n",
      "Epoch 890/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3401718.7273\n",
      "Epoch 891/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3438605.2500\n",
      "Epoch 892/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2566807.0455\n",
      "Epoch 893/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3191199.3636\n",
      "Epoch 894/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3140811.1591\n",
      "Epoch 895/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3556405.0682\n",
      "Epoch 896/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3083173.2727\n",
      "Epoch 897/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3527289.8523\n",
      "Epoch 898/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3287426.9318\n",
      "Epoch 899/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3884554.4716\n",
      "Epoch 900/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3483929.5227\n",
      "Epoch 901/2000\n",
      "176/176 [==============================] - 0s 251us/step - loss: 3686803.9773\n",
      "Epoch 902/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3101049.9432\n",
      "Epoch 903/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3388614.2273\n",
      "Epoch 904/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3253224.5909\n",
      "Epoch 905/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 3798312.7727\n",
      "Epoch 906/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3501923.2273\n",
      "Epoch 907/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3044232.5682\n",
      "Epoch 908/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3621084.3523\n",
      "Epoch 909/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3609896.4205\n",
      "Epoch 910/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3754926.5114\n",
      "Epoch 911/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3055216.2727\n",
      "Epoch 912/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3387274.0227\n",
      "Epoch 913/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3602866.1818\n",
      "Epoch 914/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3080812.4091\n",
      "Epoch 915/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3136812.0000\n",
      "Epoch 916/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 2842869.7273\n",
      "Epoch 917/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 2978681.7159\n",
      "Epoch 918/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3499111.5909\n",
      "Epoch 919/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 3050245.0455\n",
      "Epoch 920/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3054678.2727\n",
      "Epoch 921/2000\n",
      "176/176 [==============================] - 0s 239us/step - loss: 3209344.2386\n",
      "Epoch 922/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2910678.3750\n",
      "Epoch 923/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3009495.0341\n",
      "Epoch 924/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 4057274.4318\n",
      "Epoch 925/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3082136.4432\n",
      "Epoch 926/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3372803.5000\n",
      "Epoch 927/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3299286.3182\n",
      "Epoch 928/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3147599.8864\n",
      "Epoch 929/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 2880789.4659\n",
      "Epoch 930/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3573264.6591\n",
      "Epoch 931/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 2838607.6591\n",
      "Epoch 932/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 2942437.4432\n",
      "Epoch 933/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3716396.7273\n",
      "Epoch 934/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3007776.8523\n",
      "Epoch 935/2000\n",
      "176/176 [==============================] - 0s 264us/step - loss: 3187005.7727\n",
      "Epoch 936/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3163238.0682\n",
      "Epoch 937/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3294987.9318\n",
      "Epoch 938/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3690123.8523\n",
      "Epoch 939/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3169213.5227\n",
      "Epoch 940/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2769480.5682\n",
      "Epoch 941/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3658693.9545\n",
      "Epoch 942/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 2969016.7500\n",
      "Epoch 943/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 2753723.6932\n",
      "Epoch 944/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3279531.1364\n",
      "Epoch 945/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3548879.3068\n",
      "Epoch 946/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3330571.4773\n",
      "Epoch 947/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3686707.0909\n",
      "Epoch 948/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3162293.0682\n",
      "Epoch 949/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3218604.5455\n",
      "Epoch 950/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3434600.0341\n",
      "Epoch 951/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3201242.2727\n",
      "Epoch 952/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3490940.8977\n",
      "Epoch 953/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3033480.5114\n",
      "Epoch 954/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3091753.6136\n",
      "Epoch 955/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3898248.5455\n",
      "Epoch 956/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3331688.3182\n",
      "Epoch 957/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3364821.3977\n",
      "Epoch 958/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3246992.8636\n",
      "Epoch 959/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3348169.8864\n",
      "Epoch 960/2000\n",
      "176/176 [==============================] - 0s 231us/step - loss: 3880519.8523\n",
      "Epoch 961/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2948579.3068\n",
      "Epoch 962/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3375767.2045\n",
      "Epoch 963/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 2855233.1250\n",
      "Epoch 964/2000\n",
      "176/176 [==============================] - 0s 241us/step - loss: 3449227.8523\n",
      "Epoch 965/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 172us/step - loss: 3797336.1364\n",
      "Epoch 966/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3239924.6364\n",
      "Epoch 967/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 2942073.7955\n",
      "Epoch 968/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3106419.8523\n",
      "Epoch 969/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3167714.7727\n",
      "Epoch 970/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3995171.9773\n",
      "Epoch 971/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3434547.1364\n",
      "Epoch 972/2000\n",
      "176/176 [==============================] - 0s 251us/step - loss: 3518715.2273\n",
      "Epoch 973/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 2908505.4091\n",
      "Epoch 974/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3739446.9773\n",
      "Epoch 975/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3011471.4773\n",
      "Epoch 976/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3733871.0909\n",
      "Epoch 977/2000\n",
      "176/176 [==============================] - 0s 259us/step - loss: 3009110.7841\n",
      "Epoch 978/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3950900.8864\n",
      "Epoch 979/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3403801.0000\n",
      "Epoch 980/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 984283.43 - 0s 180us/step - loss: 3304902.2898\n",
      "Epoch 981/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 2798407.7386\n",
      "Epoch 982/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3463183.4318\n",
      "Epoch 983/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3316544.7386\n",
      "Epoch 984/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3205239.3949\n",
      "Epoch 985/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3284232.2614\n",
      "Epoch 986/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3355174.6818\n",
      "Epoch 987/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 3816917.1591\n",
      "Epoch 988/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3272426.3239\n",
      "Epoch 989/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3079321.1818\n",
      "Epoch 990/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3323241.6591\n",
      "Epoch 991/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3317094.1705\n",
      "Epoch 992/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 2891430.0341\n",
      "Epoch 993/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2995544.7955\n",
      "Epoch 994/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3266830.6705\n",
      "Epoch 995/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3300175.7045\n",
      "Epoch 996/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3359521.1477\n",
      "Epoch 997/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3028923.0795\n",
      "Epoch 998/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3438022.5568\n",
      "Epoch 999/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 2769098.1705\n",
      "Epoch 1000/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 3592295.1364\n",
      "Epoch 1001/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3149122.0341\n",
      "Epoch 1002/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3251137.9091\n",
      "Epoch 1003/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 2667663.5455\n",
      "Epoch 1004/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 3451055.0455\n",
      "Epoch 1005/2000\n",
      "176/176 [==============================] - 0s 252us/step - loss: 3388169.7614\n",
      "Epoch 1006/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3215604.0114\n",
      "Epoch 1007/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3257833.3636\n",
      "Epoch 1008/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3332252.5000\n",
      "Epoch 1009/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3123256.8409\n",
      "Epoch 1010/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3106397.1136\n",
      "Epoch 1011/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3762797.0568\n",
      "Epoch 1012/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 3182584.3977\n",
      "Epoch 1013/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 3083719.9205\n",
      "Epoch 1014/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3201429.0227\n",
      "Epoch 1015/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 4050326.4318\n",
      "Epoch 1016/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2820673.3182\n",
      "Epoch 1017/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3680248.9545\n",
      "Epoch 1018/2000\n",
      "176/176 [==============================] - 0s 287us/step - loss: 3701311.5227\n",
      "Epoch 1019/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 3056593.9545\n",
      "Epoch 1020/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3239680.5682\n",
      "Epoch 1021/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2817642.4773\n",
      "Epoch 1022/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 2722037.2841\n",
      "Epoch 1023/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 2848211.4545\n",
      "Epoch 1024/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3251364.1761\n",
      "Epoch 1025/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 2546858.5455\n",
      "Epoch 1026/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3329065.6136\n",
      "Epoch 1027/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3225378.2443\n",
      "Epoch 1028/2000\n",
      "176/176 [==============================] - 0s 256us/step - loss: 3378818.7273\n",
      "Epoch 1029/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3284213.1818\n",
      "Epoch 1030/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3457107.4545\n",
      "Epoch 1031/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3131470.6250\n",
      "Epoch 1032/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3398107.9773\n",
      "Epoch 1033/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3211371.2614\n",
      "Epoch 1034/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 2981186.7727\n",
      "Epoch 1035/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3312788.3864\n",
      "Epoch 1036/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3853513.9318\n",
      "Epoch 1037/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3036450.9886\n",
      "Epoch 1038/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3710378.6477\n",
      "Epoch 1039/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 2987582.8977\n",
      "Epoch 1040/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3402204.6250\n",
      "Epoch 1041/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 2674494.7045\n",
      "Epoch 1042/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3003302.5909\n",
      "Epoch 1043/2000\n",
      "176/176 [==============================] - 0s 265us/step - loss: 3121512.7386\n",
      "Epoch 1044/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 3663980.5227\n",
      "Epoch 1045/2000\n",
      "176/176 [==============================] - 0s 272us/step - loss: 3067027.1591\n",
      "Epoch 1046/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3188799.4773\n",
      "Epoch 1047/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3271221.7159\n",
      "Epoch 1048/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3157506.4659\n",
      "Epoch 1049/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3452727.1932\n",
      "Epoch 1050/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3575720.0000\n",
      "Epoch 1051/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3320279.3295\n",
      "Epoch 1052/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 202us/step - loss: 3443679.6591\n",
      "Epoch 1053/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3535841.5455\n",
      "Epoch 1054/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3301560.2727\n",
      "Epoch 1055/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3617298.0000\n",
      "Epoch 1056/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3368024.2841\n",
      "Epoch 1057/2000\n",
      "176/176 [==============================] - 0s 267us/step - loss: 3524061.6705\n",
      "Epoch 1058/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3287755.8636\n",
      "Epoch 1059/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3365908.0682\n",
      "Epoch 1060/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2327466.250 - 0s 188us/step - loss: 3986457.4205\n",
      "Epoch 1061/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3141598.6818\n",
      "Epoch 1062/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3459552.5909\n",
      "Epoch 1063/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3398086.1364\n",
      "Epoch 1064/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3177066.3295\n",
      "Epoch 1065/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3727955.0682\n",
      "Epoch 1066/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3811435.2045\n",
      "Epoch 1067/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3016521.7273\n",
      "Epoch 1068/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3405809.5682\n",
      "Epoch 1069/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3040510.3409\n",
      "Epoch 1070/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3303601.2386\n",
      "Epoch 1071/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3412543.5227\n",
      "Epoch 1072/2000\n",
      "176/176 [==============================] - 0s 257us/step - loss: 3115379.5114\n",
      "Epoch 1073/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3489320.3182\n",
      "Epoch 1074/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3052192.8409\n",
      "Epoch 1075/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3486036.6705\n",
      "Epoch 1076/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3587863.7045\n",
      "Epoch 1077/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3854248.2841\n",
      "Epoch 1078/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3171642.2614\n",
      "Epoch 1079/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 2697654.9432\n",
      "Epoch 1080/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 2983556.7955\n",
      "Epoch 1081/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3339668.0341\n",
      "Epoch 1082/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3739729.9773\n",
      "Epoch 1083/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2786603.4545\n",
      "Epoch 1084/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 2834114.0568\n",
      "Epoch 1085/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3307514.7500\n",
      "Epoch 1086/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3047581.8409\n",
      "Epoch 1087/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 2960176.4091\n",
      "Epoch 1088/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3430886.2841\n",
      "Epoch 1089/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 2655788.9886\n",
      "Epoch 1090/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 1952986.125 - 0s 181us/step - loss: 3443562.3636\n",
      "Epoch 1091/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3762492.9773\n",
      "Epoch 1092/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 2942358.6818\n",
      "Epoch 1093/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 2848472.3977\n",
      "Epoch 1094/2000\n",
      "176/176 [==============================] - 0s 268us/step - loss: 3502028.2614\n",
      "Epoch 1095/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 2892624.3068\n",
      "Epoch 1096/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3155823.7955\n",
      "Epoch 1097/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3191060.6591\n",
      "Epoch 1098/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3401847.1591\n",
      "Epoch 1099/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 2967937.6136\n",
      "Epoch 1100/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3456231.3977\n",
      "Epoch 1101/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3280385.2386\n",
      "Epoch 1102/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3318095.8636\n",
      "Epoch 1103/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3050390.3864\n",
      "Epoch 1104/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3212565.8750\n",
      "Epoch 1105/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3024433.8864\n",
      "Epoch 1106/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3009842.2727\n",
      "Epoch 1107/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 2401563.7500\n",
      "Epoch 1108/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3509883.1477\n",
      "Epoch 1109/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 2949901.9205\n",
      "Epoch 1110/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3742705.6818\n",
      "Epoch 1111/2000\n",
      "176/176 [==============================] - 0s 262us/step - loss: 3108844.8636\n",
      "Epoch 1112/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3237536.9773\n",
      "Epoch 1113/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2424489.9545\n",
      "Epoch 1114/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 3025397.2273\n",
      "Epoch 1115/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3294980.5455\n",
      "Epoch 1116/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3315033.9318\n",
      "Epoch 1117/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3345088.4091\n",
      "Epoch 1118/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3629053.3409\n",
      "Epoch 1119/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3064442.5909\n",
      "Epoch 1120/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3045949.3409\n",
      "Epoch 1121/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3278591.6591\n",
      "Epoch 1122/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3303792.4318\n",
      "Epoch 1123/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3731335.0000\n",
      "Epoch 1124/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3487290.7273\n",
      "Epoch 1125/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3520040.6591\n",
      "Epoch 1126/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3171870.1364\n",
      "Epoch 1127/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3057455.5000\n",
      "Epoch 1128/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 3358311.2273\n",
      "Epoch 1129/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 2632328.7045\n",
      "Epoch 1130/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3048971.3750\n",
      "Epoch 1131/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 2838570.0795\n",
      "Epoch 1132/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3231180.2386\n",
      "Epoch 1133/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3420016.0227\n",
      "Epoch 1134/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3021153.2159\n",
      "Epoch 1135/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3429783.4432\n",
      "Epoch 1136/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 3433811.3409\n",
      "Epoch 1137/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3169742.8636\n",
      "Epoch 1138/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 216us/step - loss: 2704937.7273\n",
      "Epoch 1139/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3515148.4318\n",
      "Epoch 1140/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 3378779.8182\n",
      "Epoch 1141/2000\n",
      "176/176 [==============================] - 0s 251us/step - loss: 2993429.7500\n",
      "Epoch 1142/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3452327.0909\n",
      "Epoch 1143/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3495424.3182\n",
      "Epoch 1144/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3104210.1932\n",
      "Epoch 1145/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 2879703.6818\n",
      "Epoch 1146/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3206587.2045\n",
      "Epoch 1147/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 3168082.3409\n",
      "Epoch 1148/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3527642.6591\n",
      "Epoch 1149/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 3186938.8182\n",
      "Epoch 1150/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3145279.0455\n",
      "Epoch 1151/2000\n",
      "176/176 [==============================] - 0s 143us/step - loss: 3198940.9091\n",
      "Epoch 1152/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3044679.6591\n",
      "Epoch 1153/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 2880489.8068\n",
      "Epoch 1154/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3641799.7614\n",
      "Epoch 1155/2000\n",
      "176/176 [==============================] - 0s 258us/step - loss: 3176408.9432\n",
      "Epoch 1156/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 2963037.7386\n",
      "Epoch 1157/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 3544738.3864\n",
      "Epoch 1158/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3255511.5568\n",
      "Epoch 1159/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2951155.0227\n",
      "Epoch 1160/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 2927745.8295\n",
      "Epoch 1161/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 3514451.1477\n",
      "Epoch 1162/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3408961.8977\n",
      "Epoch 1163/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 3158231.8125\n",
      "Epoch 1164/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3711490.0227\n",
      "Epoch 1165/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3261612.7955\n",
      "Epoch 1166/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3223168.7955\n",
      "Epoch 1167/2000\n",
      "176/176 [==============================] - 0s 256us/step - loss: 3547075.4205\n",
      "Epoch 1168/2000\n",
      "176/176 [==============================] - 0s 265us/step - loss: 2912266.0909\n",
      "Epoch 1169/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 2988979.7500\n",
      "Epoch 1170/2000\n",
      "176/176 [==============================] - 0s 265us/step - loss: 2907956.6818\n",
      "Epoch 1171/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3277940.0000\n",
      "Epoch 1172/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3027802.0682\n",
      "Epoch 1173/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3630343.8182\n",
      "Epoch 1174/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 2904430.1705\n",
      "Epoch 1175/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3353232.7273\n",
      "Epoch 1176/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 4048790.5455\n",
      "Epoch 1177/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2567183.8523\n",
      "Epoch 1178/2000\n",
      "176/176 [==============================] - 0s 70us/step - loss: 3031384.5227\n",
      "Epoch 1179/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3728011.7045\n",
      "Epoch 1180/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3215305.0909\n",
      "Epoch 1181/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3277268.6818\n",
      "Epoch 1182/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3355498.5682\n",
      "Epoch 1183/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3185803.5625\n",
      "Epoch 1184/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 3197048.9318\n",
      "Epoch 1185/2000\n",
      "176/176 [==============================] - 0s 252us/step - loss: 2822025.4432\n",
      "Epoch 1186/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3767414.3182\n",
      "Epoch 1187/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3564816.0455\n",
      "Epoch 1188/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3537456.3295\n",
      "Epoch 1189/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 2835282.1932\n",
      "Epoch 1190/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 2631355.9886\n",
      "Epoch 1191/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2906511.8636\n",
      "Epoch 1192/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 2784931.5227\n",
      "Epoch 1193/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2951223.5341\n",
      "Epoch 1194/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 3748433.7273\n",
      "Epoch 1195/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3385887.6364\n",
      "Epoch 1196/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3205046.3523\n",
      "Epoch 1197/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3116608.7500\n",
      "Epoch 1198/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3047808.9659\n",
      "Epoch 1199/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3380441.9091\n",
      "Epoch 1200/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3570100.0682\n",
      "Epoch 1201/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3381037.2273\n",
      "Epoch 1202/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 2858006.5455\n",
      "Epoch 1203/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3279133.9886\n",
      "Epoch 1204/2000\n",
      "176/176 [==============================] - 0s 124us/step - loss: 3348580.0057\n",
      "Epoch 1205/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3432624.8295\n",
      "Epoch 1206/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3148384.5682\n",
      "Epoch 1207/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 2638034.6591\n",
      "Epoch 1208/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3422939.2386\n",
      "Epoch 1209/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3241468.6818\n",
      "Epoch 1210/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3618037.7727\n",
      "Epoch 1211/2000\n",
      "176/176 [==============================] - 0s 283us/step - loss: 2775225.6591\n",
      "Epoch 1212/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 2956784.1023\n",
      "Epoch 1213/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3446605.8182\n",
      "Epoch 1214/2000\n",
      "176/176 [==============================] - 0s 256us/step - loss: 2827728.9545\n",
      "Epoch 1215/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3702984.6364\n",
      "Epoch 1216/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2919544.4716\n",
      "Epoch 1217/2000\n",
      "176/176 [==============================] - 0s 287us/step - loss: 3126931.6477\n",
      "Epoch 1218/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3043840.5568\n",
      "Epoch 1219/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3917193.0909\n",
      "Epoch 1220/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3256888.4318\n",
      "Epoch 1221/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3228396.1705\n",
      "Epoch 1222/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2885967.0000\n",
      "Epoch 1223/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3481744.8182\n",
      "Epoch 1224/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 2953896.5682\n",
      "Epoch 1225/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 172us/step - loss: 3186553.5341\n",
      "Epoch 1226/2000\n",
      "176/176 [==============================] - 0s 272us/step - loss: 3068450.8750\n",
      "Epoch 1227/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3615878.7273\n",
      "Epoch 1228/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 3225818.1250\n",
      "Epoch 1229/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3858489.5682\n",
      "Epoch 1230/2000\n",
      "176/176 [==============================] - 0s 149us/step - loss: 2954570.3807\n",
      "Epoch 1231/2000\n",
      "176/176 [==============================] - 0s 135us/step - loss: 3130476.1023\n",
      "Epoch 1232/2000\n",
      "176/176 [==============================] - 0s 283us/step - loss: 3052686.5795\n",
      "Epoch 1233/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3272132.7500\n",
      "Epoch 1234/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3405439.0000\n",
      "Epoch 1235/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3315663.2727\n",
      "Epoch 1236/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3382377.8864\n",
      "Epoch 1237/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3737142.6591\n",
      "Epoch 1238/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3311261.7727\n",
      "Epoch 1239/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3725864.2727\n",
      "Epoch 1240/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3520242.9886\n",
      "Epoch 1241/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3753498.3864\n",
      "Epoch 1242/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3331729.6932\n",
      "Epoch 1243/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3567812.1591\n",
      "Epoch 1244/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3266427.2614\n",
      "Epoch 1245/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 2848831.0568\n",
      "Epoch 1246/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3894992.5000\n",
      "Epoch 1247/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3119827.5682\n",
      "Epoch 1248/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 2957578.7045\n",
      "Epoch 1249/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3506974.7159\n",
      "Epoch 1250/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3383321.2273\n",
      "Epoch 1251/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2865771.6477\n",
      "Epoch 1252/2000\n",
      "176/176 [==============================] - 0s 172us/step - loss: 3246483.3409\n",
      "Epoch 1253/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3878455.0000\n",
      "Epoch 1254/2000\n",
      "176/176 [==============================] - 0s 256us/step - loss: 3288359.5000\n",
      "Epoch 1255/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 2860816.6591\n",
      "Epoch 1256/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 4135434.5227\n",
      "Epoch 1257/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3503289.0682\n",
      "Epoch 1258/2000\n",
      "176/176 [==============================] - 0s 144us/step - loss: 2798204.4886\n",
      "Epoch 1259/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 2979096.1364\n",
      "Epoch 1260/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3519282.3636\n",
      "Epoch 1261/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3153319.0227\n",
      "Epoch 1262/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3666805.5227\n",
      "Epoch 1263/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 2831805.2841\n",
      "Epoch 1264/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3286021.4091\n",
      "Epoch 1265/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3669929.1364\n",
      "Epoch 1266/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 3239722.1136\n",
      "Epoch 1267/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3288310.8182\n",
      "Epoch 1268/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3426284.0795\n",
      "Epoch 1269/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3372670.8409\n",
      "Epoch 1270/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3328348.2727\n",
      "Epoch 1271/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3023838.4091\n",
      "Epoch 1272/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3048719.4318\n",
      "Epoch 1273/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3602735.7614\n",
      "Epoch 1274/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3258818.1705\n",
      "Epoch 1275/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3598953.2955\n",
      "Epoch 1276/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3493745.3864\n",
      "Epoch 1277/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3389526.2500\n",
      "Epoch 1278/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 4104704.750 - 0s 166us/step - loss: 3687684.8636\n",
      "Epoch 1279/2000\n",
      "176/176 [==============================] - 0s 128us/step - loss: 3157621.8636\n",
      "Epoch 1280/2000\n",
      "176/176 [==============================] - 0s 134us/step - loss: 3166925.3409\n",
      "Epoch 1281/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3625130.5909\n",
      "Epoch 1282/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3411762.1364\n",
      "Epoch 1283/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3044128.2955\n",
      "Epoch 1284/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3250959.3636\n",
      "Epoch 1285/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 2809999.2500\n",
      "Epoch 1286/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3598305.8182\n",
      "Epoch 1287/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 4168196.0227\n",
      "Epoch 1288/2000\n",
      "176/176 [==============================] - 0s 264us/step - loss: 3184573.3068\n",
      "Epoch 1289/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3286820.9091\n",
      "Epoch 1290/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3326808.1818\n",
      "Epoch 1291/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3308525.9773\n",
      "Epoch 1292/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3051872.0114\n",
      "Epoch 1293/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 3241494.2045\n",
      "Epoch 1294/2000\n",
      "176/176 [==============================] - 0s 274us/step - loss: 3072211.9318\n",
      "Epoch 1295/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2887481.9318\n",
      "Epoch 1296/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3224616.9318\n",
      "Epoch 1297/2000\n",
      "176/176 [==============================] - 0s 228us/step - loss: 3396649.8523\n",
      "Epoch 1298/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3160639.8182\n",
      "Epoch 1299/2000\n",
      "176/176 [==============================] - 0s 246us/step - loss: 3149048.4886\n",
      "Epoch 1300/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3284990.2273\n",
      "Epoch 1301/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3490500.9886\n",
      "Epoch 1302/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 2659700.8409\n",
      "Epoch 1303/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3454444.8636\n",
      "Epoch 1304/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2808603.1818\n",
      "Epoch 1305/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2824478.8977\n",
      "Epoch 1306/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3356508.2273\n",
      "Epoch 1307/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3320433.3920\n",
      "Epoch 1308/2000\n",
      "176/176 [==============================] - 0s 259us/step - loss: 3488808.1364\n",
      "Epoch 1309/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3193553.5795\n",
      "Epoch 1310/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3025123.9886\n",
      "Epoch 1311/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3343228.9886\n",
      "Epoch 1312/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 139us/step - loss: 3326015.7955\n",
      "Epoch 1313/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 2421752.6250\n",
      "Epoch 1314/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3343162.4318\n",
      "Epoch 1315/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3173220.4886\n",
      "Epoch 1316/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3481207.8295\n",
      "Epoch 1317/2000\n",
      "176/176 [==============================] - 0s 236us/step - loss: 3071173.3523\n",
      "Epoch 1318/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 4631828.000 - 0s 187us/step - loss: 3240521.7955\n",
      "Epoch 1319/2000\n",
      "176/176 [==============================] - 0s 168us/step - loss: 3511522.1705\n",
      "Epoch 1320/2000\n",
      "176/176 [==============================] - 0s 125us/step - loss: 3195039.8864\n",
      "Epoch 1321/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 2984940.0227\n",
      "Epoch 1322/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3103500.8295\n",
      "Epoch 1323/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 3507806.9432\n",
      "Epoch 1324/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3138468.3182\n",
      "Epoch 1325/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3559766.0682\n",
      "Epoch 1326/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3570725.4318\n",
      "Epoch 1327/2000\n",
      "176/176 [==============================] - 0s 254us/step - loss: 3193265.1136\n",
      "Epoch 1328/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3324177.3977\n",
      "Epoch 1329/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3097131.3864\n",
      "Epoch 1330/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3258174.9886\n",
      "Epoch 1331/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 2892812.4886\n",
      "Epoch 1332/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2639904.3125\n",
      "Epoch 1333/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 3400182.7614\n",
      "Epoch 1334/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 2932591.2500\n",
      "Epoch 1335/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 3419787.7330\n",
      "Epoch 1336/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3133155.8182\n",
      "Epoch 1337/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 2756094.8977\n",
      "Epoch 1338/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3461153.9773\n",
      "Epoch 1339/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3232833.4091\n",
      "Epoch 1340/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3358087.1591\n",
      "Epoch 1341/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3322018.1136\n",
      "Epoch 1342/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 3552899.5114\n",
      "Epoch 1343/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3128582.2045\n",
      "Epoch 1344/2000\n",
      "176/176 [==============================] - 0s 169us/step - loss: 3093949.0227\n",
      "Epoch 1345/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3053926.3864\n",
      "Epoch 1346/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3977647.4091\n",
      "Epoch 1347/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3169765.2614\n",
      "Epoch 1348/2000\n",
      "176/176 [==============================] - 0s 275us/step - loss: 3537607.9091\n",
      "Epoch 1349/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3329720.4545\n",
      "Epoch 1350/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3026331.8068\n",
      "Epoch 1351/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 2922664.1136\n",
      "Epoch 1352/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3271805.1591\n",
      "Epoch 1353/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3689303.2841\n",
      "Epoch 1354/2000\n",
      "176/176 [==============================] - 0s 293us/step - loss: 3096010.2045\n",
      "Epoch 1355/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3092589.2386\n",
      "Epoch 1356/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3554730.1023\n",
      "Epoch 1357/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3309087.7955\n",
      "Epoch 1358/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3089407.9432\n",
      "Epoch 1359/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3497587.6250\n",
      "Epoch 1360/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 2904971.5568\n",
      "Epoch 1361/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 2492405.0227\n",
      "Epoch 1362/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3508102.2955\n",
      "Epoch 1363/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3548689.4773\n",
      "Epoch 1364/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 2765593.5057\n",
      "Epoch 1365/2000\n",
      "176/176 [==============================] - 0s 161us/step - loss: 4131502.4318\n",
      "Epoch 1366/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3220901.9375\n",
      "Epoch 1367/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 2540044.5909\n",
      "Epoch 1368/2000\n",
      "176/176 [==============================] - 0s 270us/step - loss: 3571270.5114\n",
      "Epoch 1369/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3122087.1136\n",
      "Epoch 1370/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2894596.9545\n",
      "Epoch 1371/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3570759.2159\n",
      "Epoch 1372/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3371355.7727\n",
      "Epoch 1373/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3716240.6364\n",
      "Epoch 1374/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3856700.2500\n",
      "Epoch 1375/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3136904.5000\n",
      "Epoch 1376/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 3524065.8864\n",
      "Epoch 1377/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2865827.9886\n",
      "Epoch 1378/2000\n",
      "176/176 [==============================] - 0s 240us/step - loss: 3196164.1818\n",
      "Epoch 1379/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3081106.7159\n",
      "Epoch 1380/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 2925772.2159\n",
      "Epoch 1381/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 2431067.3295\n",
      "Epoch 1382/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3114632.0114\n",
      "Epoch 1383/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3823220.9886\n",
      "Epoch 1384/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2855022.6818\n",
      "Epoch 1385/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3322872.5227\n",
      "Epoch 1386/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2273975.750 - 0s 187us/step - loss: 3321175.4318\n",
      "Epoch 1387/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2802623.2045\n",
      "Epoch 1388/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3264232.0455\n",
      "Epoch 1389/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 2634057.1705\n",
      "Epoch 1390/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3409435.8409\n",
      "Epoch 1391/2000\n",
      "176/176 [==============================] - 0s 158us/step - loss: 3440754.2500\n",
      "Epoch 1392/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3341168.7955\n",
      "Epoch 1393/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3309837.0682\n",
      "Epoch 1394/2000\n",
      "176/176 [==============================] - 0s 210us/step - loss: 3492119.4091\n",
      "Epoch 1395/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3443916.0114\n",
      "Epoch 1396/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3358525.0000\n",
      "Epoch 1397/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3694837.8864\n",
      "Epoch 1398/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 175us/step - loss: 3297520.4773\n",
      "Epoch 1399/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3070330.3523\n",
      "Epoch 1400/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 2939171.4318\n",
      "Epoch 1401/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3143568.7955\n",
      "Epoch 1402/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3359132.5000\n",
      "Epoch 1403/2000\n",
      "176/176 [==============================] - 0s 132us/step - loss: 3091162.5000\n",
      "Epoch 1404/2000\n",
      "176/176 [==============================] - 0s 269us/step - loss: 3353575.8295\n",
      "Epoch 1405/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3774263.1023\n",
      "Epoch 1406/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2859782.5114\n",
      "Epoch 1407/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 2703202.1364\n",
      "Epoch 1408/2000\n",
      "176/176 [==============================] - 0s 145us/step - loss: 3156535.5227\n",
      "Epoch 1409/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 3259163.0568\n",
      "Epoch 1410/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3528911.1136\n",
      "Epoch 1411/2000\n",
      "176/176 [==============================] - 0s 284us/step - loss: 3011311.3182\n",
      "Epoch 1412/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3078548.5682\n",
      "Epoch 1413/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3296082.3636\n",
      "Epoch 1414/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 3407219.3750\n",
      "Epoch 1415/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3501367.2159\n",
      "Epoch 1416/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3256217.6364\n",
      "Epoch 1417/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3382404.1818\n",
      "Epoch 1418/2000\n",
      "176/176 [==============================] - 0s 125us/step - loss: 2939446.8864\n",
      "Epoch 1419/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 2968490.5568\n",
      "Epoch 1420/2000\n",
      "176/176 [==============================] - 0s 255us/step - loss: 2542513.6250\n",
      "Epoch 1421/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3389192.8409\n",
      "Epoch 1422/2000\n",
      "176/176 [==============================] - 0s 273us/step - loss: 3228015.2614\n",
      "Epoch 1423/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 2189856.8750\n",
      "Epoch 1424/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3019828.7727\n",
      "Epoch 1425/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3123137.7159\n",
      "Epoch 1426/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3116369.2727\n",
      "Epoch 1427/2000\n",
      "176/176 [==============================] - 0s 270us/step - loss: 3157989.2216\n",
      "Epoch 1428/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3493224.6705\n",
      "Epoch 1429/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2864333.3182\n",
      "Epoch 1430/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 3042517.6818\n",
      "Epoch 1431/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3490358.9773\n",
      "Epoch 1432/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 2894370.7727\n",
      "Epoch 1433/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 2942054.7500\n",
      "Epoch 1434/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3135513.9545\n",
      "Epoch 1435/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3531862.0455\n",
      "Epoch 1436/2000\n",
      "176/176 [==============================] - 0s 132us/step - loss: 3312868.1591\n",
      "Epoch 1437/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3578521.0000\n",
      "Epoch 1438/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 2986224.2614\n",
      "Epoch 1439/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 2879716.6250\n",
      "Epoch 1440/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3282710.0000\n",
      "Epoch 1441/2000\n",
      "176/176 [==============================] - 0s 163us/step - loss: 2997038.0455\n",
      "Epoch 1442/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 3338717.4432\n",
      "Epoch 1443/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3492952.5227\n",
      "Epoch 1444/2000\n",
      "176/176 [==============================] - 0s 250us/step - loss: 2684283.3636\n",
      "Epoch 1445/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3060341.0227\n",
      "Epoch 1446/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3152949.3409\n",
      "Epoch 1447/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3915439.3182\n",
      "Epoch 1448/2000\n",
      "176/176 [==============================] - 0s 225us/step - loss: 3572031.5000\n",
      "Epoch 1449/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 3046730.9091\n",
      "Epoch 1450/2000\n",
      "176/176 [==============================] - 0s 223us/step - loss: 3291385.6136\n",
      "Epoch 1451/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3189451.2273\n",
      "Epoch 1452/2000\n",
      "176/176 [==============================] - 0s 242us/step - loss: 2799038.8068\n",
      "Epoch 1453/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3066072.3864\n",
      "Epoch 1454/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3629597.3864\n",
      "Epoch 1455/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 2857365.8068\n",
      "Epoch 1456/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3419221.3295\n",
      "Epoch 1457/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3057443.1136\n",
      "Epoch 1458/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3699468.2500\n",
      "Epoch 1459/2000\n",
      "176/176 [==============================] - 0s 232us/step - loss: 2924676.1477\n",
      "Epoch 1460/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 3169755.6136\n",
      "Epoch 1461/2000\n",
      "176/176 [==============================] - 0s 199us/step - loss: 3361606.6364\n",
      "Epoch 1462/2000\n",
      "176/176 [==============================] - 0s 218us/step - loss: 3192742.3125\n",
      "Epoch 1463/2000\n",
      "176/176 [==============================] - 0s 257us/step - loss: 3322824.3750\n",
      "Epoch 1464/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3803250.3068\n",
      "Epoch 1465/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 4082779.5795\n",
      "Epoch 1466/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2982167.4659\n",
      "Epoch 1467/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 2947575.8068\n",
      "Epoch 1468/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3640108.4886\n",
      "Epoch 1469/2000\n",
      "176/176 [==============================] - 0s 175us/step - loss: 3226247.3068\n",
      "Epoch 1470/2000\n",
      "176/176 [==============================] - 0s 207us/step - loss: 3264622.0568\n",
      "Epoch 1471/2000\n",
      "176/176 [==============================] - 0s 139us/step - loss: 3435450.5909\n",
      "Epoch 1472/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3844022.4318\n",
      "Epoch 1473/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2916380.4318\n",
      "Epoch 1474/2000\n",
      "176/176 [==============================] - 0s 200us/step - loss: 3540662.8409\n",
      "Epoch 1475/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3032684.2045\n",
      "Epoch 1476/2000\n",
      "176/176 [==============================] - 0s 224us/step - loss: 3115195.1477\n",
      "Epoch 1477/2000\n",
      "176/176 [==============================] - 0s 120us/step - loss: 3593989.5625\n",
      "Epoch 1478/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3491082.0227\n",
      "Epoch 1479/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3223173.4773\n",
      "Epoch 1480/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3068155.5795\n",
      "Epoch 1481/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2980121.1023\n",
      "Epoch 1482/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3186585.6705\n",
      "Epoch 1483/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3102882.8182\n",
      "Epoch 1484/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3194327.8750\n",
      "Epoch 1485/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 216us/step - loss: 3055408.5000\n",
      "Epoch 1486/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3172837.2386\n",
      "Epoch 1487/2000\n",
      "176/176 [==============================] - 0s 234us/step - loss: 3400143.1932\n",
      "Epoch 1488/2000\n",
      "176/176 [==============================] - 0s 249us/step - loss: 3518348.5000\n",
      "Epoch 1489/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 2786346.4318\n",
      "Epoch 1490/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3170134.7614\n",
      "Epoch 1491/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3452651.6591\n",
      "Epoch 1492/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 2795921.7273\n",
      "Epoch 1493/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3370140.0795\n",
      "Epoch 1494/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3401823.1705\n",
      "Epoch 1495/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 2815285.6591\n",
      "Epoch 1496/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3127361.2841\n",
      "Epoch 1497/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3070332.7955\n",
      "Epoch 1498/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3516746.3636\n",
      "Epoch 1499/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 2974434.5795\n",
      "Epoch 1500/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 3388220.5114\n",
      "Epoch 1501/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 3201131.0114\n",
      "Epoch 1502/2000\n",
      "176/176 [==============================] - 0s 189us/step - loss: 3193680.7500\n",
      "Epoch 1503/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3286742.7727\n",
      "Epoch 1504/2000\n",
      "176/176 [==============================] - 0s 251us/step - loss: 3662432.9545\n",
      "Epoch 1505/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 2958985.8977\n",
      "Epoch 1506/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3916667.1136\n",
      "Epoch 1507/2000\n",
      "176/176 [==============================] - 0s 186us/step - loss: 3284304.7727\n",
      "Epoch 1508/2000\n",
      "176/176 [==============================] - 0s 124us/step - loss: 2911694.4659\n",
      "Epoch 1509/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3389938.5682\n",
      "Epoch 1510/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3241386.5227\n",
      "Epoch 1511/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 2649092.3068\n",
      "Epoch 1512/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2790116.5227\n",
      "Epoch 1513/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 2717720.7045\n",
      "Epoch 1514/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3131225.3409\n",
      "Epoch 1515/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3171204.0227\n",
      "Epoch 1516/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3027399.0000\n",
      "Epoch 1517/2000\n",
      "176/176 [==============================] - 0s 252us/step - loss: 3522884.0000\n",
      "Epoch 1518/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3008400.5000\n",
      "Epoch 1519/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 3076494.9659\n",
      "Epoch 1520/2000\n",
      "176/176 [==============================] - 0s 171us/step - loss: 3468477.6705\n",
      "Epoch 1521/2000\n",
      "176/176 [==============================] - 0s 217us/step - loss: 3403905.7727\n",
      "Epoch 1522/2000\n",
      "176/176 [==============================] - 0s 151us/step - loss: 3263169.9432\n",
      "Epoch 1523/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3033437.3409\n",
      "Epoch 1524/2000\n",
      "176/176 [==============================] - 0s 165us/step - loss: 3043135.4602\n",
      "Epoch 1525/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3801984.3864\n",
      "Epoch 1526/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3502780.8182\n",
      "Epoch 1527/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 2944762.3523\n",
      "Epoch 1528/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3131363.0227\n",
      "Epoch 1529/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3259053.8636\n",
      "Epoch 1530/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3068789.2841\n",
      "Epoch 1531/2000\n",
      "176/176 [==============================] - 0s 273us/step - loss: 3039006.8182\n",
      "Epoch 1532/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3072130.9545\n",
      "Epoch 1533/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3185012.2386\n",
      "Epoch 1534/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3284973.6591\n",
      "Epoch 1535/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3283383.1136\n",
      "Epoch 1536/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3019397.6591\n",
      "Epoch 1537/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2788383.500 - 0s 203us/step - loss: 2770204.1818\n",
      "Epoch 1538/2000\n",
      "176/176 [==============================] - 0s 180us/step - loss: 3536736.2500\n",
      "Epoch 1539/2000\n",
      "176/176 [==============================] - 0s 235us/step - loss: 3177342.7727\n",
      "Epoch 1540/2000\n",
      "176/176 [==============================] - 0s 146us/step - loss: 2939357.8750\n",
      "Epoch 1541/2000\n",
      "176/176 [==============================] - 0s 281us/step - loss: 3462994.5000\n",
      "Epoch 1542/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3091463.3864\n",
      "Epoch 1543/2000\n",
      "176/176 [==============================] - 0s 167us/step - loss: 3648720.2614\n",
      "Epoch 1544/2000\n",
      "176/176 [==============================] - 0s 202us/step - loss: 3782016.2273\n",
      "Epoch 1545/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 3301717.9091\n",
      "Epoch 1546/2000\n",
      "176/176 [==============================] - 0s 194us/step - loss: 3204622.1705\n",
      "Epoch 1547/2000\n",
      "176/176 [==============================] - 0s 288us/step - loss: 2954344.9318\n",
      "Epoch 1548/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3155455.8636\n",
      "Epoch 1549/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3584847.5455\n",
      "Epoch 1550/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3384609.1932\n",
      "Epoch 1551/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 2941022.8523\n",
      "Epoch 1552/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3383606.2273\n",
      "Epoch 1553/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 3212300.4659\n",
      "Epoch 1554/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3176034.8977\n",
      "Epoch 1555/2000\n",
      "176/176 [==============================] - 0s 190us/step - loss: 3198796.8182\n",
      "Epoch 1556/2000\n",
      "176/176 [==============================] - 0s 166us/step - loss: 2990616.9886\n",
      "Epoch 1557/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3002702.1818\n",
      "Epoch 1558/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3542335.7500\n",
      "Epoch 1559/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3346099.0682\n",
      "Epoch 1560/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 3542459.0341\n",
      "Epoch 1561/2000\n",
      "176/176 [==============================] - 0s 261us/step - loss: 2950954.2955\n",
      "Epoch 1562/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2896646.2955\n",
      "Epoch 1563/2000\n",
      "176/176 [==============================] - 0s 213us/step - loss: 3642883.7386\n",
      "Epoch 1564/2000\n",
      "176/176 [==============================] - 0s 215us/step - loss: 2786952.4091\n",
      "Epoch 1565/2000\n",
      "176/176 [==============================] - 0s 156us/step - loss: 3233129.6477\n",
      "Epoch 1566/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 2774470.2386\n",
      "Epoch 1567/2000\n",
      "176/176 [==============================] - 0s 290us/step - loss: 2750293.6705\n",
      "Epoch 1568/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3305861.0114\n",
      "Epoch 1569/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3251588.7159\n",
      "Epoch 1570/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2560701.8295\n",
      "Epoch 1571/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 2850592.2955\n",
      "Epoch 1572/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 156us/step - loss: 3285141.3182\n",
      "Epoch 1573/2000\n",
      "176/176 [==============================] - 0s 214us/step - loss: 2677561.1250\n",
      "Epoch 1574/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 3316796.9659\n",
      "Epoch 1575/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2871224.3977\n",
      "Epoch 1576/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3118047.4545\n",
      "Epoch 1577/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3150444.9773\n",
      "Epoch 1578/2000\n",
      "176/176 [==============================] - 0s 160us/step - loss: 3797916.0114\n",
      "Epoch 1579/2000\n",
      "176/176 [==============================] - 0s 222us/step - loss: 2684718.5909\n",
      "Epoch 1580/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 3526264.8750\n",
      "Epoch 1581/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 3341920.8295\n",
      "Epoch 1582/2000\n",
      "176/176 [==============================] - 0s 238us/step - loss: 3548171.3182\n",
      "Epoch 1583/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 4042856.3409\n",
      "Epoch 1584/2000\n",
      "176/176 [==============================] - 0s 174us/step - loss: 3228787.3409\n",
      "Epoch 1585/2000\n",
      "176/176 [==============================] - 0s 230us/step - loss: 2520398.2159\n",
      "Epoch 1586/2000\n",
      "176/176 [==============================] - 0s 157us/step - loss: 2877297.9659\n",
      "Epoch 1587/2000\n",
      "176/176 [==============================] - 0s 233us/step - loss: 3186002.2841\n",
      "Epoch 1588/2000\n",
      "176/176 [==============================] - 0s 243us/step - loss: 3562061.0227\n",
      "Epoch 1589/2000\n",
      "176/176 [==============================] - 0s 184us/step - loss: 2908303.2841\n",
      "Epoch 1590/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 2748143.0057\n",
      "Epoch 1591/2000\n",
      "176/176 [==============================] - 0s 201us/step - loss: 3247565.8409\n",
      "Epoch 1592/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3544062.8068\n",
      "Epoch 1593/2000\n",
      "176/176 [==============================] - 0s 245us/step - loss: 2664433.7159\n",
      "Epoch 1594/2000\n",
      "176/176 [==============================] - 0s 206us/step - loss: 3812689.0909\n",
      "Epoch 1595/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3152986.7102\n",
      "Epoch 1596/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2954171.6250\n",
      "Epoch 1597/2000\n",
      "176/176 [==============================] - 0s 265us/step - loss: 2465671.0455\n",
      "Epoch 1598/2000\n",
      "176/176 [==============================] - 0s 101us/step - loss: 3362471.8068\n",
      "Epoch 1599/2000\n",
      "176/176 [==============================] - 0s 192us/step - loss: 3463395.5795\n",
      "Epoch 1600/2000\n",
      "176/176 [==============================] - 0s 102us/step - loss: 2832317.6364\n",
      "Epoch 1601/2000\n",
      "176/176 [==============================] - 0s 182us/step - loss: 3332858.2614\n",
      "Epoch 1602/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3059090.4545\n",
      "Epoch 1603/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3105168.4886\n",
      "Epoch 1604/2000\n",
      "176/176 [==============================] - 0s 799us/step - loss: 3275535.2955\n",
      "Epoch 1605/2000\n",
      "176/176 [==============================] - 0s 976us/step - loss: 2988972.9318\n",
      "Epoch 1606/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 2728858.3977\n",
      "Epoch 1607/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3362850.8636\n",
      "Epoch 1608/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3193552.9773\n",
      "Epoch 1609/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 2964334.3295\n",
      "Epoch 1610/2000\n",
      "176/176 [==============================] - 0s 969us/step - loss: 3596566.8295\n",
      "Epoch 1611/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3117783.0000\n",
      "Epoch 1612/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3263759.0568\n",
      "Epoch 1613/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3684056.0682\n",
      "Epoch 1614/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3014143.1136\n",
      "Epoch 1615/2000\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 3326511.9318\n",
      "Epoch 1616/2000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 3518237.0455\n",
      "Epoch 1617/2000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 3391085.0909A: 0s - loss: 3278451.67\n",
      "Epoch 1618/2000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 3327046.9773\n",
      "Epoch 1619/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3422901.4091\n",
      "Epoch 1620/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3260418.9773\n",
      "Epoch 1621/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3253404.8182\n",
      "Epoch 1622/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 3493489.3636\n",
      "Epoch 1623/2000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 2455668.1932A: 0s - loss: 2355174.46\n",
      "Epoch 1624/2000\n",
      "176/176 [==============================] - 0s 493us/step - loss: 3378262.5000\n",
      "Epoch 1625/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3195599.6591\n",
      "Epoch 1626/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3831928.8068\n",
      "Epoch 1627/2000\n",
      "176/176 [==============================] - 0s 227us/step - loss: 3416668.2045\n",
      "Epoch 1628/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3547244.7727\n",
      "Epoch 1629/2000\n",
      "176/176 [==============================] - 0s 179us/step - loss: 3190038.9432\n",
      "Epoch 1630/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3125509.1818\n",
      "Epoch 1631/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3791255.2955\n",
      "Epoch 1632/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 2391581.500 - 0s 178us/step - loss: 3026338.4318\n",
      "Epoch 1633/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3604409.7045\n",
      "Epoch 1634/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3558708.5568\n",
      "Epoch 1635/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3736255.4773\n",
      "Epoch 1636/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3359816.7727\n",
      "Epoch 1637/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3155101.1705\n",
      "Epoch 1638/2000\n",
      "176/176 [==============================] - 0s 246us/step - loss: 2559413.8295\n",
      "Epoch 1639/2000\n",
      "176/176 [==============================] - 0s 155us/step - loss: 2672066.1364\n",
      "Epoch 1640/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3065743.7614\n",
      "Epoch 1641/2000\n",
      "176/176 [==============================] - 0s 291us/step - loss: 2988729.3636\n",
      "Epoch 1642/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3672780.5000\n",
      "Epoch 1643/2000\n",
      "176/176 [==============================] - 0s 121us/step - loss: 3260266.0795\n",
      "Epoch 1644/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3140052.5909\n",
      "Epoch 1645/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3354321.5795\n",
      "Epoch 1646/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3550836.3523\n",
      "Epoch 1647/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3649488.8409\n",
      "Epoch 1648/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3657354.9432\n",
      "Epoch 1649/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3110569.7045\n",
      "Epoch 1650/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3125242.6250\n",
      "Epoch 1651/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3413118.5455\n",
      "Epoch 1652/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3790781.0795\n",
      "Epoch 1653/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2992794.6477\n",
      "Epoch 1654/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2889983.3295\n",
      "Epoch 1655/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2745900.5114\n",
      "Epoch 1656/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3425520.6364\n",
      "Epoch 1657/2000\n",
      "176/176 [==============================] - 0s 265us/step - loss: 3228513.7955\n",
      "Epoch 1658/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 91us/step - loss: 2953172.2273\n",
      "Epoch 1659/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3656987.3295\n",
      "Epoch 1660/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3409185.6023\n",
      "Epoch 1661/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3298502.0909\n",
      "Epoch 1662/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3113380.3295\n",
      "Epoch 1663/2000\n",
      "176/176 [==============================] - 0s 203us/step - loss: 3001545.6591\n",
      "Epoch 1664/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2885295.8750\n",
      "Epoch 1665/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3697551.2386\n",
      "Epoch 1666/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 2498087.8750\n",
      "Epoch 1667/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3023549.6591\n",
      "Epoch 1668/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 4213288.000 - 0s 193us/step - loss: 3279160.6250\n",
      "Epoch 1669/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3063892.3977\n",
      "Epoch 1670/2000\n",
      "176/176 [==============================] - 0s 127us/step - loss: 3596767.9318\n",
      "Epoch 1671/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3347566.0568\n",
      "Epoch 1672/2000\n",
      "176/176 [==============================] - 0s 188us/step - loss: 3604713.9318\n",
      "Epoch 1673/2000\n",
      "176/176 [==============================] - 0s 127us/step - loss: 3360839.9205\n",
      "Epoch 1674/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3024279.4091\n",
      "Epoch 1675/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 2844071.3409\n",
      "Epoch 1676/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3062160.1818\n",
      "Epoch 1677/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3171319.2500\n",
      "Epoch 1678/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 2631795.0966\n",
      "Epoch 1679/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2721348.8182\n",
      "Epoch 1680/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2672409.1023\n",
      "Epoch 1681/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3059873.9318\n",
      "Epoch 1682/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3191891.5909\n",
      "Epoch 1683/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3438080.2727\n",
      "Epoch 1684/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3228303.0568\n",
      "Epoch 1685/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3346133.6477\n",
      "Epoch 1686/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3182632.8182\n",
      "Epoch 1687/2000\n",
      "176/176 [==============================] - 0s 226us/step - loss: 2861773.5227\n",
      "Epoch 1688/2000\n",
      "176/176 [==============================] - 0s 150us/step - loss: 3373924.7955\n",
      "Epoch 1689/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3944396.8636\n",
      "Epoch 1690/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4121900.4773\n",
      "Epoch 1691/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3057183.5000\n",
      "Epoch 1692/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2765819.1023\n",
      "Epoch 1693/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4092162.9886\n",
      "Epoch 1694/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3268576.8409\n",
      "Epoch 1695/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2386026.1023\n",
      "Epoch 1696/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3264676.8864\n",
      "Epoch 1697/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 4018661.1705\n",
      "Epoch 1698/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2952125.3864\n",
      "Epoch 1699/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3344200.2500\n",
      "Epoch 1700/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3088669.4659\n",
      "Epoch 1701/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3551310.8750\n",
      "Epoch 1702/2000\n",
      "176/176 [==============================] - 0s 211us/step - loss: 2943683.5227\n",
      "Epoch 1703/2000\n",
      "176/176 [==============================] - 0s 139us/step - loss: 3327842.8636\n",
      "Epoch 1704/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2906370.3295\n",
      "Epoch 1705/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2743226.0227\n",
      "Epoch 1706/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3429056.9318\n",
      "Epoch 1707/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3085556.7955\n",
      "Epoch 1708/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2951047.6023\n",
      "Epoch 1709/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3398476.3182\n",
      "Epoch 1710/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2769691.4091\n",
      "Epoch 1711/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3591976.9205\n",
      "Epoch 1712/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3414687.5114\n",
      "Epoch 1713/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2845012.6364\n",
      "Epoch 1714/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2951278.1477\n",
      "Epoch 1715/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3125415.2727\n",
      "Epoch 1716/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3495276.1023\n",
      "Epoch 1717/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3013121.8409\n",
      "Epoch 1718/2000\n",
      "176/176 [==============================] - 0s 136us/step - loss: 2765173.4773\n",
      "Epoch 1719/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2944058.2045\n",
      "Epoch 1720/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3262644.7955\n",
      "Epoch 1721/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3205911.5909\n",
      "Epoch 1722/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3778680.2727\n",
      "Epoch 1723/2000\n",
      "176/176 [==============================] - 0s 191us/step - loss: 3741051.0795\n",
      "Epoch 1724/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2897792.5000\n",
      "Epoch 1725/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3002936.6364\n",
      "Epoch 1726/2000\n",
      "176/176 [==============================] - 0s 247us/step - loss: 3201662.1932\n",
      "Epoch 1727/2000\n",
      "176/176 [==============================] - 0s 278us/step - loss: 3240076.6818\n",
      "Epoch 1728/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3411365.7045\n",
      "Epoch 1729/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2640503.0909\n",
      "Epoch 1730/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3906170.0341\n",
      "Epoch 1731/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 2549770.6932\n",
      "Epoch 1732/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3312902.2159\n",
      "Epoch 1733/2000\n",
      "176/176 [==============================] - 0s 162us/step - loss: 2756975.4205\n",
      "Epoch 1734/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3029544.4886\n",
      "Epoch 1735/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3250150.5227\n",
      "Epoch 1736/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3392345.2557\n",
      "Epoch 1737/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3187148.0568\n",
      "Epoch 1738/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3248905.8182\n",
      "Epoch 1739/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3158966.2500\n",
      "Epoch 1740/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2534347.8409\n",
      "Epoch 1741/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3548372.1591\n",
      "Epoch 1742/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3206531.1136\n",
      "Epoch 1743/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2933815.2727\n",
      "Epoch 1744/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3623912.1136\n",
      "Epoch 1745/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 178us/step - loss: 2796556.0114\n",
      "Epoch 1746/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3386266.3636\n",
      "Epoch 1747/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3004272.6023\n",
      "Epoch 1748/2000\n",
      "176/176 [==============================] - 0s 220us/step - loss: 3536303.7045\n",
      "Epoch 1749/2000\n",
      "176/176 [==============================] - 0s 130us/step - loss: 3879005.3636\n",
      "Epoch 1750/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3112785.6591\n",
      "Epoch 1751/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2985710.1364\n",
      "Epoch 1752/2000\n",
      "176/176 [==============================] - 0s 252us/step - loss: 4585100.5682\n",
      "Epoch 1753/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3307318.4545\n",
      "Epoch 1754/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3066589.1818\n",
      "Epoch 1755/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3531828.9886\n",
      "Epoch 1756/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3067926.4886\n",
      "Epoch 1757/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3407619.1591\n",
      "Epoch 1758/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3645152.1364\n",
      "Epoch 1759/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3601438.9432\n",
      "Epoch 1760/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2851433.2273\n",
      "Epoch 1761/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 2798555.4091\n",
      "Epoch 1762/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3313240.8295\n",
      "Epoch 1763/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3651388.7386\n",
      "Epoch 1764/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3728881.6364\n",
      "Epoch 1765/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3127042.8523\n",
      "Epoch 1766/2000\n",
      "176/176 [==============================] - 0s 221us/step - loss: 2744916.7159\n",
      "Epoch 1767/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 2871130.7159\n",
      "Epoch 1768/2000\n",
      "176/176 [==============================] - 0s 204us/step - loss: 3358898.7386\n",
      "Epoch 1769/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2426337.9659\n",
      "Epoch 1770/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3234808.1932\n",
      "Epoch 1771/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2662108.7500\n",
      "Epoch 1772/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3252725.7045\n",
      "Epoch 1773/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3287879.0227\n",
      "Epoch 1774/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3402987.6477\n",
      "Epoch 1775/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3129879.6705\n",
      "Epoch 1776/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2976536.3636\n",
      "Epoch 1777/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2685467.9773\n",
      "Epoch 1778/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3378597.2045\n",
      "Epoch 1779/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3829807.1818\n",
      "Epoch 1780/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3700960.5227\n",
      "Epoch 1781/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3856986.4091\n",
      "Epoch 1782/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2949731.5909\n",
      "Epoch 1783/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2937641.4318\n",
      "Epoch 1784/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3028531.7273\n",
      "Epoch 1785/2000\n",
      "176/176 [==============================] - 0s 198us/step - loss: 3356420.1818\n",
      "Epoch 1786/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3055094.8409\n",
      "Epoch 1787/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3420510.4091\n",
      "Epoch 1788/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3358980.4318\n",
      "Epoch 1789/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3095498.3636\n",
      "Epoch 1790/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 3320298.2045\n",
      "Epoch 1791/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3317906.4886\n",
      "Epoch 1792/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2728554.5682\n",
      "Epoch 1793/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3373556.2045\n",
      "Epoch 1794/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3339530.2955\n",
      "Epoch 1795/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3306340.9659\n",
      "Epoch 1796/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3187610.2386\n",
      "Epoch 1797/2000\n",
      "176/176 [==============================] - 0s 131us/step - loss: 3530026.6136\n",
      "Epoch 1798/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2894981.4545\n",
      "Epoch 1799/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3301005.0455\n",
      "Epoch 1800/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2951114.3182\n",
      "Epoch 1801/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3816990.8636\n",
      "Epoch 1802/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3516596.1477\n",
      "Epoch 1803/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3193128.9091\n",
      "Epoch 1804/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2760310.7216\n",
      "Epoch 1805/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3051018.7614\n",
      "Epoch 1806/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2897841.5114\n",
      "Epoch 1807/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3338952.7955\n",
      "Epoch 1808/2000\n",
      "176/176 [==============================] - 0s 219us/step - loss: 3803314.2273\n",
      "Epoch 1809/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 2802213.1705\n",
      "Epoch 1810/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 3216547.500 - 0s 89us/step - loss: 3415964.0455\n",
      "Epoch 1811/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3256366.9773\n",
      "Epoch 1812/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3397856.3864\n",
      "Epoch 1813/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3526913.9773\n",
      "Epoch 1814/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3172990.0568\n",
      "Epoch 1815/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3026849.3864\n",
      "Epoch 1816/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2871640.4886\n",
      "Epoch 1817/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3479555.3068\n",
      "Epoch 1818/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3129774.0000\n",
      "Epoch 1819/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3575287.3068\n",
      "Epoch 1820/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3463611.4318\n",
      "Epoch 1821/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3251323.3636\n",
      "Epoch 1822/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3010827.5227\n",
      "Epoch 1823/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3238224.3182\n",
      "Epoch 1824/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3336139.8636\n",
      "Epoch 1825/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2632943.7273\n",
      "Epoch 1826/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3781489.6705\n",
      "Epoch 1827/2000\n",
      "176/176 [==============================] - 0s 244us/step - loss: 2918894.7841\n",
      "Epoch 1828/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2679246.7955\n",
      "Epoch 1829/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3498897.7273\n",
      "Epoch 1830/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 3937770.5455\n",
      "Epoch 1831/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 3150227.3295\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 164us/step - loss: 3549122.1591\n",
      "Epoch 1833/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3063278.1705\n",
      "Epoch 1834/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2669813.8409\n",
      "Epoch 1835/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2916095.6364\n",
      "Epoch 1836/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3394195.5227\n",
      "Epoch 1837/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3045448.7727\n",
      "Epoch 1838/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3613737.6705\n",
      "Epoch 1839/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3176728.3636\n",
      "Epoch 1840/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2844757.4091\n",
      "Epoch 1841/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2779570.6250\n",
      "Epoch 1842/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 2961019.7841\n",
      "Epoch 1843/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3044040.4659\n",
      "Epoch 1844/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3177926.5227\n",
      "Epoch 1845/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 2686373.7386\n",
      "Epoch 1846/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 2845259.8125\n",
      "Epoch 1847/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2729887.2045\n",
      "Epoch 1848/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3281502.9432\n",
      "Epoch 1849/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3297707.9773\n",
      "Epoch 1850/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3215013.8068\n",
      "Epoch 1851/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 2923691.5114\n",
      "Epoch 1852/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 2890035.9659\n",
      "Epoch 1853/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2571991.5909\n",
      "Epoch 1854/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3430010.0114\n",
      "Epoch 1855/2000\n",
      "176/176 [==============================] - ETA: 0s - loss: 3184451.500 - 0s 89us/step - loss: 3443581.4545\n",
      "Epoch 1856/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 2444101.8295\n",
      "Epoch 1857/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3493585.5227\n",
      "Epoch 1858/2000\n",
      "176/176 [==============================] - 0s 89us/step - loss: 3007400.1364\n",
      "Epoch 1859/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2890922.8864\n",
      "Epoch 1860/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 2866619.6364\n",
      "Epoch 1861/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3286078.4773\n",
      "Epoch 1862/2000\n",
      "176/176 [==============================] - 0s 212us/step - loss: 3497035.0455\n",
      "Epoch 1863/2000\n",
      "176/176 [==============================] - 0s 148us/step - loss: 3396730.4545\n",
      "Epoch 1864/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3100650.9091\n",
      "Epoch 1865/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3159856.7841\n",
      "Epoch 1866/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2635281.3068\n",
      "Epoch 1867/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2965717.5000\n",
      "Epoch 1868/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3365691.0568\n",
      "Epoch 1869/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3338987.6023\n",
      "Epoch 1870/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3094622.4205\n",
      "Epoch 1871/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3348660.0909\n",
      "Epoch 1872/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3156678.9205\n",
      "Epoch 1873/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3377838.1364\n",
      "Epoch 1874/2000\n",
      "176/176 [==============================] - 0s 216us/step - loss: 2674244.4091\n",
      "Epoch 1875/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 3804036.2955\n",
      "Epoch 1876/2000\n",
      "176/176 [==============================] - 0s 187us/step - loss: 3159797.1705\n",
      "Epoch 1877/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3530683.6023\n",
      "Epoch 1878/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3149956.6818\n",
      "Epoch 1879/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3086712.6591\n",
      "Epoch 1880/2000\n",
      "176/176 [==============================] - 0s 153us/step - loss: 2455950.6705\n",
      "Epoch 1881/2000\n",
      "176/176 [==============================] - 0s 159us/step - loss: 2955053.3864\n",
      "Epoch 1882/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3107185.8977\n",
      "Epoch 1883/2000\n",
      "176/176 [==============================] - 0s 164us/step - loss: 3716367.9091\n",
      "Epoch 1884/2000\n",
      "176/176 [==============================] - 0s 181us/step - loss: 3312901.6932\n",
      "Epoch 1885/2000\n",
      "176/176 [==============================] - 0s 80us/step - loss: 3297403.7045\n",
      "Epoch 1886/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3668227.1818\n",
      "Epoch 1887/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3852176.1591\n",
      "Epoch 1888/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3200308.4091\n",
      "Epoch 1889/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2590063.7841\n",
      "Epoch 1890/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3052793.6023\n",
      "Epoch 1891/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3203765.8409\n",
      "Epoch 1892/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3154889.6250\n",
      "Epoch 1893/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3188126.5398\n",
      "Epoch 1894/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2907699.6136\n",
      "Epoch 1895/2000\n",
      "176/176 [==============================] - 0s 259us/step - loss: 3557640.0227\n",
      "Epoch 1896/2000\n",
      "176/176 [==============================] - 0s 195us/step - loss: 3166417.7727\n",
      "Epoch 1897/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3831977.2727\n",
      "Epoch 1898/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2891346.6818\n",
      "Epoch 1899/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3379518.5795\n",
      "Epoch 1900/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2852274.0682\n",
      "Epoch 1901/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3609267.0000\n",
      "Epoch 1902/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2919503.7727\n",
      "Epoch 1903/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3060067.0000\n",
      "Epoch 1904/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3271731.6818\n",
      "Epoch 1905/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2787063.0000\n",
      "Epoch 1906/2000\n",
      "176/176 [==============================] - 0s 196us/step - loss: 3447471.2841\n",
      "Epoch 1907/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3321433.5455\n",
      "Epoch 1908/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3363976.6932\n",
      "Epoch 1909/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2723278.5341\n",
      "Epoch 1910/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2763371.7614\n",
      "Epoch 1911/2000\n",
      "176/176 [==============================] - 0s 197us/step - loss: 3242252.1932\n",
      "Epoch 1912/2000\n",
      "176/176 [==============================] - 0s 140us/step - loss: 3243242.0455\n",
      "Epoch 1913/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3344300.9205\n",
      "Epoch 1914/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3371389.6250\n",
      "Epoch 1915/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2776492.6591\n",
      "Epoch 1916/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2786460.4318\n",
      "Epoch 1917/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3736211.6818\n",
      "Epoch 1918/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2910456.1591\n",
      "Epoch 1919/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 178us/step - loss: 2998122.3409\n",
      "Epoch 1920/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2835683.0682\n",
      "Epoch 1921/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3067964.9432\n",
      "Epoch 1922/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3233542.1477\n",
      "Epoch 1923/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2783705.5455\n",
      "Epoch 1924/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3576503.5909\n",
      "Epoch 1925/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2920558.2216\n",
      "Epoch 1926/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2953798.7159\n",
      "Epoch 1927/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3425323.9091\n",
      "Epoch 1928/2000\n",
      "176/176 [==============================] - 0s 209us/step - loss: 3185777.4773\n",
      "Epoch 1929/2000\n",
      "176/176 [==============================] - 0s 147us/step - loss: 3510938.3068\n",
      "Epoch 1930/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2735791.6591\n",
      "Epoch 1931/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3027809.2727\n",
      "Epoch 1932/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3710644.8409\n",
      "Epoch 1933/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3125723.3409\n",
      "Epoch 1934/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 2967026.1818\n",
      "Epoch 1935/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3086609.4773\n",
      "Epoch 1936/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3831676.2727\n",
      "Epoch 1937/2000\n",
      "176/176 [==============================] - 0s 193us/step - loss: 2858149.6250\n",
      "Epoch 1938/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2962482.5909\n",
      "Epoch 1939/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3363983.8750\n",
      "Epoch 1940/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3320137.5795\n",
      "Epoch 1941/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2887428.2102\n",
      "Epoch 1942/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2912728.0341\n",
      "Epoch 1943/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3179117.0795\n",
      "Epoch 1944/2000\n",
      "176/176 [==============================] - 0s 208us/step - loss: 3186040.7955\n",
      "Epoch 1945/2000\n",
      "176/176 [==============================] - 0s 126us/step - loss: 2988458.0795\n",
      "Epoch 1946/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3902738.0568\n",
      "Epoch 1947/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3262714.6932\n",
      "Epoch 1948/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3260578.4545\n",
      "Epoch 1949/2000\n",
      "176/176 [==============================] - 0s 266us/step - loss: 3728413.4091\n",
      "Epoch 1950/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3734463.8409\n",
      "Epoch 1951/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3317096.6136\n",
      "Epoch 1952/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3217341.7500\n",
      "Epoch 1953/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3699708.2045\n",
      "Epoch 1954/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3297369.5682\n",
      "Epoch 1955/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2992052.6932\n",
      "Epoch 1956/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3237097.3636\n",
      "Epoch 1957/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3005058.2500\n",
      "Epoch 1958/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3101757.1136\n",
      "Epoch 1959/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2862253.4205\n",
      "Epoch 1960/2000\n",
      "176/176 [==============================] - 0s 183us/step - loss: 3653038.6477\n",
      "Epoch 1961/2000\n",
      "176/176 [==============================] - 0s 173us/step - loss: 3464653.6591\n",
      "Epoch 1962/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3149326.5000\n",
      "Epoch 1963/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3113793.0000\n",
      "Epoch 1964/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3384263.5114\n",
      "Epoch 1965/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2556329.2386\n",
      "Epoch 1966/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2671424.0000\n",
      "Epoch 1967/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3683688.2159\n",
      "Epoch 1968/2000\n",
      "176/176 [==============================] - 0s 253us/step - loss: 3034395.1023\n",
      "Epoch 1969/2000\n",
      "176/176 [==============================] - 0s 185us/step - loss: 3216165.4545\n",
      "Epoch 1970/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3172288.3864\n",
      "Epoch 1971/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2896495.9886\n",
      "Epoch 1972/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2658089.2045\n",
      "Epoch 1973/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3273302.5227\n",
      "Epoch 1974/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3054278.5227\n",
      "Epoch 1975/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2875785.0795\n",
      "Epoch 1976/2000\n",
      "176/176 [==============================] - 0s 205us/step - loss: 3306954.8750\n",
      "Epoch 1977/2000\n",
      "176/176 [==============================] - 0s 134us/step - loss: 3358151.9773\n",
      "Epoch 1978/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3167287.1136\n",
      "Epoch 1979/2000\n",
      "176/176 [==============================] - 0s 229us/step - loss: 2833750.7841\n",
      "Epoch 1980/2000\n",
      "176/176 [==============================] - 0s 154us/step - loss: 2797191.4773\n",
      "Epoch 1981/2000\n",
      "176/176 [==============================] - 0s 177us/step - loss: 3383756.3864\n",
      "Epoch 1982/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3336516.8523\n",
      "Epoch 1983/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3201757.5909\n",
      "Epoch 1984/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2888542.0909\n",
      "Epoch 1985/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3117745.5227\n",
      "Epoch 1986/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3426989.4432\n",
      "Epoch 1987/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3134866.9091\n",
      "Epoch 1988/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3114878.4091\n",
      "Epoch 1989/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2893945.0682\n",
      "Epoch 1990/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2938553.7273\n",
      "Epoch 1991/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3593195.9545\n",
      "Epoch 1992/2000\n",
      "176/176 [==============================] - 0s 170us/step - loss: 3131081.8864\n",
      "Epoch 1993/2000\n",
      "176/176 [==============================] - 0s 141us/step - loss: 3273822.5341\n",
      "Epoch 1994/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 2861089.1364\n",
      "Epoch 1995/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3465367.2159\n",
      "Epoch 1996/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3426373.1136\n",
      "Epoch 1997/2000\n",
      "176/176 [==============================] - 0s 178us/step - loss: 3399547.0114\n",
      "Epoch 1998/2000\n",
      "176/176 [==============================] - 0s 237us/step - loss: 3160580.7273\n",
      "Epoch 1999/2000\n",
      "176/176 [==============================] - 0s 176us/step - loss: 2861080.5114\n",
      "Epoch 2000/2000\n",
      "176/176 [==============================] - 0s 119us/step - loss: 3325080.2273\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2e309ae0e88>"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer ='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=2000,batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "train_pred= model.predict(X_train)\n",
    "test_u =test_pred.flatten()\n",
    "test_u\n",
    "train_u = train_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.75\n",
      "Accuracy for Training set: 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(r2_score(y_test,test_u)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(r2_score(y_train,train_u)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 5.2\n",
      "Tree on test set MAE%: 12.0\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_u))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_u))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2636.6686043749787"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_u))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regressor with K = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Tuning \n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "booster=['gbtree','gblinear']\n",
    "n_estimators = [100, 500, 700, 1000, 1500]\n",
    "max_depth = [2, 3, 5, 9]\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "parameter_grid = {\n",
    "    'base_score':base_score,\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "ran = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=parameter_grid,cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5,\n",
    "            return_train_score = True,\n",
    "            random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   33.0s\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  1.9min finished\n",
      "C:\\Users\\amith\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\amith\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:53:00] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_st...\n",
       "                   iid='warn', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 9],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 700, 1000,\n",
       "                                                         1500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=35, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
       "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ran.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
    "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "             silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:54:57] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.15, max_delta_step=0,\n",
       "             max_depth=2, min_child_weight=1, missing=None, n_estimators=700,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = regressor.predict(X_train)\n",
    "test_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152    19900\n",
       "74     14995\n",
       "71     12995\n",
       "161    15300\n",
       "162    23400\n",
       "Name: Price, dtype: int64"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Test set: 0.76\n",
      "Accuracy for Training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for Test set: \"+\"{:.2f}\".format(regressor.score(X_test,y_test)))\n",
    "print(\"Accuracy for Training set: \"+\"{:.2f}\".format(regressor.score(X_train,y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree on train set MAE%: 3.1\n",
      "Tree on test set MAE%: 11.8\n"
     ]
    }
   ],
   "source": [
    "MAE_train=np.mean(abs(y_train-train_pred))/np.mean(y_train)\n",
    "print(\"Tree on train set MAE%:\", round(MAE_train*100,1))\n",
    "\n",
    "MAE_test=np.mean(abs(y_test-test_pred))/np.mean(y_test)\n",
    "print(\"Tree on test set MAE%:\", round(MAE_test*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2612.2167251606866"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
